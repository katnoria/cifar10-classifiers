{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classfication Network Architecture\n",
    "\n",
    "BatchNorm has some issue in tf2.0. The github issues say that the behaviour has changed and we need to be mindful of the flag `training:False | True`. This notebook attempts to figure out how to get BN to work in TF 2.x.\n",
    "\n",
    "In my previous notebooks, I have had dismal performance whenever I used BN.\n",
    "\n",
    "@date: 02-Sep-2020 | @author: katnoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def version_info(cls):\n",
    "    print(f\"{cls.__name__}: {cls.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version Used in this Notebook:\n",
      "tensorflow: 2.3.0\n",
      "tensorflow_datasets: 3.2.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Version Used in this Notebook:\")\n",
    "version_info(tf)\n",
    "version_info(tfds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Tensorflow Datasets already provides this dataset in a format that we can use out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "(ds_train, ds_test), metadata = tfds.load(\n",
    "    'cifar10', split=['train', 'test'], shuffle_files=True, \n",
    "    with_info=True, as_supervised=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_train), len(ds_test), metadata.features['label'].num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the built in function to visualise the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeaturesDict({\n",
       "    'id': Text(shape=(), dtype=tf.string),\n",
       "    'image': Image(shape=(32, 32, 3), dtype=tf.uint8),\n",
       "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review metadata\n",
    "# See https://www.tensorflow.org/datasets/overview\n",
    "metadata.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 50000\n",
      "Test dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = metadata.features[\"label\"].num_classes\n",
    "\n",
    "num_train_examples = len(ds_train)\n",
    "num_test_examples = len(ds_test)\n",
    "print(f\"Training dataset size: {num_train_examples}\")\n",
    "print(f\"Test dataset size: {num_test_examples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 32\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "\n",
    "def preprocess_image(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "#     image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    return image / 255., label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ds_train.map(preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE) \\\n",
    "    .cache() \\\n",
    "    .shuffle(num_train_examples).batch(BATCH_SIZE, drop_remainder=True) \\\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = ds_train.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for images, labels in example:\n",
    "    plt.imshow(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = ds_test.map(preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE) \\\n",
    "    .cache() \\\n",
    "    .batch(BATCH_SIZE, drop_remainder=True) \\\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model\n",
    "\n",
    "We now build a simple convolution neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Pretrained Models\n",
    "\n",
    "Instead of training the full model, it is generally a good practice to use a pretrained network as a base model and add your layers on top. \n",
    "This allows us to reduce the training times and leverage on what base model has learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 32\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not use the preprocessing we were using earlier, because we now use a pre-trained network as our feature extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ds_train \\\n",
    "    .cache() \\\n",
    "    .shuffle(num_train_examples).batch(BATCH_SIZE, drop_remainder=True) \\\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = ds_train.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for images, labels in example:\n",
    "    plt.imshow(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = ds_test \\\n",
    "    .cache() \\\n",
    "    .batch(BATCH_SIZE, drop_remainder=True) \\\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Resnet50 + GAP + BN + DENSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.ResNet50(input_shape=(IMG_SIZE, IMG_SIZE, 3), include_top=False)\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_model(base_model):\n",
    "    inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    x = tf.keras.applications.resnet.preprocess_input(inputs)\n",
    "    x = base_model(x, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    outputs = Dense(NUM_CLASSES)(x)\n",
    "    _model = tf.keras.Model(inputs, outputs)    \n",
    "    return _model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_strided_slice_4  [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_BiasAdd_4 (Tenso [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 1, 1, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 23,859,466\n",
      "Trainable params: 267,658\n",
      "Non-trainable params: 23,591,808\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_model = get_pretrained_model(base_model)\n",
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a higher learning rate for BN\n",
    "lr = 1e-2\n",
    "resnet_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.001)\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logdir, update_freq='epoch', profile_batch=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 1s 12ms/step - loss: 4.9519 - accuracy: 0.1133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.951874732971191, 0.11328125]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "  2/390 [..............................] - ETA: 1:10 - loss: 2.8645 - accuracy: 0.2656WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0118s vs `on_train_batch_end` time: 0.3508s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0118s vs `on_train_batch_end` time: 0.3508s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 6s 15ms/step - loss: 1.2871 - accuracy: 0.5824 - val_loss: 1.1245 - val_accuracy: 0.6148\n",
      "Epoch 2/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 1.0319 - accuracy: 0.6449 - val_loss: 1.0881 - val_accuracy: 0.6359\n",
      "Epoch 3/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9510 - accuracy: 0.6708 - val_loss: 1.0954 - val_accuracy: 0.6336\n",
      "Epoch 4/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.8878 - accuracy: 0.6941 - val_loss: 1.1245 - val_accuracy: 0.6340\n",
      "Epoch 5/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.8471 - accuracy: 0.7064 - val_loss: 1.2138 - val_accuracy: 0.6289\n",
      "Epoch 6/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.8082 - accuracy: 0.7206 - val_loss: 1.1524 - val_accuracy: 0.6410\n",
      "Epoch 7/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7673 - accuracy: 0.7335 - val_loss: 1.2191 - val_accuracy: 0.6240\n",
      "Epoch 8/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5624 - accuracy: 0.8013 - val_loss: 1.1681 - val_accuracy: 0.6572\n",
      "Epoch 9/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4742 - accuracy: 0.8331 - val_loss: 1.2093 - val_accuracy: 0.6520\n",
      "Epoch 10/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4292 - accuracy: 0.8496 - val_loss: 1.2845 - val_accuracy: 0.6541\n",
      "Epoch 11/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3902 - accuracy: 0.8608 - val_loss: 1.3575 - val_accuracy: 0.6569\n",
      "Epoch 12/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3613 - accuracy: 0.8716 - val_loss: 1.4213 - val_accuracy: 0.6479\n",
      "Epoch 13/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3069 - accuracy: 0.8928 - val_loss: 1.4637 - val_accuracy: 0.6445\n",
      "Epoch 14/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.2848 - accuracy: 0.9010 - val_loss: 1.5532 - val_accuracy: 0.6494\n",
      "Epoch 15/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.2722 - accuracy: 0.9046 - val_loss: 1.5886 - val_accuracy: 0.6484\n",
      "Epoch 16/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.2554 - accuracy: 0.9104 - val_loss: 1.6437 - val_accuracy: 0.6440\n",
      "Epoch 17/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.2430 - accuracy: 0.9148 - val_loss: 1.6392 - val_accuracy: 0.6462\n",
      "Epoch 18/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.2275 - accuracy: 0.9206 - val_loss: 1.7446 - val_accuracy: 0.6442\n",
      "Epoch 19/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.2132 - accuracy: 0.9252 - val_loss: 1.7993 - val_accuracy: 0.6391\n",
      "Epoch 20/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.2035 - accuracy: 0.9295 - val_loss: 1.8513 - val_accuracy: 0.6367\n",
      "Epoch 21/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1923 - accuracy: 0.9323 - val_loss: 1.8821 - val_accuracy: 0.6406\n",
      "Epoch 22/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1835 - accuracy: 0.9361 - val_loss: 1.9626 - val_accuracy: 0.6392\n",
      "Epoch 23/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1714 - accuracy: 0.9410 - val_loss: 1.9975 - val_accuracy: 0.6384\n",
      "Epoch 24/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1640 - accuracy: 0.9430 - val_loss: 2.0484 - val_accuracy: 0.6415\n",
      "Epoch 25/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1607 - accuracy: 0.9433 - val_loss: 2.1056 - val_accuracy: 0.6382\n",
      "Epoch 26/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1488 - accuracy: 0.9479 - val_loss: 2.1385 - val_accuracy: 0.6411\n",
      "Epoch 27/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.1413 - accuracy: 0.9526 - val_loss: 2.2159 - val_accuracy: 0.6373\n",
      "Epoch 28/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1396 - accuracy: 0.9513 - val_loss: 2.2232 - val_accuracy: 0.6360\n",
      "Epoch 29/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1358 - accuracy: 0.9525 - val_loss: 2.2928 - val_accuracy: 0.6376\n",
      "Epoch 30/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1263 - accuracy: 0.9561 - val_loss: 2.3630 - val_accuracy: 0.6387\n",
      "Epoch 31/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1239 - accuracy: 0.9565 - val_loss: 2.4037 - val_accuracy: 0.6357\n",
      "Epoch 32/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1181 - accuracy: 0.9594 - val_loss: 2.4197 - val_accuracy: 0.6364\n",
      "Epoch 33/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1123 - accuracy: 0.9619 - val_loss: 2.4402 - val_accuracy: 0.6366\n",
      "Epoch 34/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1102 - accuracy: 0.9622 - val_loss: 2.4971 - val_accuracy: 0.6369\n",
      "Epoch 35/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1067 - accuracy: 0.9639 - val_loss: 2.5203 - val_accuracy: 0.6344\n",
      "Epoch 36/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1009 - accuracy: 0.9656 - val_loss: 2.5921 - val_accuracy: 0.6345\n",
      "Epoch 37/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0952 - accuracy: 0.9673 - val_loss: 2.6273 - val_accuracy: 0.6335\n",
      "Epoch 38/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0953 - accuracy: 0.9673 - val_loss: 2.7166 - val_accuracy: 0.6352\n",
      "Epoch 39/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.0947 - accuracy: 0.9683 - val_loss: 2.7285 - val_accuracy: 0.6332\n",
      "Epoch 40/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0905 - accuracy: 0.9683 - val_loss: 2.7433 - val_accuracy: 0.6348\n",
      "Epoch 41/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0856 - accuracy: 0.9712 - val_loss: 2.8134 - val_accuracy: 0.6356\n",
      "Epoch 42/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0860 - accuracy: 0.9712 - val_loss: 2.8007 - val_accuracy: 0.6323\n",
      "Epoch 43/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0831 - accuracy: 0.9716 - val_loss: 2.8472 - val_accuracy: 0.6330\n",
      "Epoch 44/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0803 - accuracy: 0.9732 - val_loss: 2.8562 - val_accuracy: 0.6348\n",
      "Epoch 45/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0769 - accuracy: 0.9734 - val_loss: 2.9332 - val_accuracy: 0.6298\n",
      "Epoch 46/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0738 - accuracy: 0.9747 - val_loss: 2.9238 - val_accuracy: 0.6343\n",
      "Epoch 47/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0722 - accuracy: 0.9758 - val_loss: 3.0058 - val_accuracy: 0.6317\n",
      "Epoch 48/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0698 - accuracy: 0.9761 - val_loss: 2.9822 - val_accuracy: 0.6348\n",
      "Epoch 49/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0738 - accuracy: 0.9748 - val_loss: 2.9931 - val_accuracy: 0.6308\n",
      "Epoch 50/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.0699 - accuracy: 0.9768 - val_loss: 3.0309 - val_accuracy: 0.6305\n",
      "Epoch 51/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0671 - accuracy: 0.9772 - val_loss: 3.0360 - val_accuracy: 0.6306\n",
      "Epoch 52/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0685 - accuracy: 0.9769 - val_loss: 3.1016 - val_accuracy: 0.6299\n",
      "Epoch 53/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0670 - accuracy: 0.9770 - val_loss: 3.1105 - val_accuracy: 0.6309\n",
      "Epoch 54/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0667 - accuracy: 0.9773 - val_loss: 3.1475 - val_accuracy: 0.6293\n",
      "Epoch 55/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0610 - accuracy: 0.9801 - val_loss: 3.2003 - val_accuracy: 0.6324\n",
      "Epoch 56/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0606 - accuracy: 0.9799 - val_loss: 3.2344 - val_accuracy: 0.6319\n",
      "Epoch 57/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0609 - accuracy: 0.9797 - val_loss: 3.2419 - val_accuracy: 0.6317\n",
      "Epoch 58/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0612 - accuracy: 0.9799 - val_loss: 3.2307 - val_accuracy: 0.6329\n",
      "Epoch 59/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0593 - accuracy: 0.9802 - val_loss: 3.3187 - val_accuracy: 0.6310\n",
      "Epoch 60/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0611 - accuracy: 0.9795 - val_loss: 3.3004 - val_accuracy: 0.6314\n",
      "Epoch 61/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0581 - accuracy: 0.9803 - val_loss: 3.3125 - val_accuracy: 0.6317\n",
      "Epoch 62/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.0567 - accuracy: 0.9811 - val_loss: 3.3204 - val_accuracy: 0.6318\n",
      "Epoch 63/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0565 - accuracy: 0.9817 - val_loss: 3.3391 - val_accuracy: 0.6326\n",
      "Epoch 64/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0517 - accuracy: 0.9833 - val_loss: 3.4011 - val_accuracy: 0.6298\n",
      "Epoch 65/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0540 - accuracy: 0.9822 - val_loss: 3.4420 - val_accuracy: 0.6297\n",
      "Epoch 66/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0522 - accuracy: 0.9822 - val_loss: 3.3670 - val_accuracy: 0.6284\n",
      "Epoch 67/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0527 - accuracy: 0.9829 - val_loss: 3.3976 - val_accuracy: 0.6285\n",
      "Epoch 68/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0515 - accuracy: 0.9826 - val_loss: 3.5109 - val_accuracy: 0.6288\n",
      "Epoch 69/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0501 - accuracy: 0.9832 - val_loss: 3.4880 - val_accuracy: 0.6287\n",
      "Epoch 70/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0493 - accuracy: 0.9842 - val_loss: 3.5524 - val_accuracy: 0.6307\n",
      "Epoch 71/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0470 - accuracy: 0.9836 - val_loss: 3.5136 - val_accuracy: 0.6301\n",
      "Epoch 72/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0475 - accuracy: 0.9845 - val_loss: 3.5094 - val_accuracy: 0.6294\n",
      "Epoch 73/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0473 - accuracy: 0.9842 - val_loss: 3.5739 - val_accuracy: 0.6322\n",
      "Epoch 74/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.0483 - accuracy: 0.9839 - val_loss: 3.5885 - val_accuracy: 0.6322\n",
      "Epoch 75/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0468 - accuracy: 0.9840 - val_loss: 3.6374 - val_accuracy: 0.6302\n",
      "Epoch 76/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0454 - accuracy: 0.9855 - val_loss: 3.6393 - val_accuracy: 0.6290\n",
      "Epoch 77/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0465 - accuracy: 0.9844 - val_loss: 3.6366 - val_accuracy: 0.6311\n",
      "Epoch 78/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0469 - accuracy: 0.9837 - val_loss: 3.6482 - val_accuracy: 0.6337\n",
      "Epoch 79/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0468 - accuracy: 0.9848 - val_loss: 3.6589 - val_accuracy: 0.6293\n",
      "Epoch 80/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0460 - accuracy: 0.9843 - val_loss: 3.6726 - val_accuracy: 0.6315\n",
      "Epoch 81/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0463 - accuracy: 0.9845 - val_loss: 3.7625 - val_accuracy: 0.6289\n",
      "Epoch 82/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0407 - accuracy: 0.9874 - val_loss: 3.7496 - val_accuracy: 0.6343\n",
      "Epoch 83/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0457 - accuracy: 0.9847 - val_loss: 3.7470 - val_accuracy: 0.6338\n",
      "Epoch 84/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0425 - accuracy: 0.9860 - val_loss: 3.7430 - val_accuracy: 0.6339\n",
      "Epoch 85/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.0398 - accuracy: 0.9863 - val_loss: 3.7076 - val_accuracy: 0.6331\n",
      "Epoch 86/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0407 - accuracy: 0.9863 - val_loss: 3.7535 - val_accuracy: 0.6321\n",
      "Epoch 87/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0420 - accuracy: 0.9870 - val_loss: 3.8447 - val_accuracy: 0.6300\n",
      "Epoch 88/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0409 - accuracy: 0.9859 - val_loss: 3.8744 - val_accuracy: 0.6316\n",
      "Epoch 89/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0408 - accuracy: 0.9866 - val_loss: 3.9147 - val_accuracy: 0.6317\n",
      "Epoch 90/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0417 - accuracy: 0.9867 - val_loss: 3.8419 - val_accuracy: 0.6313\n",
      "Epoch 91/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0408 - accuracy: 0.9865 - val_loss: 3.8193 - val_accuracy: 0.6272\n",
      "Epoch 92/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0407 - accuracy: 0.9861 - val_loss: 3.8380 - val_accuracy: 0.6335\n",
      "Epoch 93/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0402 - accuracy: 0.9864 - val_loss: 3.8811 - val_accuracy: 0.6308\n",
      "Epoch 94/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0392 - accuracy: 0.9869 - val_loss: 3.8798 - val_accuracy: 0.6309\n",
      "Epoch 95/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0410 - accuracy: 0.9867 - val_loss: 3.9495 - val_accuracy: 0.6281\n",
      "Epoch 96/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0382 - accuracy: 0.9876 - val_loss: 3.9074 - val_accuracy: 0.6293\n",
      "Epoch 97/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.0396 - accuracy: 0.9870 - val_loss: 3.8995 - val_accuracy: 0.6262\n",
      "Epoch 98/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0384 - accuracy: 0.9876 - val_loss: 4.0261 - val_accuracy: 0.6286\n",
      "Epoch 99/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0399 - accuracy: 0.9871 - val_loss: 3.9773 - val_accuracy: 0.6272\n",
      "Epoch 100/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0377 - accuracy: 0.9877 - val_loss: 3.9820 - val_accuracy: 0.6338\n",
      "Epoch 101/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0350 - accuracy: 0.9889 - val_loss: 4.0382 - val_accuracy: 0.6324\n",
      "Epoch 102/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0352 - accuracy: 0.9874 - val_loss: 4.0372 - val_accuracy: 0.6361\n",
      "Epoch 103/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0371 - accuracy: 0.9876 - val_loss: 4.0315 - val_accuracy: 0.6314\n",
      "Epoch 104/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0343 - accuracy: 0.9891 - val_loss: 3.9972 - val_accuracy: 0.6300\n",
      "Epoch 105/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0330 - accuracy: 0.9890 - val_loss: 4.1226 - val_accuracy: 0.6313\n",
      "Epoch 106/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0383 - accuracy: 0.9878 - val_loss: 4.0850 - val_accuracy: 0.6298\n",
      "Epoch 107/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0374 - accuracy: 0.9876 - val_loss: 4.0856 - val_accuracy: 0.6313\n",
      "Epoch 108/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.0346 - accuracy: 0.9886 - val_loss: 4.0211 - val_accuracy: 0.6368\n",
      "Epoch 109/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.0347 - accuracy: 0.9888 - val_loss: 4.1493 - val_accuracy: 0.6333\n",
      "Epoch 110/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0350 - accuracy: 0.9883 - val_loss: 4.1341 - val_accuracy: 0.6350\n",
      "Epoch 111/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0326 - accuracy: 0.9890 - val_loss: 4.1637 - val_accuracy: 0.6302\n",
      "Epoch 112/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0377 - accuracy: 0.9880 - val_loss: 4.0955 - val_accuracy: 0.6292\n",
      "Epoch 113/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0322 - accuracy: 0.9899 - val_loss: 4.1426 - val_accuracy: 0.6321\n",
      "Epoch 114/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0347 - accuracy: 0.9892 - val_loss: 4.2412 - val_accuracy: 0.6322\n",
      "Epoch 115/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0349 - accuracy: 0.9882 - val_loss: 4.2123 - val_accuracy: 0.6314\n",
      "Epoch 116/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0350 - accuracy: 0.9884 - val_loss: 4.2165 - val_accuracy: 0.6354\n",
      "Epoch 117/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0324 - accuracy: 0.9897 - val_loss: 4.2895 - val_accuracy: 0.6319\n",
      "Epoch 118/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0317 - accuracy: 0.9896 - val_loss: 4.2394 - val_accuracy: 0.6325\n",
      "Epoch 119/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0324 - accuracy: 0.9892 - val_loss: 4.2409 - val_accuracy: 0.6309\n",
      "Epoch 120/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.0348 - accuracy: 0.9884 - val_loss: 4.2899 - val_accuracy: 0.6326\n",
      "Epoch 121/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0343 - accuracy: 0.9889 - val_loss: 4.3317 - val_accuracy: 0.6315\n",
      "Epoch 122/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0350 - accuracy: 0.9891 - val_loss: 4.2681 - val_accuracy: 0.6338\n",
      "Epoch 123/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0337 - accuracy: 0.9893 - val_loss: 4.2610 - val_accuracy: 0.6257\n",
      "Epoch 124/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0316 - accuracy: 0.9900 - val_loss: 4.3240 - val_accuracy: 0.6309\n",
      "Epoch 125/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0308 - accuracy: 0.9903 - val_loss: 4.3627 - val_accuracy: 0.6335\n",
      "Epoch 126/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0331 - accuracy: 0.9898 - val_loss: 4.2832 - val_accuracy: 0.6333\n",
      "Epoch 127/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0335 - accuracy: 0.9900 - val_loss: 4.3191 - val_accuracy: 0.6332\n",
      "Epoch 128/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0339 - accuracy: 0.9894 - val_loss: 4.3551 - val_accuracy: 0.6335\n",
      "Epoch 129/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0322 - accuracy: 0.9900 - val_loss: 4.4234 - val_accuracy: 0.6355\n",
      "Epoch 130/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0310 - accuracy: 0.9901 - val_loss: 4.4270 - val_accuracy: 0.6322\n",
      "Epoch 131/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0304 - accuracy: 0.9905 - val_loss: 4.3437 - val_accuracy: 0.6349\n",
      "Epoch 132/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0293 - accuracy: 0.9906 - val_loss: 4.4245 - val_accuracy: 0.6339\n",
      "Epoch 133/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0332 - accuracy: 0.9901 - val_loss: 4.3289 - val_accuracy: 0.6293\n",
      "Epoch 134/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0336 - accuracy: 0.9896 - val_loss: 4.3353 - val_accuracy: 0.6307\n",
      "Epoch 135/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0300 - accuracy: 0.9903 - val_loss: 4.4295 - val_accuracy: 0.6296\n",
      "Epoch 136/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0303 - accuracy: 0.9902 - val_loss: 4.5168 - val_accuracy: 0.6313\n",
      "Epoch 137/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0296 - accuracy: 0.9903 - val_loss: 4.4768 - val_accuracy: 0.6310\n",
      "Epoch 138/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0307 - accuracy: 0.9907 - val_loss: 4.4617 - val_accuracy: 0.6319\n",
      "Epoch 139/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0315 - accuracy: 0.9905 - val_loss: 4.4725 - val_accuracy: 0.6320\n",
      "Epoch 140/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0293 - accuracy: 0.9906 - val_loss: 4.4284 - val_accuracy: 0.6302\n",
      "Epoch 141/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0295 - accuracy: 0.9907 - val_loss: 4.5203 - val_accuracy: 0.6332\n",
      "Epoch 142/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0288 - accuracy: 0.9909 - val_loss: 4.4341 - val_accuracy: 0.6301\n",
      "Epoch 143/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0309 - accuracy: 0.9904 - val_loss: 4.4087 - val_accuracy: 0.6331\n",
      "Epoch 144/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0297 - accuracy: 0.9903 - val_loss: 4.5074 - val_accuracy: 0.6339\n",
      "Epoch 145/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0256 - accuracy: 0.9917 - val_loss: 4.6446 - val_accuracy: 0.6351\n",
      "Epoch 159/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0266 - accuracy: 0.9919 - val_loss: 4.6214 - val_accuracy: 0.6265\n",
      "Epoch 160/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0274 - accuracy: 0.9916 - val_loss: 4.7090 - val_accuracy: 0.6316\n",
      "Epoch 161/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0296 - accuracy: 0.9914 - val_loss: 4.6044 - val_accuracy: 0.6347\n",
      "Epoch 162/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0227 - accuracy: 0.9926 - val_loss: 4.5173 - val_accuracy: 0.6356\n",
      "Epoch 163/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0268 - accuracy: 0.9915 - val_loss: 4.6682 - val_accuracy: 0.6350\n",
      "Epoch 164/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0277 - accuracy: 0.9912 - val_loss: 4.6292 - val_accuracy: 0.6326\n",
      "Epoch 165/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0286 - accuracy: 0.9908 - val_loss: 4.6314 - val_accuracy: 0.6329\n",
      "Epoch 166/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0246 - accuracy: 0.9921 - val_loss: 4.6460 - val_accuracy: 0.6313\n",
      "Epoch 167/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 4.7250 - val_accuracy: 0.6349\n",
      "Epoch 168/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0273 - accuracy: 0.9915 - val_loss: 4.7205 - val_accuracy: 0.6317\n",
      "Epoch 169/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0256 - accuracy: 0.9917 - val_loss: 4.7057 - val_accuracy: 0.6303\n",
      "Epoch 170/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0282 - accuracy: 0.9911 - val_loss: 4.7160 - val_accuracy: 0.6349\n",
      "Epoch 171/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0285 - accuracy: 0.9909 - val_loss: 4.6213 - val_accuracy: 0.6299\n",
      "Epoch 172/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0275 - accuracy: 0.9913 - val_loss: 4.7265 - val_accuracy: 0.6344\n",
      "Epoch 173/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0242 - accuracy: 0.9926 - val_loss: 4.6620 - val_accuracy: 0.6320\n",
      "Epoch 174/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0258 - accuracy: 0.9925 - val_loss: 4.6862 - val_accuracy: 0.6315\n",
      "Epoch 175/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0283 - accuracy: 0.9915 - val_loss: 4.6966 - val_accuracy: 0.6310\n",
      "Epoch 176/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0265 - accuracy: 0.9916 - val_loss: 4.8409 - val_accuracy: 0.6324\n",
      "Epoch 177/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0265 - accuracy: 0.9921 - val_loss: 4.7692 - val_accuracy: 0.6348\n",
      "Epoch 178/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0257 - accuracy: 0.9919 - val_loss: 4.7732 - val_accuracy: 0.6338\n",
      "Epoch 179/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0264 - accuracy: 0.9919 - val_loss: 4.7691 - val_accuracy: 0.6343\n",
      "Epoch 180/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0253 - accuracy: 0.9921 - val_loss: 4.7727 - val_accuracy: 0.6324\n",
      "Epoch 181/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0236 - accuracy: 0.9928 - val_loss: 4.8314 - val_accuracy: 0.6328\n",
      "Epoch 182/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0274 - accuracy: 0.9916 - val_loss: 4.7396 - val_accuracy: 0.6325\n",
      "Epoch 183/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0277 - accuracy: 0.9915 - val_loss: 4.7870 - val_accuracy: 0.6348\n",
      "Epoch 184/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0236 - accuracy: 0.9924 - val_loss: 4.7538 - val_accuracy: 0.6319\n",
      "Epoch 185/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0253 - accuracy: 0.9927 - val_loss: 4.8207 - val_accuracy: 0.6337\n",
      "Epoch 186/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0258 - accuracy: 0.9917 - val_loss: 4.7922 - val_accuracy: 0.6338\n",
      "Epoch 187/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0226 - accuracy: 0.9926 - val_loss: 4.8276 - val_accuracy: 0.6338\n",
      "Epoch 188/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0307 - accuracy: 0.9907 - val_loss: 4.7669 - val_accuracy: 0.6329\n",
      "Epoch 189/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0265 - accuracy: 0.9922 - val_loss: 4.9206 - val_accuracy: 0.6335\n",
      "Epoch 190/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0269 - accuracy: 0.9919 - val_loss: 4.7883 - val_accuracy: 0.6301\n",
      "Epoch 191/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0265 - accuracy: 0.9922 - val_loss: 4.8271 - val_accuracy: 0.6310\n",
      "Epoch 192/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0252 - accuracy: 0.9922 - val_loss: 4.8189 - val_accuracy: 0.6299\n",
      "Epoch 193/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0267 - accuracy: 0.9923 - val_loss: 4.8782 - val_accuracy: 0.6303\n",
      "Epoch 194/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0237 - accuracy: 0.9928 - val_loss: 4.8569 - val_accuracy: 0.6322\n",
      "Epoch 195/200\n",
      "325/390 [========================>.....] - ETA: 0s - loss: 0.0270 - accuracy: 0.9917"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0227 - accuracy: 0.9924 - val_loss: 4.8536 - val_accuracy: 0.6302\n",
      "Epoch 198/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 4.8401 - val_accuracy: 0.6305\n",
      "Epoch 199/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0235 - accuracy: 0.9927 - val_loss: 4.9802 - val_accuracy: 0.6312\n",
      "Epoch 200/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0220 - accuracy: 0.9930 - val_loss: 4.9854 - val_accuracy: 0.6364\n"
     ]
    }
   ],
   "source": [
    "# We are going to train for 50 epochs\n",
    "history = resnet_model.fit(\n",
    "    train_ds, epochs=200, validation_data=test_ds, \n",
    "    callbacks=[reduce_lr, tb_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.style.use('seaborn')\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))    \n",
    "\n",
    "    ax1.plot(acc, label=\"Training Accuracy\")\n",
    "    ax1.plot(val_acc, label=\"Validation Accuracy\")\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Accuracy')    \n",
    "    ax1.legend(loc='lower right')\n",
    "    ax1.set_title(\"Training and Validation Accuracy\")\n",
    "    \n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    ax2.plot(loss, label=\"Training Loss\")\n",
    "    ax2.plot(val_loss, label=\"Validation Loss\")\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Loss')    \n",
    "    ax2.legend(loc='upper right')\n",
    "    ax2.set_title(\"Training and Validation Loss\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAAEVCAYAAADAcXJ8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAACDSklEQVR4nOzdd3gUVffA8e/WtE1vJEBCSIBA6B1RegBBBREholhRX8GCggUUsSAqP0V9sb4qFlREEBQbQZqg9E4IAUINIWXTy26y9fdHYDUSCISEJZvzeZ482ZnZmT1nFyZn79y5V2G32+0IIYQQQgghakTp7ACEEEIIIYSoz6SgFkIIIYQQ4jJIQS2EEEIIIcRlkIJaCCGEEEKIyyAFtRBCCCGEEJdBCmohhBBCCCEugxTULmDmzJkMHTqUoUOHEhcXR//+/R3LJSUlF32cr776irfffvuCz8nKyuKGG264zIhr1/bt2xkwYMA56xMSEvjmm2/OWf/tt98ybty48x5v6dKl3H333QA89dRTrFmz5pznZGZm0qpVq2pjO3r0KNu2bQPg999/Z9q0adXucykOHTpE165d+fDDD2v1uEKIq4ec4xvmOX78+PH8+OOPtXY8UbfUzg5AXL4XX3zR8XjAgAHMmTOHrl27XvJx7rjjjmqfExoays8//3zJx3aGUaNGsXTp0nNOrMuXL+fmm2++qGPMmTPnsmJYtWoVFouFbt26ER8fT3x8/GUd79+WLVvGY489xrfffst//vOfWj22EOLqIOf4qjWEc7yoP6SF2sVt2bKFhIQEJk+ezJQpUwBYvHgx119/PYMHD+b2228nPT0dgHnz5vHss88CFd+MP/vsM2677Tauu+46nnjiCex2O6dOnaJNmzZAxbf8Rx99lOnTpzNkyBCGDRvG4cOHATh16hQJCQnEx8fz/PPP8+CDD7J06dJz4svJyeG+++5j6NChDBgwgM8++8yxbcCAAXz77beMHj2aa6+9ltdee82x7f3336dv377cfPPNbNy4scrchw0bRkpKCidPnnSsO3XqFAcOHOD6669n9erV3HjjjQwZMoRRo0Zx4MCBc47xzxaCJUuW0L9/f2688UaWL1/ueI7NZuPFF19kyJAhDBgwgCeffBKz2cyaNWv46KOP+PLLL3nttdcqtYoUFBTw2GOPOd63//3vf47jtWrVih9++IGRI0dy7bXX8vnnn1eZn9VqZdWqVYwaNYpGjRqxZ88ex7aysjKeeuopBgwYwPXXX+/I4Xzrn3nmGd5//33H/v9cHjBgAO+++y5Dhgzh9OnTHD16lNtuu43rr7+e+Pj4Sn98N2zYwPDhwxkyZAgPPvggBQUFPProo3z66aeO5xw8eJCePXtisViqzEsIcfHkHO+65/gL+fLLLxk2bBhDhw7loYceIi8vD4CtW7dy8803M2zYMK6//np+++23C64XtUcK6gYgOTmZsWPH8uabb5Kbm8tLL73EZ599xsqVK4mIiKhUSP3TmjVr+Oyzz0hMTGTz5s3s3LnznOesX7+ecePGkZiYSI8ePfjiiy+Aim/9Xbp04ffff+e666477wnxgw8+oEmTJqxYsYIvvviCN998k4yMDMf2bdu2sWjRIr7//nu++uorMjMzSU1N5fPPP+f7779nyZIlHDx4sMpj63Q6Bg4cWOnE+NNPPzFo0CDc3d155plnePnll0lMTGTAgAG8/vrr530PCwsLeeWVV/jkk0/46aefyM7Odmz7/fff2b59Oz///DO//fYb+/fv59dff2XAgAHEx8dz55138swzz1Q63ty5c/H19SUxMZFvvvmGhQsXsn37dsf21NRUfvjhB95//33mzp2L1Wo9J6YNGzbQoUMHvLy8uPHGG/nhhx8c2+bPn+844X/22WfMmjWLrKys866vTlZWFomJiYSHhzNnzhz69+/Pb7/9xuzZs3n22Wcxm80YDAamTJnCW2+9RWJiIhEREbzzzjvccMMNlYruVatWMXjwYNRquUAmRG2Qc7xrnuPPZ/fu3Xz66acsWLCAFStWEB4ezptvvgnA66+/zrRp0/j111/54IMPWLVq1QXXi9ojBXUD4O7uTq9evQAIDAxkx44dNGrUCICuXbuSlpZW5X5Dhw7F3d0dT09PmjVrVukkeFZ0dDRt27YFoE2bNo7nbN++3dEPLz4+npCQkCpf47nnnmPGjBkANG3alODgYE6dOuXYfuONN6JSqQgNDSUwMJCMjAy2bdtGt27dCAoKQqVScdNNN50391GjRvHTTz85lpcvX86oUaNQq9Vs3LiRjh07Vvs+AOzZs4fIyEiio6MBGDlypGPbkCFD+P7779FoNLi5udGuXbsLHgvgjz/+cFym9PPzIz4+nr/++suxfcSIEQDExcVRXl5Obm7uOcdYtmyZI/f4+HjWrl2LyWQCKv4IDh8+HIBGjRqxbt06QkNDz7u+Ov369XM8fv/997nvvvsA6NKlC+Xl5ej1enbu3ElYWBgtW7YE4Mknn2TatGn07duXkydPcvToUaCioB42bFi1rymEuDhyjnfNc/z5rFu3jiFDhhAYGAjArbfe6jh2YGAgP/zwA0eOHKFZs2aOQvt860XtkSaiBsDX19fx2Gq1Mm/ePFavXo3VaqW0tJSoqKgq99PpdI7HKpWqym/Q3t7eVT6nqKgIHx8fx7bzFW379u1ztFgolUr0ej02m+2CMRQWFlZ63X++zr/16tWL8vJy9uzZg1KppKysjB49egCwYMECli1bhslkwmQyoVAoznucf7/mP9/TvLw8Xn75ZZKTk1EoFOTk5HDXXXed91hn9/ln3D4+PpVaRM6+lkqlAqj0npyNZ926dZVO0GVlZaxbt47BgweTn59fKV4vLy+A866vzj/z3bBhAx988AH5+fkoFArsdjs2m438/PxKOWm1Wsfjs11DRo8ejV6vp3v37hf1ukKI6sk53vXO8dUd+59fYHx8fBwF+ezZs/nggw+45557cHd354knnmDo0KHnXS9qj7RQNzC//vorq1ev5quvviIxMZFHH320Tl7Hy8ur0t3ner2+yuc9+eSTDBkyhMTERFasWIG/v3+1x/bx8aG4uNixnJ+ff97nKpVKRowYwc8//8wvv/zCiBEjUCqV7Ny5k48//pgPPviAxMREZs2adUmveba/GsBbb72FWq3mp59+YsWKFfTt27faHIKCgigoKHAsFxQUEBQUVO1+Z53NZfv27Y6ft956y9Htw9/fv9L7kpmZidFoPO96pVJZ6YT+z9j+yWw2M3nyZB566CESExNZvny544/Uv49tNBrJzMwEYPjw4axYsYLExESGDBmCUimnHiHqgpzjXeMcX9NjBwUFMWPGDNavX8/zzz/PtGnTKC0tPe96UXvkr1oDk5ubS+PGjR3Fz6+//lon/6nat2/PypUrAVi7dm2lb+b/jicuLg6FQsGyZcswGo3VxtO5c2d27NhBXl4eVqu1Uv+5qtx8882sWbOG1atXO+78zsvLIzAwkLCwMIxGI0uXLsVgMJy3laBdu3YcO3aM48ePAxXdLf6ZQ4sWLdBqtaSkpLBr1y5HDmq1utJJ+qy+ffuyaNEiRywrV66s1K2iOsuWLWPQoEGV1l177bVs3bqV/Px8BgwYwA8//IDdbkev1zNy5Ejy8vLOuz44OJiUlBQA0tLS2LVrV5WvazQaMRgMjpuWvvjiCzQaDaWlpXTp0gW9Xs/evXuBiq4h7733HgDXXHMNBQUFLFiwgOuvv/6i8xRCXBo5x7vGOf5C+vXrx++//+74ovHtt9/St29fzGYz48ePd3wWcXFxqNVq7HZ7levPto6L2iEFdQNzww03UFBQQP/+/ZkyZQqPP/44mZmZ1X57v1RPPvkkK1euZOjQoWzatImOHTtWebntscce48EHH+TGG2/EYDAwduxYpk2bVumu7X+LjY0lISGBm2++mVGjRtG5c+cLxtKsWTNCQkIIDg4mMjISgOuuu46QkBD69u3Lvffey9133423tzeTJk2q8hgBAQE8/fTT3H333dxwww2VLqHee++9fPvttwwePJivv/6ap59+mkWLFvHbb7/Rv39/vv3223NaiR5//HGKiooYOnQod9xxBw8++CDt27e/YB5nHTlyhKNHj9KzZ89K6z08POjevTu//PILd999N4GBgfTv35/x48fz9NNP07hx4/OuHzNmDOnp6QwePJg333yTIUOGVPnaPj4+TJgwgRtvvJGRI0cSERHBoEGDmDBhAna7nXnz5jlapA4ePMjjjz8OVFzWHDp0KBaLhS5dulxUnkKISyfn+Pp/jv+n//u//3OMOT506FA+++wz2rdvzwMPPMDtt9/O0KFDKS4u5vHHH0ej0TB69Gjuvvtuhg0bxvjx43nuuefQ6XRVrnd3d7/keMT5Kex2u93ZQQjXZLfbHSfYW265hYceeuicVlXRcHz88cfk5+fz1FNPOTsUIUQtkHO8EH+TFmpRJ15//XXHZARnW1TP3ikuGp68vDy+++47brvtNmeHIoSoBXKOF6IyaaEWdSI7O5unnnqK9PR0lEol//nPfy565irhWr799ls++ugjHnroIcaMGePscIQQtUDO8UJUJgW1EEIIIYQQl0G6fAghhBBCCHEZ6v3ELnr9ucPVXAx/f0/y8w21HM3Vw9XzA9fP0dXzA9fPsbr8goO9z7vNVck5u2qunh+4fo6unh+4fo6Xc85usC3UarVrj7/o6vmB6+fo6vmB6+fo6vldSa7+Xrp6fuD6Obp6fuD6OV5Ofg22oBZCCCGEEKI2SEEthBBCCCHEZZCCWgghhBBCiMsgBbUQQgghhBCXQQpqIYQQQgghLoMU1EIIIYQQQlwGKaiFEEIIIYS4DPV+YhchhLiSDGVmcovKyS0sI7eo4kcB3NynOWqVa7VRGI1GnnnmGXJzcykvL2fixIn079/fsX3jxo3MnTsXlUpFnz59mDRpkhOjFUKIC7Pb7RwpPM4efRL9m15LgLt/rR1bCmohRINltdkoKjVjKDNjKLdgKLM4fhcbTBQZzBSXmig0mCgqrfgpM1nPOY5apWRglyYE+Lg7IYu6s3btWtq2bcv9999Peno69957b6WCetasWXz66aeEhoYybtw4hgwZQkxMjBMjFkJcqnnz3uLgwQPk5eVSVlZGeHhjfHx8mT37/6rdd+bMaUyfPhM3t3PPfbm5OXz66Uc89dSzNY5t9Ogb+fLLRXh6etb4GAAWm4Wd2XtZm7aBk8XpAMT4NZeCWgjRsNntdmx2OzabHbPFjtlqw2KxYbHaMFtslFuslJVbMZZbMJosGM88Lio1kV9cTn5JOQXF5RSVmrBfxOspFQq8PTUE+3kQ4O1GgK87gT5//4QGeODtqa3zvK+0YcOGOR5nZGQQGhrqWE5LS8PX15ewsDAA+vbty6ZNm6SgFqKeeeSRxwH49defOHr0CA8/PPmi933xxVfPuy0wMOiyiunaUGIu5c/0zaw/tZFCUzEKFHQMbkv/ptcR4xdVq68lBbUQ4qpiLLdwOqeU9JxSTulLSNeXcjq3FGO5BZvNjtVmx34xVfAFaNRK/HVutGjqh59Oi5e7Bk93NZ5uajzO/NZ5aPDx0uLjpUXnoUGpUNROgvVQQkICmZmZfPjhh451er2egIAAx3JQUBBpaWnOCE8IUQdeeeUF1GoNRUUFTJ8+kxdffA6LxURxcSmPP/4kbdq0dbQgv/XWHIKCgjl48ABZWZk8//wsfHx8eO65p/n00wWMHTuSESNG8ddfGzCZTLzzzvvYbHaee+4pysvL6d9/IIsXf8vixcurjaukpIRXXnmBkpJiLBYLkyc/SatWsbz99v+RknIAq9XKzTePpkf/3jw080EK0nJR2BX0HtKPiQmTCPIIqPY1akIKaiFErbPZ7GTlG0jLLiEtu4T84nIMZRZKyswYyiyUGiu6WFQUxpULZKvt3Go50Med8EAvlEoFSqUClULheKxRKVGrlWhUCtRnHrupVXi4qXB3qyiO3bVqPNxU+Hhp8fd2w9NNjaIBF8iX6ttvv+XAgQM8+eSTLF++HIVCgb2KbzUX8576+3uiVqtqFEdwsHeN9qsvXD0/cP0cLze/+T/t56896bUUTYXeHRpz741x1T7P29sdT0+tIwd3dw1BQUG88cZrHDt2jNtvv41BgwaxadMmvvnmG+bNm4dKpSQoSIe7uwa1GhYs+IKFCxfyxx8rueuuu1CrlWeOZ6ddu9Y89tgkHn/8cQ4fTiIjI4PWrVvx3HPP8fXXX6NUKs55/84e38vLy7Fu0aIv6N69Cw888AD79u3j9ddf591332XLlo2sWrUKs9nMwsXfMm/rR+QcyODZj1/m+uh+JP68gtYRkdW+DzX9DKWgFkJUyWqzkXqqkIw8A6VGMyVnfkqNFgxlZlQqJW4aFW5aFVp1xWOTxUZadgnp+hJMFts5x1QowMtdg5e7Gn9vN9zc1FjMZ/okn6nF3DUqwoN0NA72onGwF+GBXni4yanKGZKSkggMDCQsLIzWrVtjtVrJy8sjMDCQ0NBQcnJyHM/NysoiODi42mPm5xtqFEtwsDd6fXGN9q0PXD0/cP0cayM/o8GE1XqZl+CqOObFxFVcXIbhH88tKzPTrFmLM8vuLF/+M59++ikGQxnu7u7o9cVYrTZyckooKzPTokUcen0xHh6+5OTkk5dXisViczyvWbNY9PpifHwCOH1az/79KXTu3BW9vpgOHbpjtX58Tpxnj28w/P33ZOfO3dx5533o9cU0atSMI0eOYjarCA9vyn333U+ffv054J+OvjSf8CZN+P3tn7D0N9K//6Bq34fqPsMLFdvyV0oI4WC2WNl/PJ+dB/XsTs2hxGi+5GOolArCg7yICNHR9MxPkJ8HXu4a3N1UlbpOuPof2Ppu+/btpKen8+yzz5KTk4PBYMDfv+ImniZNmlBSUsKpU6do1KgRa9eu5Y033nByxELUb2MGxDBmwNVzH4JarQHgu+++ISgohP/+9202bNjCu+++fc5zVaq/rzxVdQXr3O12zv45UCovboQkm92G1W7Dbj+3webNN/9LSsoB3ln0NseOHuWWqXdy3/uvcfjQIX7/fQUrVvzCW2+9d1GvUxNSUAvRwNjsdkqMZgpLTBSWVNygV1hiIi27hL1Hcyk/M4qFr05L/06NiW7sg85Dg5eHBt2ZHw83NTabHZPZSrnZRrnZislsRalQ0CjQ0+WGj2uoEhISePbZZxk3bhxlZWU8//zz/PDDD3h7exMfH88LL7zAlClTgIobGKOiavcmHyHE1aGwsIDo6BYA/PHHWiwWy2UfMzy8CSkpB+jffxCbN288Z/vJolMYLWV8d3AZxRjILcsjv6yAdPfTvLn8be7zfwBdrpaoqGgyMk7z55/rce/sh/I6X1QHlAzx78v3S77j1lsTaNUqlnvvveOyY74QKaiFqOfsdjvFRjPZeUay8g1k5RvJPvO71GjGYrVhsdqx2ip+Wyy2845sEeLnQedOwXRuGUzzcJ8L3oinPNNn2dO1RooT/+Du7s6bb7553u3dunVj0aJFVzAiIYQzDB06nFmzZvLXX+u48cZRrFq1kl9+qf4GwgsZNuxGpk17gocffoBu3XpUasFOzj3IR3s/x2AxsvD/5oNSgUqholm3llxzfT/WfPYLs555DiVKRk0Yh1KnZu22taQuPYxW68bto+4gLDSMpKQ9rF69Eo1Gw/DhN13u23BBCntV7fL1SE0vF7v6pWZXzw9cP8d/52cst3BKX0JmnoHsfOPfPwUGjOVVj43s7alBo1KiOnvDnkqBSqXE20ODn7cbfl5afHVu+OncCPZzp1GA5xW9Wa+hfYZVbW9o5JxdNVfPD1w/R1fPD2o3x8zMDE6cOE6PHr1IStrL/Pn/Y+7cdzmUn8r7e+YDcFurW4j0aUqAux9a1d9DkxaUF7IhfTN/pm+mxFyKAgUKhQIPtTtTu0wixLP6+zlqkp/0oRaiHrFYbeQVlXFMX0rSoWxOZpeQllVCdoHxnOdq1EpC/DwIbupBaIAHof6ehPhX/Pb3dkOplJEshBBCXH28vHQsWvQ1n3/+MXY7TJ48lSMFx/lg7+fY7XYeaH83cYGtqtzXz82XG5sPYWjkALZn72Fd2p/ojTk82O7uGhfTl6tOC+rZs2ezZ88eFAoF06dPp3379o5tq1at4oMPPkCr1TJ8+HDuuOMOkpKSmDhxIpGRFcOatGzZkhkzZtRliEI4TYnRzOG0Ao5mFJFTWEZuYRk5hUYKS86dbETnoaFNM3+ahugIC/Qi1N+DEH9PfHXaBj0+shBCiPrJ29ubuXPfdSyfKErjv7s+xmKzMKHt+PMW0/+kUWnoFdaVno26YLPbUClrNiRnbaizgnrr1q2cOHGCRYsWkZqayrRp01i8eDEANpuNl19+mWXLluHn58f999/PoEGDMBgMDBkyhGefde7MOkJcjhKjmfzichSKihn2FAoqWortcDK7hEMnCziYls8pfWml/ZQKBQE+brSK8CPQx52opn4EemmJCPXGT6eVcZOFEEJcdQrLi1ApVHio3Wtc0KaXZPDu7k8ot5ZzT9w4OgRXP272PykUFX2snanOCupNmzYxaNAgAGJiYigqKqKkpASdTkd+fj4+Pj6OWbZ69uzJxo0bHcMxCVGf5BaWcehUAYdPFXI4rYD0nNJq99GqlbSO9KdVUz9imvgS6u+Jn7cW1T+GDmoI/fGEEELUTyaria8OLGZH9h7HOjeVFk+1Jx5qd/zcfAnXNSLcqxGNdWGEeoWgUaod++YY89Abc9Ebc/j9xDqMljLGtx5Dl9AOzkrpstRZQZ2Tk0Nc3N/fMAIDA9Hr9eh0OgICAigtLeX48eM0btyYLVu20L17d9zc3NixYwcTJkzAaDTyyCOP0LNnzwu+jsy6dX6unh9c+RztdjtZeQb2peaw70gO+47kkvOPvs1uWhUdWgTRJMQbu92OzV6xj81mx2a30zhYR9vmQcQ09UOjrn5oOfkM6z9Xz08I0fDkleXzv71fkFZymqa6cAI9AjCYjRgtRgwWI/nlBZwuzSQ576BjH6VCSbBHEGWWMgpNRecc87ZWo+gR1uVKplGr6qyg/vfgIXa73XHJWqFQ8NprrzF9+nS8vb1p0qQJALGxsUyaNImBAwdy7Ngx7rnnHlauXIlWqz3n+GfJrFtVc/X84MrkaLHaOJ1TyvHMYg6nFZByMp/conLHdp2Hhs4tg2nRxJeWTf1oGqK7qDGYC/Krb8WWz7D+k1E+hBCu5nD+UT5JWkCJuZTe4d0Z03IkauW55aTBbOB0aRbpJRmcLskgvSSTTEM2Hmp3WvrHEOwR6PgJ14UR4hnkhGxqT50V1P+eljY7O5ugoL/frO7du/PNN98A8Oabb9K4cWOio6OJjo4GICoqiqCgILKysmjatGldhSmEg91uJ11fyuH0Qk5kFnMiq5h0fQmWf0wD6+WupnPLYGIj/IiN9Cc8yEtuChRCCFFvPfDA3UyZ8gytWsU61n344bv4+fmRkFB5MpSVqeuZPHYi7af1xWuTjb5396xUTB89msrcuXN4993/4anxJMYvihi/vyd8Ki0tYf/+JLp36smCBZ8T1qkFbSPb1SjuX3/9iaNHj/Dww5NrtH9tq7OCunfv3sybN4+EhASSk5MJCQlBp9M5tk+YMIE5c+bg7u7O2rVrueeee1iyZAkGg4E777wTvV5Pbm4uoaGhdRWiEBSUlLP/WB7Jx/NIPp5PYanJsU2tUtAkWEdkI28iQ71pHu5DkxCdFNBCCCFcRnz8UFavXlmpoF63bg3vvvuRY9loKWNZ6s/8dXorCuDRjvfTon/0Jb/WwYMpbN26me7dezJ+/N21EP3Vo84K6s6dOxMXF0dCQgIKhYKZM2eydOlSx5S1Y8aM4Z577sHDw4PJkycTEBBAfHw8U6dOJTExEZPJxAsvvHDB7h5CXCqT2cqhUwUkHc1j//E80v8x0oaPl5aecaHERvjTrJE34UFeMoW2EEIIlzZwYDwTJ05g4sRHAUhJOUBISAg2m41HHnmQwvIickpzCb+5JS2bt+So2oMW/tE8/PADPPHEU+h03syY8Qw6nTcREZGO4y5c+BXr1q3GZrPRq1dv7r33AebOnYPBUErTphEkJe2lX7+B9OjRizlzXuH06XRMJhMTJvyH7t17MnbsSEaMGMVff23AZDLxzjvv4+npVW0+q1f/zqJFX6NSqWjVqjWTJ0/l0KEU3nzzdTQaDVqtlhdffJWMjPRz1l1ON7w6HYd66tSplZZjY//+9jN48GAGDx5cabuvry8ff/xxXYYkGhi73U56Tin7j+WRdCyPQ2kFmC02oGKkjbZRAbRpFkBcVABNgr1kaDohhBBOszT1Z3Zl76vVY3YKaceomBvOuz0gIJCwsHCSk5No06Yta9b8Tnz8UHYd2422pz/eYb7Ydrnhe1DDK/c/ybUzfqy0/5Il3zJw4GDGjLmNr776nMOH/972/vufoFQqGTNmBGPHjmPcuPEcPXqEESNGkZS0F4Dff1+BVqvl3Xf/R06OnocffoBvv12G1WolIqIZ48bdycyZ09i+fRt9+vS7YK4Gg4H//e89PvvsGzw9PXnqqcfZuXM769ev5eabRzN06HB27NhGXl4uv/760znrmjcPr/H7LDMlCpeTX1x+pgvHud04mgTraBsVQFzzAFo28UVTwxFihBBCCFdR0e3jd9q0acv6DWu59rFh7Dm9j/R1h/C0uONm0RAQ2wyt+txeA8ePH6N//4phkjt16srmzRsBcHd35+GHH0ClUlFQUEBR0bkjewAcPHiATp0qRvcICgpGpVJRVFQIQIcOnQAIDg6ltLSk2jzS0k7SpEkEnp6eALRv34FDh1K49tq+vPHGa6SlnWTgwHgiI5tVue5ySEEt6jW73U5mnoGjp4s4crqIQ2kFnP7HONA+nhp6tgklLqqiFdpP5+bEaIUQQojzGxVzwwVbk+tK3779WbDgM3zaBlGiK+eA4TClG7K5ZcAt3Hfb/axdu4qNG/+sct+KUdyUZx5XXAHOzMxg0aKvmT//azw9PRk/fswFXl1RaWQ4m83mOJ5K9Xej179Hj6vySIrKz7Pb7SiVSrp27c4nn3zJxo0bmDXrBR5+eHKV64YM6V/ta5yPFNSi3iksNbF+z2lOZJdw8HgepWUWxzbpxiGEEEJcGr01D7O/ne+++YZGHSO4s/VYvl+xgPYx7bDb7fz55x9YrbYq942IiCQlJZnY2Nbs3LkdgIKCAvz9/fH09OTgwRQyMzMxm80oFArMZlOl/Vu3bsPOndsZNGgIWVmZKJVKvL1r1pe5adNITp06icFQiqenF7t27eSuu+7j++8X0avXtQwefD12u51Dh1I4duzIOeukoBYNQpHBxIrNJ1mz8xSmM/2gQ/w8aBcdSHS4L83DfS56HGghhBCioTNayvjp6ArWn9qEexs/cpcd5P/eeo0AnT+WEQbefvsNQkPDGD16LHPmvMKff57bSn3rrbcxY8YzrF+/lujoFgC0aNESDw9PHnroXtq168iIEaN4883XeeyxJ/jww3mEhoY59h84cDC7du3gkUcexGIx8+ST0y86/jVrficlJdmx/NZb7zFp0mNMmfIICoWS9u070qFDR4xGw5kbJ3VoNBqmT5/JoUMHz1l3ORT2i2lDv4rVdFKIhj6hRH1SYjSzYstJVu84RbnZir+3Gzf0imRI7+aYjKbqD1BPudJneD6unqNM7HIuOWdXzdXzA9fPsb7ltz/3IN+kLKGgvJBQz2Bua3ULLfybX3Cf+pbjpbqcc7a0UIurktli4/CpAvak5rJ+72nKTVb8dFpG94umT4cwNGoVvjo39C5cUAshhBC1zWQ1sSz1V9anb0SlUDEsKp7Bkf3RVDHbobh48u6Jq0ZOoZF9R/PYdySXAyfyKTdbAfD10jLquub07RiOViOjcgghhBA1cbL4FJ/v/5YsQzaNvEK5u81tNPWu+VBx4m9SUAunKi0zszU5iz/3ZXAs4+/LLKEBnrRrHkD75oG0ivCT4e2EEEKIGrLZbaw68Qc/HUvEZrfRv8m13BR9PVqVxtmhuQwpqMUVZ7PZST6Rx597M9h5KAeL1YZCAW2jAugQE0S76EBC/DycHaYQQghRb1htVn46msgefRIoQIkShUKBUqGkzFJOblkevlpvxrceS+vAls4O1+VIQS2uiLyiMg6cyCflRD77j+dRUFLR97lRgCfXtg+jV1wj/L1ljGghhBDiUhWZivk06StSC47hrnJHo1Jjt9ux2+3YsGG32+kS0oExrUai01Q/fbe4dFJQizphtdnYdzSPvUdyOXA8j6x8o2ObzkNDnw7hXNs+jOhwHxknWgghhKihY4Un+HjfAgpNRXQKbscdrcfgrpYGqitNCmpRq/KKyli/5zQb9maQX1wOgLtWRYfoQFpH+hMb6U+TEB1KKaKFEEKIy/Jn+mYWH/oRq93GyOhhDIroK41UTiIFtbhsNpudvUdyWbc7nX1Hc7HbK4ro/p0a06ttI6LCvFEpZbIVIYQQojaUW00sObScjRlb8dJ4cm/c7cQGtHB2WA2aFNTishzLKGJB4kGOZ1aM0BEV5kPfjuH0aB2Km1ZG5hBCCCFqi91uZ1vWLn488hsF5YU01YVzf7s7CfQIcHZoDZ4U1KJGSoxmlv5xhD92n8YO9GwTytAeEUSENryZ34RwdXPmzGHHjh1YLBYefPBBBg8e7Ng2cuRIvL3//n//xhtvEBoa6owwhajXTpdkkpx3kGY+EUT6ND1nopUTRWksPrScY0UnUCvVDIkcwNBmA2Xou6uEFNTiktjsdv7am8HidUcoMZoJD/Ji/OCWtIrwd3ZoQog6sHnzZg4fPsyiRYvIz8/n5ptvrlRQAyxYsMBJ0QnhGrINObyz6yNKzKUAaJRqmvlE0MKvOc18I9mRtZstmTsA6BTcjpExwwmSVumrSp0W1LNnz2bPnj0oFAqmT59O+/btHdtWrVrFBx98gFarZfjw4dxxxx3V7iOc61BaAYvXpXIkvQg3jYox/WMY1LUJapX0jxbCVXXr1s1xHvb19cVoNGK1WlGpKrp0lZaWOjM8Ieq9YlMJ7+/5lBJzKfER/TDbzBwuOEpqwTEOFxx1PK+xLoxbW9xEC/9oJ0YrzqfOCuqtW7dy4sQJFi1aRGpqKtOmTWPx4sUA2Gw2Xn75ZZYtW4afnx/3338/gwYN4uTJk+fdRzjPicxilq4/yr6juQB0bRVMwsAWBPi4OzkyIURdU6lUeHp6ArB48WL69OnjKKYBCgoKmDJlCunp6fTo0YPJkydfcJQBf39P1DWc+TQ42LW7lLl6fuD6OV5qfuUWE2+v+wC9MZebWw/ltvYjHNtKTKWk6I9wKPco4d6h9InsgfIquMFfPsOq1VlBvWnTJgYNGgRATEwMRUVFlJSUoNPpyM/Px8fHh4CAissVPXv2ZOPGjaSlpZ13H3HlZeSWsmzDMbanZAMQG+HHLX2jiW7s6+TIhBBX2qpVq1iyZAnz58+vtP7xxx/npptuws3NjYkTJ7Jy5UqGDBly3uPk5xtq9PrBwd7o9cU12rc+cPX8wPVzvNT8bHYbH+9bwOHcY3Rv1JmBjfqfs3+kNorIsCgAcnOdfzWooX+GFyq26+yrTk5ODv7+f/erDQwMRK/XAxAQEEBpaSnHjx/HbDazZcsWcnJyLriPuLKWrT/Kc59sYXtKNlFhPkxN6MhT4zpLMS1EA7RhwwY+/PBDPv7440o3IAKMGzcOnU6HRqOhX79+HDx40ElRClF/2O12Fh/6kb05+2nlH8PtsaNl/Oh6rs5aqO12+znLZ/+xKBQKXnvtNaZPn463tzdNmjSpdp/zkcuH51fT/HakZPHTxuOEBngyYURbesQ1umr/o8tnWP+5eo71Pb/i4mLmzJnD559/jp+fX6VteXl5PP3007z//vtoNBq2bdt2wdZpIUSFVSf/YH36JsK9GnF/u/GolTJGRH1XZ59gaGgoOTk5juXs7GyCgoIcy927d+ebb74B4M0336Rx48aUl5dfcJ+qyOXDqtU0P0OZmXe+3YVKqeChEXFEhOrIySmpgwgvn3yG9Z+r53g5lw+vFr/++iv5+flMnjzZsa5Hjx60atWK+Ph4evTowdixY9FqtbRp00YKaiEuILM0i1+O/c7O7L34ufkyscO9eKg9nB2WqAV1VlD37t2befPmkZCQQHJyMiEhIZX6Qk+YMIE5c+bg7u7O2rVrueeeewgLC7vgPqLufbs6lfzickZeGyVjSgshGDt2LGPHjj3v9gkTJjBhwoQrGJEQ9Y/ekMuvx39nW+Yu7NiJ8G7MnW0S8Hf3c3ZoopbUWUHduXNn4uLiSEhIQKFQMHPmTJYuXYq3tzfx8fGMGTOGe+65Bw8PDyZPnkxAQAABAQHn7COunL1HcvhzXwYRoTqG9Yp0djhCCCFEvZZfVsBvx1exKWM7NruNcK9G3NB8CO2D2ly1XSlFzdRpp52pU6dWWo6NjXU8Hjx48DmTA1S1j7gySsvMfP5bCiqlgvuGt5GxpYUQQogastltrE/fxI+pv2KymQn1DGZ4VDydQtqjVMjfV1ckveAFAN+uOkxBiYmb+zSnaYh0sxFCCCFqItuQw9cpi0ktOIaX2pNbW46kR6POqJQ1G0BB1A9SUAt2H87hr6RMIht5M6xnhLPDEUIIIeodm93G2rQ/+fHIb5htZjoEt2Vsy5vxdZP7kRoCKagbuBKjmS8SU1CrFNw3vDWqq2AWJiGEEOJqZ7fbKTKVkFuWi96Qy9a920nJOYKXxpPxrW+lc0gH6SfdgEhB3YCZLVbeX7aPwhITt/RtTpNg6eohhBBCnM+JojRWn1xPRmkWOWV5mKymSts7BbdjbKub8dbK39OGRgrqBspqs/Hhj/tJOVlA55bBDO0hXT2EEEKIqmSWZvPT0UR26/cB4KbSEuwRSLBHIIEeAQR7BBLXJJoAe4iTIxXOIgV1A2S32/nit4PsOpxD60h/HrypjXT1EEIIIf4lv6yAX4/9zqaM7dix08wnghHRQ2nhF31Od47gINeeqEpcmBTUDdDidUf4c18GzRp58/CodmhqOHW7EEIIUd9lGfT8mb6ZcqsJq82KxW7BarNitplJyU/FYrPQyDOEm6KH0j4oTvpFiypJQd3A/Lb5BCu2nKRRgCeTx3TAw03+CQghhGiY0ksy+O+u/1FiLq1ye4C7P8Oi4unRqLOMHy0uSKqpBmT9ntMsXncEf283poztiI+n1tkhCSGEEE5xqvg0/939P0rNBka3uIk2AS1RKdWolSpUioofd7WbFNLiokhB3UCs33OaL1akoPPQMGVsRwJ93Z0dkhBCCOEUacXpzNv1MQaLkXGxt9A7vIezQxL1nBTUDUDi1pMsWpPqKKbDg7ycHZIQQgjhFCeLTjFv98cYLWXcHjuaXuHdnB2ScAFSULswu93ODxuO8dPG4/jptExJ6ERjKaaFEEI0UCeK0pi3+xPKLGWMbz2GHmFdnB2ScBFSULsom83ON6sOs3rHKUL8PJiS0JFgPw9nhyWEEEI4xani08zb/TFllnLubDOW7o06Ozsk4UKkoHZBVpuNdxbtYs2OUzQO9mLK2I746dycHZYQQgjhFLnGPN7b8ylGSxl3tUmQYlrUOimoXYzVZuOjH/ez/aCeqDAfHh/TAZ2HxtlhCSGEEE5RYirlvT2fUmQqZnSLm6SYFnVCCmoXYrPb+fzXFLYf1BPXPJCJI+JknGkhhBANVrnVxAd7PyPLoGdQRF/6N73W2SEJFyWDK7oIu93Owt8P81dSJlFhPjx/Xw8ppoUQQjRYVpuV+UlfcbzoJN1COzMi+npnhyRcWJ1WXLNnz2bPnj0oFAqmT59O+/btHdu+/vprli9fjlKppG3btjz77LMkJSUxceJEIiMjAWjZsiUzZsyoyxBdxtL1R1m9s6LP9ONjOuDprqG0uMzZYQkhhBBXnN1uZ+HBpSTlptA6oCV3tB4tE7SIOlVnBfXWrVs5ceIEixYtIjU1lWnTprF48WIASkpK+PTTT1m5ciVqtZp7772X3bt3YzKZGDJkCM8++2xdheWSftl0nF82nSDE34OpYztKn2khhBANQom5lG2ZuzCYDZRbTZTbTJRbTBSWF3Ko4AgR3o2Z0PYO1Eq5YivqVp39C9u0aRODBg0CICYmhqKiIkpKStDpdGg0GjQaDQaDAU9PT4xGI76+vhw/fryuwnFZa3ae4vs/jhLg48bUhI74ymgeQgghGoDTJZl8uPczcsvyq9we5hXKQx3uxV0tMwOLuldnBXVOTg5xcXGO5cDAQPR6PTqdDjc3NyZNmsSgQYNwd3dn+PDhREVFkZyczI4dO5gwYQJGo5FHHnmEnj17XvB1/P09UatVNYoxONi7RvtdLfYc1vPVykP46dyYPfFaGgfrKm2v7/ldDFfP0dXzA9fP0dXzE8IZknIO8Nn+byizljM4sj+tA1rgpnJDq9LiptKiVWnxVHtINw9xxdRZQW23289ZVigUQEWXj48++ogVK1ag0+m46667SElJITY2lkmTJjFw4ECOHTvGPffcw8qVK9Fqted9nfx8Q43iCw72Rq8vrtG+V4tlaw8D8J8RcWixV8rHFfKrjqvn6Or5gevnWF1+UmwLcWnsdjur09bzQ+qvqJUq7o27nS6hHZwdlhB1V1CHhoaSk5PjWM7OziYoKAiAI0eO0LRpUwICAgDo2rUrSUlJjB49mujoaACioqIICgoiKyuLpk2b1lWY9ZahzMye1BzCg7xo0cTX2eEIIVzYnDlz2LFjBxaLhQcffJDBgwc7tm3cuJG5c+eiUqno06cPkyZNcmKkwpWZbRa+PbiUzRnb8dX68GD7u4j0kfpAXB3q7FpI7969SUxMBCA5OZmQkBB0uoouCY0bN+bIkSOUlZVht9tJSkqiWbNmLFmyhC+//BIAvV5Pbm4uoaGhdRVivbYtJRuL1U6vuFBHy78QQtS2zZs3c/jwYRYtWsQnn3zC7NmzK22fNWsW8+bNY+HChWzYsIHU1FQnRSpcVbnVxPbMXby18wM2Z2wnwrsJT3V7RIppcVWpsxbqzp07ExcXR0JCAgqFgpkzZ7J06VK8vb2Jj4/nvvvu484770SlUtGpUye6du1KixYtmDp1KomJiZhMJl544YULdvdoyDbtzwKgZ5tGTo5ECOHKunXr5hjy1NfXF6PRiNVqRaVSkZaWhq+vL2FhYQD07duXTZs2ERMT48yQhQuw2qwcyDvE9qzd7MnZj8lqAqBLSAfuaH0rWpXUBuLqUqfjyEydOrXScmxsrONxQkICCQkJlbb7+vry8ccf12VILiGnwMihtAJiI/wI9JW7l4UQdUelUuHp6QnA4sWL6dOnDypVxY3ger3e0XUPICgoiLS0tAseryHfSF4dV88Pqs/Rbrfzy6HVLDuQSHF5CQChumCujehG78iuNPEJuxJh1ph8hvVfTfOTgRnroc3JZ1qn46R1WghxZaxatYolS5Ywf/58x7p/33wOVNsFrSHfSH4hrp4fVJ+j3W5naerPrEnbgJfGk35NetM1tBPNfJpW/Lsq56p+j+QzrP8u50ZyKajrGbvdzqb9mahVSrq2CnF2OEKIBmDDhg18+OGHfPLJJ3h7//0H5d83n2dlZREcHOyMEEU9Z7PbWJjyPRszttHIM4RHOt2Pn5vccC/qDxmgsZ45kVVMRq6Bji2C8HSX70NCiLpVXFzMnDlz+Oijj/Dz86u0rUmTJpSUlHDq1CksFgtr166ld+/ezglU1FsWm4X5+79hY8Y2Irwb83jnh6SYFvWOVGT1zKakiu4eveJk9BMhRN379ddfyc/PZ/LkyY51PXr0oFWrVsTHx/PCCy8wZcoUAIYNG0ZUVJSTIhX1kclq4uN9C0jOO0iMXxT/aX8PHjKzoaiHpKCuR6w2G1sOZKHz0NCueaCzwxFCNABjx45l7Nix593erVs3Fi1adAUjEq6i1Gzgo71fcKTwGG0CW3F/2/Eyeoeot6SgrkeSj+dTVGqif+fGqFXSW0cIIUT9lJJ3mAUHvqOgvJDOIe25q00CaqWUJKL+kn+99cim/ZkAXCOjewghhKiHTFYzy4/8xtpTf6JUKLmx+RAGR/ZHqZBGIlG/SUFdT5SZLOw8pCfE34Pm4T7ODkcIIYS4JMfz05i7/VMyS7MI9QzmrjYJMtuhcBlSUNcTOw/pMZlt9IprJFONCyGEuOrY7Xa2Z+1mf+5BVEolaqUajUKNWqmm3Grir4wtWG1W+jS+hptjhkl/aeFSqi2ojxw5QnR09JWIRVyAY6pxGd1DCCHEVabYVMLClO/Zk7P/vM/xc/dhXKvRxAXGnvc5QtRX1RbUjzzyCL6+vowePZphw4bh4eFxJeIS/2Ast5B8PI+oMB9C/T2dHY4QQgjhsFufxMKU7ykxl9LCrzmjW9yEm8oNi92CxXb2x0rHZi0pLbQ4O1wh6kS1BfWvv/7KoUOH+O233xg/fjytW7fm1ltvpX379lciPgGczi3FbofoxtJ3WgghxNXBYDay+PCPbM3ciVqp5paYG+jX9Nrz3mDoqfWgFNedtlo0bBfVh7ply5a0bNmS3r17M3fuXCZOnEhkZCSvvPIKzZo1q+MQRUaOAYDwQC8nRyKEEKKhs9vt7M1J5rtDP1BQXkiEdxPuajOWRl7SJVE0XNUW1KdPn2bp0qX8/PPPxMTE8J///IfrrruOffv28eSTT7J48eIrEWeDlpFbCkB4kBTUQgghnCfboGfxoeUk5x1EqVAyrNkghjYbiEqpcnZoQjhVtQX1HXfcwejRo/niiy8IDf3722f79u2l28cVcjqnoqAOC5T+00IIIa68cquJxONrWH3yDyx2K7H+Lbi15QgaeYU4OzQhrgrVFtTLly9n/fr1jmJ64cKF3HTTTXh5eTFjxow6D1BARq4BnYcGb08ZYkgIIcSVY7QY2atP5qejieSXF+Dv5seoFjfQKbidDOEqxD9UW1BPmzaNdu3aOZbLysp46qmneO+996o9+OzZs9mzZw8KhYLp06dXatH++uuvWb58OUqlkrZt2/Lss89Wu09DZDJb0RcaadHEz9mhCCGEaAByjXnsyznAvpxkDhccxWq3olKoGBzZn6HNBuIm40cLcY5qC+qCggIeeOABx/I999zDmjVrqj3w1q1bOXHiBIsWLSI1NZVp06Y5+luXlJTw6aefsnLlStRqNffeey+7d+/GZDKdd5+GKjPPgN0O4dLdQwghRB1KyjnA8qMrSC/JcKxr6t2YdkFt6B7amWDPQCdGJ8TVrdqC2mw2V5rcZd++fZjN5moPvGnTJgYNGgRATEwMRUVFlJSUoNPp0Gg0aDQaDAYDnp6eGI1GfH19Wb58+Xn3aagycitG+AiTGxKFEELUkcP5R/h435fYgTaBrWgf1Ia2ga3xd/dzdmhC1AsX1eVj4sSJFBcXY7VaCQgIYM6cOdUeOCcnh7i4OMdyYGAger0enU6Hm5sbkyZNYtCgQbi7uzN8+HCioqIuuM/5+Pt7olbX7O7i4GDvGu13JRUa0wFo3TzokuOtD/ldLlfP0dXzA9fP0dXzE/Xf6ZJMPtr3BTbsTOpwH7EBLZwdkhD1TrUFdYcOHUhMTCQ/Px+FQoGfnx87d+6s9sB2u/2c5bM3MJSUlPDRRx+xYsUKdDodd911FykpKRfc53zy8w3VxlKV4GBv9Pqrf4D51JN5AHiqFZcUb33J73K4eo6unh+4fo7V5SfFtnC2/LIC3tvzKUZLGXe1SZBiWogaqragLikp4ccffyQ/Px+o6ALy/fff8+eff15wv9DQUHJychzL2dnZBAUFAXDkyBGaNm1KQEAAAF27diUpKemC+zRUGbkG3LUq/L3dnB2KEKKeS0pKQq/X079/f9566y12797NI488QteuXZ0dmnACg9nI+3vmU1BeyIjo6+neqLOzQxKi3qp6ftB/mDx5MgcPHmTp0qWUlpaydu1aXnjhhWoP3Lt3bxITEwFITk4mJCTE0XWjcePGHDlyhLKyMux2O0lJSTRr1uyC+zREVpuNzDwDYYFeMjyREOKyzZo1i6ioKLZv386+ffuYMWMG//3vf50dlnACs83C//Z9wenSTPo2uYb4iH7ODkmIeq3aFury8nJeeuklxo8fz9NPP01BQQEvv/yy4+bB8+ncuTNxcXEkJCSgUCiYOXMmS5cuxdvbm/j4eO677z7uvPNOVCoVnTp1crSQ/Hufhiw734jVZpcRPoQQtcLNzY1mzZqxaNEixowZQ0xMjHxZb4BsdhsLkhdxuOAoHYLbMrrFTfLvQIjLdFGjfBgMBmw2G/n5+fj7+5OWlnZRB586dWql5djYWMfjhIQEEhISqt2nITs7wodMOS6EqA1Go5HffvuN1atXM2nSJAoKCigudt0+7OJc2QY9XyZ/x7GiEzT3bcbdbW5Dqaj2YrUQohrVFtQjRozgu+++49Zbb2XYsGF4eXnRsmXLKxFbg/f3lONSUAshLt8TTzzBl19+yeTJk9HpdMybN4+7777b2WGJK8Bmt7EhfTM/pP6CyWamS0gHElqNQqvSODs0IVxCtQX12e4XAL169SI3N5fWrVvXeWACMnIrCurwIOnyIYS4fD179qRt27bodDpycnLo1asXnTvLjWiuLr+sgK8OLCYl/zBeak/uaH0rXUI7OjssIVxKtdd57rzzTsfj0NBQ2rRpI32trpDTuQbUKiVBvh7ODkUI4QJefvllfvvtNwoKCkhISOCrr766qJvMRf1ktVn5K30Ls7bMJSX/MG0DY3m2xxNSTAtRB6ptoW7dujXvvPMOnTp1QqP5+9JQr1696jSwhs5mt5ORW0qjAE+USvkCI4S4fMnJycyYMYOFCxdy8803M2nSJO666y5nhyVqmdVmZUvmThKPryanLA83lZbbY0fTK6ybNIgJUUeqLagPHDgAwPbt2x3rFAqFFNR1LK+oDJPZJt09hBC15uzkWevWrWPy5MkAmEwmJ0YkapPFZmFzxnZWnlhLblk+aoWKPo17MTiyv0whLkQdq7agXrBgwZWIQ/yLY4QPuSFRCFFLoqKiGDZsGAEBAbRu3ZoffvgBX1/favc7dOgQEydO5O677+aOO+6otG3kyJF4e/894+Mbb7xBaGhorccuqma320krSWefPplNGdvJLy9ArVTTt0lvBkf2w8+t+s9XCHH5qi2ox40bV+Uloq+//rpOAhIVzo7wIUPmCSFqy6xZszh06BDR0dEAxMTEMGfOnAvuYzAYePnlly94VVIaXq4ss9XMoYIj7M1JJinnAAXlhQBolBoGNL2OQRF98XXzcXKUQjQs1RbUZy8LQsWY1Js3b8bTU7oh1LWzI3yEyaQuQohaUlZWxpo1a3jnnXdQKBR07NiRmJiYC+6j1Wr5+OOP+fjjj6vcXlpaWhehivNIL8ngnV0fUWquuIrppfake6POtAtqQ+uAlnio3Z0coRANU7UFdffu3Sst9+7dm/vvv7/OAhIVTucYUCoUhAZIQS2EqB0zZswgNDSUhIQE7HY7Gzdu5LnnnuONN9447z5qtRq1+vx/KgoKCpgyZQrp6en06NGDyZMnX/DGN39/T9RqVY3iDw72rv5J9Vh1+ZksJl7d/i2lZgPXt+hPz6adaBnYHJWyZu+nMzT0z9AVuHqONc2v2oL637MiZmRkcOzYsRq9mLg49jMjfIT4e6BWyQxWQojakZOTw9y5cx3L/fv3Z/z48Zd1zMcff5ybbroJNzc3Jk6cyMqVKxkyZMh5n5+fb6jR6wQHe6PXu+6sjheT36KDyzhVlEHfJtdwQ9PrAcjLrdn76QzyGdZ/rp5jdfldqNiutqD+55BKCoUCnU7Hww8/fIkhiktRZDBTWmahZVM/Z4cihHAhRqMRo9GIh0fF2PYGg4Hy8vLLOua4ceMcj/v168fBgwcvWFCLmtmXk8z69E2EezViZPRwZ4cjhPiXagvqNWvWYLPZUCorWkrNZnOl8ahF7ZMbEoUQdWHs2LFcf/31tG3bFoD9+/fz2GOP1fh4eXl5PP3007z//vtoNBq2bdsmxXQdKCgvZMGB71Ar1dwTN06mCxfiKlRtQZ2YmMj333/P//73PwBuv/127r33XoYOHVrnwTVUjinHZcg8IUQtGj16NL1792b//v1ARZ/q6kboSEpK4vXXXyc9PR21Wk1iYiIDBgygSZMmxMfH06NHD8aOHYtWq6VNmzZSUNcym93GguTvKDUbuLXlCMJ1jZwdkhCiCtUW1J999hnvvfeeY3n+/Pncd999UlDXoYycij5xYTKpixCiloWFhREWFuZY3rt37wWf37Zt2wsW3RMmTGDChAm1Fp+obE3aBse04X0bX+PscIQQ51HtHW92u53AwEDHsk6nk6lL69jps0PmBUgLtRCibp2dPVFcfU4Wn2L5kRV4a3Xc0XqM/O0V4ipWbQt127ZtmTx5Mt27d8dut7NhwwZH/ztRN07nlhLo446btv4MhSSEqJ+kSLs6Hcg7xILkRVjtVu5sPRZvrc7ZIQkhLqDagvq5555j+fLl7N27F4VCwU033STdPeqQocxMYYmJts0DnB2KEMJF9O3bt8rC2W63k5+f74SIxPmYrCaWpf7K+vSNKBVKRre4iTaBrZwdlhCiGtUW1EajEY1Gw4wZMwBYuHAhRqMRL6/quyPMnj2bPXv2oFAomD59Ou3btwcgKyuLqVOnOp6XlpbGlClTiIqKYuLEiURGRgLQsmVLx+s2FKfPjCkqNyQKIWrLN9984+wQxEU4UZTG58kLyTbk0MgrlLvbJNDUu7GzwxJCXIRqC+qnn36adu3aOZbLysp46qmnKt2oWJWtW7dy4sQJFi1aRGpqKtOmTWPx4sUAhIaGOm5ysVgsjB8/ngEDBrB//36GDBnCs88+ezk51WsZMmSeEKKWNW4sRdnVzGqz8l3SzyxN/g273c6AptdxU/OhaGR4PCHqjWoL6oKCAh544AHH8j333MOaNWuqPfCmTZsYNGgQADExMRQVFVFSUoJOV7kf2LJlyxgyZAheXl6UlpZeavwux3FDYqCM8CGEEK6uxFzKJ/sWcLjgKP5uftzZZiwt/aOdHZYQ4hJVW1CbzWaOHDlCdHTFf/C9e/diNpurPXBOTg5xcXGO5cDAQPR6/TkF9eLFi5k/fz5QMWvXjh07mDBhAkajkUceeYSePXte8HX8/T1Rq2t2897VNh/9aX0JWw5ko1IqaN8qFJ2n9rKOd7XlVxdcPUdXzw9cP0dXz+9KyM43oHG/vPPh1SizNJsP936G3phL98YdGRN9Mx5qD2eHJYSogWoL6mnTpjFx4kSKi4ux2Wz4+/szZ86cag/876GY7Hb7OTfF7Nq1i+bNmzuK7NjYWCZNmsTAgQM5duwY99xzDytXrkSrPf+JND/fUG0sVbna5qPPKyrj1a92UFBczu3xLTGWlmMsrfmUwFdbfnXB1XN09fzA9XOsLj8pti/O69/solGgF08mdHR2KLXmQN4hPk36CqOljCGRA7inxy3k5shVWiHqq2oL6g4dOpCYmEhGRgZbtmzhhx9+4KGHHuLPP/+84H6hoaHk5OQ4lrOzswkKCqr0nHXr1tGrVy/HcnR0tKMlPCoqiqCgILKysmjatOklJVXfFBlMvPHtbnKLyhnVpzkDuzRxdkhCCHHVCPX34MDxPApKyvHTuTk7nMu2/tRGFh9ejhIFd7YeS4+wLigV1U4LIYS4ilX7P3jPnj08//zz3HTTTbz00kvceuutrF27ttoD9+7dm8TERACSk5MJCQk5p7vHvn37iI2NdSwvWbKEL7/8EgC9Xk9ubi6hoaGXlFB9YyizMHfRbjLzDAztEcHwXpHODkkIIa4qHWMqGmP2Hsl1ciSXJ9eYxzcp37Po0A94qj14rPOD9Ajr4uywhBC14Lwt1J988glLly7FaDQyYsQIvv/+ex599FGGDx9+UQfu3LkzcXFxJCQkoFAomDlzJkuXLsXb25v4+Higomj+5yyM8fHxTJ06lcTEREwmEy+88MIFu3vUd+VmK+8s2cPJrBL6dAjn1n7RMsmCEEL8S4eYIL5dk8qe1Bz6dAh3djiXpLC8mJ3Ze9iRtYdjRScACPdqxH/a30Ogh7+ToxNC1JbzFtRvvfUWMTExPP/8844bAy+12PvnWNNApdZogJ9++qnSsq+vLx9//PElvUZ9ZbbYeG/ZPg6fKqR76xDuHNJKimkhhKhCaIAnjYN17D+eh9liRVPDG9EvVkZpFgfyDqFWqFAr1X//KFRY7FZMVhMmq4nyM7/NNkuVxzlZfIpD+UewY0eBglb+MXQN7UiX0I64qVy3sUiIhui8BfW6detYtmwZM2fOxGazcfPNN1/U6B6ienlFZby3bB/HMoppHx3IhBvaoFRKMS2EEOfTPa4Ry9alcuBEAe2jA6vfoYZSC47x3p5PMVlNtXK8KJ9IuoZ2pFNIe3zd5CZUIVzVeQvq4OBgHnjgAR544AG2bt3K999/T3p6Ov/5z3+47bbb6Nu375WM02UcOJHPhz8mUWww07ttI8YPaYVaJTejCCHEhXRrE8qydRXdPuqqoD6cf4T3936GxWZhdIub8NHqsNisWGwWzHYLFpsFtUKNVqXFTaU581uLRqkBzm0U8XPzwd/dr05iFUJcXaod5QOge/fudO/enRkzZvDTTz/x7rvvSkF9iex2O4lb01i8LhWlQsH4wS3p16mxdPMQQoiL0KZZAJ5uavYcyeEOe8taP3ceyk/lgz2fYbXbuL/teNoHx1W/kxBCnHFRBfVZOp2O2267jdtuu62u4nFJxnILn/2WwvaUbHx1WiaNbEdME19nhyWEEPWGSqWkXXQgW5KzSMsuISK09rpPHMxL5YO9n2G327i/3XjaBbWptWMLIRoG6WtQx8wWK69/s5PtKdm0aOLLC3d3k2JaCCFqoENMRVePPak51Tzz4qXkHeaDvfPPFNN3SjEthKgRKajr2PK/jnMyq4RecaE8eVsnfF1gUgIhhHCGds0DUSoU7KmF8ahtdhvrT23iw72fYQceaH8XbYNaX36QQogG6ZK6fIhLczKrmBVbThLo4y43HwohxGXyctfQookvh9IKKCw14etVs6HnThSl8e3BZZwsPoW7yp372t5Om8BWtRytEKIhkYK6jlhtNj77LQWrzc5dQ1vhrpW3WgghLleHmCAOphXw58FDeIUU0iagJSGewRe1b4m5lOVHVrDx9Fbs2OkW2pmbY4bh6+ZTx1ELIVydVHl15PdtpziRWUyvuEa0bV53Y6YKIURDYbPb8AzJRdtqG78W5EIBKBVKujfqzLBmgwj0CKhyvxJzKTuy9vDLsZWUmg2EeYUytuVIWvhHX9kEhBAuSwrqOpCVb2DZhqN4e2q4bVALZ4cjhBD1msFs5OeDW/n14FpyjLmofMFe4s/I9r3YkrWDzRnb2Zq5k2vCuzM0cgD+7n4UlhezR5/Ebv0+DhccxWa34abScnPMcPo3uRaVsm5nWxRCNCxSUNcyu93OF7+lYLbYuHdYa3QeGmeHJIQQ9dpbOz/gdGkmGqWaa8K6YTzdlI3JBsLatuPZ7n3YnrWb346t4s/0zWzO2E64VyPSitOxYwcg0qcpnYLb0a1RJ/zcZJQlIUTtk4K6lm3Ym0HKyQI6xgTRvXWIs8MRQoh679rGPdF6KGnn0w6dxosDnvls3LaLPak5tGseSPdGnekS0oGtmTv57fgq0orTae7bjE4h7egY3FZmKxRC1DkpqGtRfnE5i9ak4q5Vccfg2p/JSwghnOHQoUNMnDiRu+++mzvuuKPSto0bNzJ37lxUKhV9+vRh0qRJtf76fZtcQ3CwN3p9MQAtmvji4aZmT2oOt8dXnGtVShW9wrvRI6wLJqsJd7V7rcchhBDnI+O41RK73c4XK1Iwllu4tX8MAT5yMhdC1H8Gg4GXX36ZXr16Vbl91qxZzJs3j4ULF7JhwwZSU1PrPCa1Skm75gHkFpWTll1SaZtSoZRiWghxxUlBXUt+35bG3iO5xDXzp2/HcGeHI4QQtUKr1fLxxx8TEnJuF7a0tDR8fX0JCwtDqVTSt29fNm3adEXi6tyyYqi895clka4vqebZQghRt6TLRy04llHE4nVH8PHUMOGGNiilq4cQwkWo1WrU6qr/VOj1egIC/h6qLigoiLS0tAsez9/fE7W6ZiNsBAd7Ox5fH6gjt8TE4tWHeWXBDh6/rTPXtK/fjRn/zM9VuXqOrp4fuH6ONc2vTgvq2bNns2fPHhQKBdOnT6d9+/YAZGVlMXXqVMfz0tLSmDJlCjfeeON597laGcstfPTjfqw2OxNubCNTiwshGgy73X7OuuruHcnPN9Totf7Zh/qs67s1JcjbjU9/SebVL7ZxwzWRjLyueb1s1KgqP1fj6jm6en7g+jlWl9+Fiu06K6i3bt3KiRMnWLRoEampqUybNo3FixcDEBoayoIFCwCwWCyMHz+eAQMGXHCfq5HdbmdB4kGyC4xc3zOCtlEygYsQouEIDQ0lJyfHsZyVlUVw8MXNWlhbusWGEBbgybyle/l54wlOZpXwwI1t8HSXIUuFEFdOnfWh3rRpE4MGDQIgJiaGoqIiSkrO7ee2bNkyhgwZgpeX10Xvc7X4a18mm5OzaB7uw83XNXd2OEIIcUU1adKEkpISTp06hcViYe3atfTu3fvKxxGiY8Zd3YiLCmDvkVxe/mI7JzJdtxVNCHH1qbMW6pycHOLi4hzLgYGB6PV6dDpdpectXryY+fPnX9I+/1Rb/fEuVVpWMV+vOoSXu5ppd3enUaBXjY9VV1y9nxO4fo6unh+4fo71Pb+kpCRef/110tPTUavVJCYmMmDAAJo0aUJ8fDwvvPACU6ZMAWDYsGFERUU5JU6dh4bHb+3A9+uP8Nvmk8z6cjuj+0UT361pvewCIoSoX+qsoP533zq73X5O37pdu3bRvHlzR8F8Mfv8W232x7tYZouV2V/soNxk5d6RbVHZbFddnyJX7+cErp+jq+cHrp/j5fTHu1q0bdvW0UWvKt26dWPRokVXMKLzUyoV3NovhtYR/nzyywEWrUll/7E87ruhDb5eWmeHJ4RwYXXW5ePffeuys7MJCgqq9Jx169ZVGtv0Yva5GqzYcpJT+hL6dgynW6zMhiiEEFeTts0DefHe7rRrHkjSsTxmfrqFfUdznR2WEMKF1VlB3bt3bxITEwFITk4mJCTknK4b+/btIzY29pL2cbb84nJ+2XwCH08NY/rHODscIYQQVfD10vLYre1JGNgCQ7mFt77bwxcrUigsNTk7NCGEC6qzLh+dO3cmLi6OhIQEFAoFM2fOZOnSpXh7exMfHw9UjGEaGBh4wX2uNkvWHcFktjFuUEs83GQYbyGEuFopFQoGd2tKq6Z+fPxzMn/sPs3m5CyG9YhgcPcI3DQ1u/9GCCH+rU4rwn+ONQ1Uao0G+Omnn6rd52py5HQhm/ZnEhGi49p2Yc4ORwghxEWIbOTNC/d0Y/2e0/z45zGWbTjG2l3p3Hxdc3q3C0OplJsWhRCXR6Yev0h2u51vVx0G4LZBLeQELIQQ9YhapWRA5ya89mAvbrgmktIyC5/9lsILn21l75HcKiepEUKIiyV9Fi7SluQsjpwuomurYFpF+Ds7HCGEEDXg4aZmVJ9o+nVszLINR9m4L5O3F+8hNsKPW/vHEBXm4+wQhRD1kLRQX4Ryk5XF646gVinlRkQhhHABAT7u3De8DS/c25320YGknCzg5S+288EPSWTVcDhWIUTDJS3UF+G3LSfILy5neK9Igvw8nB2OEEKIWtI0RMfkWzuQciKfxetS2ZaSzc5Deq5p24jubUJp1dQPtUranoQQFyYFdTXyispYseUkvjotw3tFOjscIYQQdSA20p/n7uzK9oN6vv/jCBv2ZrBhbwZe7mo6xATRpWUwcVEBaGVkECFEFaSgrsaSdUcwWWyM7xuNu1beLiGEcFUKhYJusSF0bhnEoZMF7DyUw87DejYmZbIxKROtRkn76CC6x4bQLjpQht0TQjhIhXgB+gIjW5KziAjV0attI2eHI4QQ4gpQKZW0bhZA62YB3BbfguMZxew8pGfHwWy2p1T8uGlUdGwRRLfYENo1D0CjluJaiIZMCuoLWLcrHTswuFtTlAoZJk8IIRoapUJB83Afmof7cEvf5qRll7AtJZutB7LYklzxo/PQMO2OzoQFejk7XCGEk0hBfR5mi5UNezPQeWjoFhvi7HCEEEI4mUKhICLUm4hQb0b1ac6JrGLW78lg3a50ft+Wxp1DY6s/iBDCJcmty+ex9UA2JUYz13UIk0t5QgghKlEoFDRr5MMd8S0J8HFjU3IWZSaLs8MSQjiJFNTnsWZnOgqgf8fGzg5FCCHEVUqpVNCnfTjlJitbD2Q7OxwhhJNIQV2FYxlFHMsookNMkIw7LYQQ4oKubR+GQlFx340QomGSgroKa3dWnBT7d5bWaSGEEBcW4ONOh+ggjmcWcyKz2NnhCCGcQArqfykxmtlyIIsQfw/iogKcHY4QQoh6oE/HcAD+2HPayZEIIZxBCup/+XNvBmaLjf6dGstQeUIIIS5Ku+YB+Hu7sXl/ptycKEQDJMPm/YPNbmftrlNo1UqubR/m7HAqSSs+TbYhG4vNisVmwWKv+G2z2/DSeOGj1eGt1eGj9Uan1Tk7XCGEaFBUSiV9OoTz45/H2Hogmz4dwp0dkhDiCqrTgnr27Nns2bMHhULB9OnTad++vWNbRkYGTzzxBGazmTZt2vDSSy+RlJTExIkTiYyMBKBly5bMmDGjLkOsJOloHvqCMq5tH4aXu+aKvW51co35/N/2eVjt1oveR6f1wk/ri7+7HwHufvi7VfyODWiJl8azDqMVQoiG6br2YSz/6xh/7D4tBbUQDUydFdRbt27lxIkTLFq0iNTUVKZNm8bixYsd21977TXuvfde4uPjefHFFzl9+jQGg4EhQ4bw7LPP1lVYF7Rm5ykABnZu4pTXP591p/7EarfSt8k1NNGFo1aqUSlUqJVqlAoFJWYDxaZiik0lFJmKKTKVUGopIbtUz6mSyv35dBovxrQcSeeQ9iikS4sQQtSaAB932jcPZM+RXE5mFRMR6u3skIQQV0idFdSbNm1i0KBBAMTExFBUVERJSQk6nQ6bzcaOHTuYO3cuADNnzgTg4MGDdRVOtfQFRvYdySU63IfIRlfPSdBgNvLX6S34an0YFXMDauXFfWTBwd5kZxdhsBjJKysgvyyfk8XprDr5B/P3f82O7D2MbXkzvm5V55pjzOV0SSYl5lJKTKUVv82llJpL0aq0eGu9K3Uz8dbq8FJ74aXxxF3thlJx/u75drtdinkhhEvq27Exe47k8see04wf3MrZ4QghrpA6K6hzcnKIi4tzLAcGBqLX69HpdOTl5aHT6fjvf//Ljh076NSpE0888QQGg4EdO3YwYcIEjEYjjzzyCD179qyrECv5c28GdmDAVdY6/dfpLZRbTQxtNvCii+mzFAoFXhpPvDSeNPUOp31wHN0bdeLrlCXs0SdxOP8Io1vcRPdGnbHZbRwtPEFS7gGScg6Qaaj5BAUKKl7XU+OBWqHGZDVhtpkx2SyYbWasNiutA1sSH9GPFn7NpbgWQriMdtF/35w4pl8MblqZaVeIhqDOCmq73X7O8tnCyW63k5WVxS233MKjjz7KAw88wB9//EFsbCyTJk1i4MCBHDt2jHvuuYeVK1ei1WrP+zr+/p6oazg1eHDw362z6XkGAAb0iETnWfF6NruNBbuXogDGtLsRd7VbjV6npixWC+s3bcRN7caI9gPRab0uaf9/5udYhzezIqayMnU9X+/9gS8PLOLPzE1klegpNRsB0Ko0dA1vT6ugaHzdvfFx0+HjVvFb5+ZFmaWcwrJiCsuKKDjzU1RWTInJQImplGLTmVbt8lJK7QbcVFo8tO74qrRoVRrMVjPJuQdJzj1IdEAkN8XG06NxJ5TKixt0xm63YzSXYTAb8QtwR61UO/5tWWxWMoqzOFGQzsnCdE4UpJNWeBoPtRstg6JpFdScloFRhHmH1otCvqrP0NW4eo71Pb8L3QszcuRIvL3/zu+NN94gNDTUGWFeNVRK5Zm+1MfZmpLFde2lL7UQDUGdFdShoaHk5OQ4lrOzswkKCgLA39+fsLAwIiIiAOjVqxeHDx+mX79+REdHAxAVFUVQUBBZWVk0bdr0vK+Tn2+oUXzBwd7o9X8PwH8svRB/bzeMpeUYS8sBWHF8Db8cXQ3A1lN7uKfNOCJ8rlwL9tbMneQZC+jf5FqMhTaMXPyEAf/O79+6+HWhWbcovkn5npT8w/i7+dGlcUfaBrWmhV80WtW/bsq0AUYoNVoAFTr80Kn9aKwDajCoyLHCE6w6+Qd79Pt5a+MnBHkEck1YNzzU7pWeZwcMZkNFt5XyAkf3FZPNXOl5aoUKlVKF1WbF8q+bN3213hSVFZNWlMHqo38C4KXxJMonkhb+zWnl34LGukYX7KbiDNV9hq7A1XOsLr+rvdiu7l4YgAULFjgpuqvXde3D+emv46zecYpecY1Qq66uc4sQovbVWUHdu3dv5s2bR0JCAsnJyYSEhKDTVVRearWapk2bcvz4cZo1a8b+/fsZPnw4S5YswWAwcOedd6LX68nNzb0irR2lZWbyi8tp2/zviVxS8g7z89FE/Nx86RDclj9O/cUbO97jxuZDGBjRp86LL7vdzuqT61GgoF/Ta+vkNQI9Ani44wRKzKXoNF5XtMU2yjeS+9vdSZZBz+qT69mSuYPlR1dUu5+X2pMQz2D83HzQumkwGMuw2C2O4QRVShXhXo1orAujsa4R4V5h6LReWG1W0kszOFZ4kqOFxzl2tntL7gGg4mbNFv7RtPKPIconAp3WCy+1J5p/f7G4CGevzlT3fp4uyWTF8dWkFhyle6MuDGnWHw+1THUvrh4XuhcGoLS01JnhXbUCfd3p3iaULclZ/O+nZB68qQ2qi7wCJ4Son+qsoO7cuTNxcXEkJCSgUCiYOXMmS5cuxdvbm/j4eKZPn87MmTMpLy+nRYsWDBgwgOLiYqZOnUpiYiImk4kXXnjhgt09asup7BIAmgRX/JHILyvgs/3foFQomdB2PFG+EbQLbM2XBxbxw5FfSc49yJ1txuLv7ldnMR3MT+VUyWk6h7QnyKPuZmxUKBR4O3Hc6lDPYMbF3sINzQeTWnDsnK5CAO5qdwLd/fBz86vU7eZSWjdVShUR3k2I8G5C3ybXABWf86H8IxzMT+Vgfiq7sveyK3tvpf20Sg2eZ/qhh3gGE+UTQTOfCJp6N67Uip9rzHMc52B+KmarhXZBrekY0o42Aa0qPTe9JIPfjq9md/Y+7NjRKNX8fnIdmzK2MTxqML3Du6NSVu7GVGYpY39uCil5qYTpQuneqDM6zfm7ANnsNlILjlFkKkan8aq4aVTjiU7jhVqpxm63U2Yto9RsxGA2UGo2YLSWYbaaK31Bsdgs+Lv70co/Bl83n4t6ry9HiakUq916RV5LVO9C98IAFBQUMGXKFNLT0+nRoweTJ0+u9otkbXXTu9pNHd+VFz7ezPaUbHy93Xh0TCeUygu/N/Upv5py9RxdPT9w/Rxrmp/CXlUFU4/U9HLxP4ux1TtO8fXvh5hwQ2u6tQnm7Z0fcrzoJGNbjqTPmeILKv7Yf52yhL05+/FUezCgaR96hnWpk8L6vT2fkpx7kCe7Pkwzn4hL3t/VL6VD7eZot9vJNuZwMC+VjNJMSs8UmQaLgVKzkRJzCeVWk+P5SoWSJrowQjyDOV54kpyyPMc2H603KoWK/PICoKIojwuMJS4wlqTcFHbr9wEQ4d2YYVHxtPKPYU3an6w8sYZyq4lQzxBujhlG9+i2rEvZxi79Pg7kHcJi+3v2NbVSTcfgtlwb3oOYMzd22uw2jhWeZEf2bnZm76XYVFJlru4qN0w2Mza77ZLeo3CvRsQGtCA2oCUt/KLQqi7/y25gkBe7jh5kf24K+3NTOF6UBkD/ptcyPGrwFblvwWA2kHumK1FeWQF55fnklxXgofagW2gnov2a1fiKVH3v8vHcc8/Rr18/Ryv1bbfdxquvvkqzZs0A+Oabb7jppptwc3Nj4sSJjB49miFDhlzwmLVxzq4vjOUW3vh2F8cyihnYuQnj4luc9wtHfczvUrl6jq6eH7h+jpdzzpaZEoF0/d8t1EsP/8zxopN0C+3MdY17VXqeTuvFA+3u5K/TW1ia+jM/H0vkl2MraR3Ykt5h3Wkb1PqSR+KoyumSzIob9nyjalRMi0unUCgI9Qwm1DO4yu12u53csnyOF53keOFJjhedJK04nZPF6Xio3WkfFEcr/xhaBcTQyDMEgJPFp9itT2J39j526St+ACK9mzIsahBxgbGOP65Dmw3gmvBu/Hx0JRtPb+XDvZ/z0T6Fo8U+zCuUjsHtiAtsxdHCE/x1egvbs3azPWs3IZ5BtPCLJjn3oKOI99J4cm14D8J1YY6hD0vNpRSfGfrQTaXFU+3pGAWmYrhDdzRKNWqFGrXy7I+KjNIsUvIOk1pwlNNpmaxJ24BKoSLQw59A9wAC3c/89vDHR+uNUqFCoVCgQIHyzG+TzUypubSiRdxS8WUlv6yAQ4VHKCwrAiq+pDT3bUahqYg1aRvYlb2PhFY30zao9TmfR64xj82ZOziYl4q3VkeQRwBBHoEEeQQQ7BGIv5vfOa38Z5394nF2RJvTpZnn/Xfx1+ktBLoH0L1RZ7o36kyIZ9BF/GtyHRe6FwZg3Lhxjsf9+vXj4MGD1RbUDYmHm5rHx3Rkzjc7Wb3zFO5uKm7pG+3ssIQQdUAKauCUvhSlQkG65RDr0zcS7tWIcbGjqmxJUCgUXNu4J11CO7Izaw9/ZWx1jFih03hxTXh3hjUbVKO+t2etSdsAwMCIPjU+hqhdCoXiTNEWQNfQjgCYbRbyy/IJdA+osniL9GlKpE9Tbmo+lNOlmRzIO0SYVyPaBLSs8t+Wj9abcbG30K9Jb34+mojBbiDWtxWdgtsS6hXieF6UbyQDml7HkcLj/Jm+hV36vfx1egseand6hnWlS0gHWvnHnLegvFRxgbEMiuiL2WrmSOFxR3GtN+aSbTh0Wcf2dfehZ6OuxAXFEuvfAk+NByarmRXHV/P7yXV8sPczOoW059YWN+Ghdme3PolNGds5lJ96weMqUODnVnmmUF83H04Wn2J/bgql5oqbmTVKNa0DWhLiGVxpRlF/dz+yDXo2Z+xgl34fvx1fxW/HV9HcN5IAd3+sdhs2mxWr3YbVbsVL48ntsbeeezNvPXehe2Hy8vJ4+umnef/999FoNGzbtk2K6SroPDRMSejEa1/t4JdNJ3DXqhjeq5mzwxJC1LIG3+XDbrfz8H9X4xlcgDl8FyqFiqe7PULIeVoqq3K6JJONGVvZmrmTUrOBSO+m3N9ufI26ghSWF/P8xtkEuPszo+fUOrvU7ApcPceLza/UbCCjNItIn6ZoauEKyaUos5STV5ZPblkeuWX5lJhKsNnt2LFjs9uw2+3YsKFVas+MTe6JTuOJp9oTndaLNhHNyM2p+sa29JIMFqZ8z7Gik7ir3AE7ZdaKEXiifaPoFdaVTiHtKLeayDHmkWPMRW/MJceYR25ZHvllBRSais7p2uKr9aFtUGvaBbWmlX9MtV1Xyq0mdmfvY2vmTg7mp2Ln3FOml9qTZ3tMOWeipPre5QMqhsLbvn27416Y5ORkx70wn3zyCb/++itarZY2bdrw3HPPVTv8ZUPq8vFPuYVlvPb1DnKLyunTIZyhPSJoFODp2F7f87sYrp6jq+cHrp/j5ZyzG2RBbbPbKFEXsPHILvZkH+BEcRoKRcXb8EC7O+kQ3LZGsZisZhYdXMbmzO14a3RMaDeeGL+oi9o3v6yAlLzDbMncweGCoyS0uvmcLieXwtX/0YPr5+jq+UH1OdrsNv5M38zyo4m4qbT0bNSFHmFdL7rrhdVmpchUTF5ZAQXlBQR7BtFU17jGI9qUmg2YbWaUCiUqhQqVQolSoUKtVFX55dcVCura1lALaoCsfANvfbeH7HwjCqBDTBCDuzWlVYQfISE+9T6/6rjCZ3ghrp4fuH6O0of6EpSaDby+7R1yy/KBikvD9lIfWvi2YHTna2nqXfNB+LUqDXe0vpWmPo35/vBPvLPrI25tcRPXNe51zh/wEnMpxwpPkJJ3mJS8w5VmJozwbkyPRl1qHIcQl2LevLc4ePAAeXm5lJWVER7eGB8fX2bP/r9q9505cxrTp8/Ezc39nG25uTl8+ulHPPXUszWOTalQsunrteSmHObT+V9d8hUblVKF/5kuHLXBS+NZ/ZOEOI9Qf09eub8Huw7lkLjtJLtTc9idmkNEiI5bBragVbgPWo3MrChEfdTgCmqlQkkjr1Dah7UmyjOKk0fc+GnrafqNakdT74vv5nE+CoWCfk1609irEZ8kfcWiQz9wovgU1zXuyYmiUxwrPMmJopNkG/++0efsKBCxAS2I9W9BmFf9mMVPuIZHHnkcgF9//YmjR4/w8MOTL3rfF1989bzbAgODLquYBrBYLGzcuAGtVkvayZNERja7rOMJ4WwqpZKusSF0jQ3hSHohK7elsf1gNm8t3IWHm5oerUO4tn04UWHe8ndAiHqkwRXUHmp3Jna419Gsv33LfgAah9TuWMwt/KN5utujfLzvSzZnbGdzxvZ/xOBB64CWNPNpSkv/GKJ8I69431dxdfpuTSrbUiquVqhUCqzWy++R1S02hDEDYi55v1deeQG1WkNRUQHTp8/kxRefw2g0UlZWxuOPP0mbNm0ZPfpGvvxyEW+9NYegoGAOHjxAVlYmzz8/Cx8fH5577mk+/XQBY8eOZMSIUfz11wZMJhPvvPM+Npudp556lOLiUvr3H8jixd+yePHySjFs3vwXLVu2IiamJatWJXLffQ8CsGLFLyxZsgiFQkFCwu0MHDi4ynXDhw/kl18qZjt97rmnGDVqDLt27eD06XQyMk7z9tvv8+qrL6HXZ2M0Grn33gfo3fs6Dh1K4c03X0epVBAX154bbhjB//3fbN5772MAPv/8E7y8dNx6a8JlfjqiIYtu7MtDjX3JKTCy7XAOq7aeZN3u06zbfZrwIC+ubRdGr7hQfHV1P3ykEOLyNPgq7pS+BDeNiiDfcy9ZX64Ad38e7zyRxBNrKDUbaObTlGY+EYR4Bl1101wLURUfHx+efvpZTp48wQ03jKRPn37s2LGNr7/+gldeqdwlxGQyMXfuu/zwwxJWrPiFMWNuc2yzWq1ERDRj3Lg7mTlzGtu3byM7O5Po6GgefPAxli5dXOWkPr//voKBAwfTsmUszz77JPfd9yAGQymfffYxX375LSaTmVdemUmvXr3PWTdw4ODz5mWxmHn//U/Iz8+je/eeXH/9DaSnn2LGjGfo3fs63nrr/3jyyenExLTg5Zefx93dHZOpnOzsLEJCQtm06S9effWN2nujRYMW5OfBncPaMKRLE/Yfz+PPvRnsOqznu7WpLFl3hPbRgVzXPox20YEyjbkQV6kGXVBbrDYycw1ENvJGWUeX1rQqDTc2l6GkxMUZMyDG0Zp8Ndz80aZNxSx5AQGBfPHFJyxcuACz2Yy7+7lfQDt06ARAcHAoycn7L7i9tLSE48eP06/ftQD07n0d33zzZaXnG41Gtm/fytNPP4enpxdarZZDh1KwWCxERkbh5uaOm5s7r702l+TkpHPWXUjr1hV5eXv7cODAfpYvX4pCoaSoqBCAU6fSiIlpAcCMGS8BMHjwMNas+Z1Bg4bi5aUjICDw4t5EIS6SUqmgXfNA2jUPpMRoZktyFn/uy3D0tfbx1NCrbSOubRdG42DnzXArhDhXgy6oM3MNWG12mgSffwpnIRoytbpiXOXvvvuGoKAQZsx4mZSUZN599+1znqtS/X0zVVWtzedutzv6iFY11Nr69WuxWq1MnHg/UDHN9apViQwYMBj7v4bCUypV56z7N4vl75kmNZqKvH7/fQVFRUW8994nFBUVMWHCeIAq+64OGjSE5557Cnd3D+Lj5UuyqFs6Dw0DuzRhYJcmpGWX8OfeDDbtzyRxaxqJW9No2zyAW/pEE9mo4Y0UI8TVqEFfOzp1ZoZE+aYvxIUVFhbQuHETAP74Y22l4rSmwsObkJSUBMDmzRvP2f777yt47rmX+Pzzb/j882/48MP5rF27msjIZpw8eQKDwUB5eTmTJ0+scp3dXlGwl5WVUVZWxqFDB895jYKCAsLCwlEqlfzxxxrMZjMAzZpFsX9/RWyvvvoSx48fw9/fHx8fHxITf6Vv3/6Xnb8QF6tpiI7bBrVg7sO9mTiyLbERfiQdzePFz7fxwQ9JZOYZnB2iEA1eg26hPqWvmFCiiRTUQlzQ0KHDmTVrJmvXruKWW8awatVKfvllefU7XsCwYTcyY8aTbNu2g27delRqwS4sLODo0SP07HmNY11YWDjh4Y05fPgg9933Hx5/fBJ2u50xY27Dw8PjnHUKhYKRI0fzwAN30axZc1q1OncK8379BvDMM0+QnJzE8OE3ERISwueff8Jjj03ljTcqRjCJi2tHs2ZRZ54/kL/+2oCnp1zVEleeWvX3CCH7j+ex9I8jbEvJZsdBPde2b8RNvaMI8Kn9+4GEENVrkBO7QEX/1Gff/5O9R3J5+9Fr8fG88Gxp9c3V0P+2rrl6jq6eX2ZmBgUFWcTGdiQpaS/z5/+PuXPfdXZYFzRr1kyGDbuRzp27XtTzZWKXczXkiV0upCb52e12dh7Ss3T9UTJyDSiA8GAvYhr7Eh3uS0wTX0L9Pa6a4ffkM6z/XD1HmdilhtL1Jfh4aV2umBaiPvDy0vH2269TWFiE3Q6TJ091dkjnVV5eziOPPEjr1m0uupgWoq4pFAq6tAqhU4tgNu3P5K99GRzNKCJdX8ofu08DFX2xm4V5ExHiTUSojqYhOkL9PVEqr44iWwhX0WAL6lKjmdyicto083d2KEI0SN7e3nz66af1orXDzc2N//3vc2eHIUSVlEoFvduF0btdGFabjVPZpaSmF3IkvZDU9EKSjuaRdDTP8XytRkmTYB2NAjwJ8fcgxM+DEP+Kx17u6qumRVuI+qTBFtQnMosA6T8thBDCdaiUSiIbeRPZyJuBXSpuJC4xmknLLiEtq5iT2SWczCrhRGYxR08XnbO/h5uKQB93An3cCfB1dzwO9vMgNMADL3fNlU5JiHqhARfUFa1ijWXIPCGEEC5M56GhdaQ/rSP/viJrsdrILSpDn28kK9+IvsBIdr4RfaGRnMIyx037VR0rNMCDUH9PQv09CPR1J8DbnQAfN/y93dGoG/TgYaIBq9OCevbs2ezZsweFQsH06dNp3769Y1tGRgZPPPEEZrOZNm3a8NJLL1W7T206kSEt1EIIIRomtUp5pij2pG0V2w1lFd0icwvLyC0qIzvfSFa+gaw8A8dOF3Mk/dzWbQAfLy2BPu6Viu7QgIrfQriyOiuot27dyokTJ1i0aBGpqalMmzaNxYsXO7a/9tpr3HvvvcTHx/Piiy9y+vRpTp06dcF9atPxjKKKO6KDpIVaCCGE+CdPdw2e7hqahpzb6GSx2sgtLCMr30BeUTl5xWUVv4vKyCsu52RWMccyqupOosbHS4uflxZfnRZfLzf8vLUEeJ/pWuLrjq+XVm6YFPVSnRXUmzZtYtCgQQDExMRQVFRESUkJOp0Om83Gjh07mDu3YnrgmTNnArB48eLz7lOb7HY7JzKKCPH3wE2jqn4HIVzYAw/czZQpz9CqVaxj3Ycfvoufnx8JCXec8/zhwwfyyy+reeedN7n11gTCwxs7th09msrcuXN4993/VflapaUl7N+fRPfuPVmw4HP697+WJk1iahy7Xp/NLbfcwCuvzOG66/rV+DhCiIunVikrWp0DPKvcbrPZyS0qO9OibXT8LjaayS00knWBiWhUSgX+3m4EeLsR4OOOv49bRX/uM91KdB4aPNzUuGlVKOXmSXEVqbOCOicnh7i4OMdyYGAger0enU5HXl4eOp2O//73v+zYsYNOnTrxxBNPXHCf8/H390StvrSiOLfQSInRTLuYIJceB9aVczvL1XO8EvndfPMINm1ax7XXdnOs+/PPdXz55ZdVvr5CoSA42JtZs144Z1t+vhdarfq8cR89mkxS0k6GD4/niSceuezYly//jsjISDZsWMOoUTde9vHqgqv/GxXi35RKBcF+HgT7edA26u/1Z8f4tVhtFBvMFJSUU1BS7mjdzj3zk1dUzuFThdgpvODruGtVeLip8XBT4+2hqRgG98yPr5cWb08NXu4adB4avDw0eLmrUaukj7eoG3VWUP97vpiz0wCffZyVlcUtt9zCo48+ygMPPMAff/xxwX3OJz//0qdc3Xc0F4BgH7d6MWRXTbj64OvgmjkuTf2ZXdn7gIqWGqvt8udd6hTSjlExN5x3e48efZg4cQJ33/0fAFJSDhAQEEROTjGPPfY4ABaLheeee5HGjZtgt9vR64t5+OEHeOKJp9DpvJkx4xl0Om8iIiIxmSzo9cUsXPgV69atxmaz0atXb+699wGef/4FDIZSAgMbkZS0lxEjbiA2tiNz5rzC6dPpmEwmJkz4D92792Ts2JGMGDGKv/7agMlk4p133j9nhsIffviRRx+dygsvTOfkyWw8PDwoLi7mpZeeo7S0FJ1OxwsvzMZqtZ6zbuHCBfj5+XHLLWMrtawnJNxMy5axdO/eg9DQMD755EM0Gg3e3t689NJraDQa3nnnTZKTk1AqlTz55DQ+++wTRowYRdeu3TGZTNx++60sXPg9YWH+MrGLEP+iVinx93bD39vtvM+xWG2Viu284orfhjILxnILRpOVsnILRpOFwpJyTudUfRPlv7lrVXi6q/HQqnF3U+GhrSjI3bUq3DQqtBoVbhql47GnuxpvTy0+nhUFu5eHRlrGRZXqrKAODQ0lJyfHsZydnU1QUBAA/v7+hIWFERERAUCvXr04fPjwBfepTaf0JYDckCgEQEBAIGFh4SQnJ9GmTVvWrPmd+Pih5ObmcM8999O5c1d+/vlHli5dzCOPPH7O/kuWfMvAgYMZM+Y2vvrqcw4f/nvb++9/glKpZMyYEYwdO45x48Zz9OgRRowYRVLSXgB+/30FWq2Wd9/9Hzk5eh5++AG+/XYZVquViIhmjBt3JzNnTmP79m306dPPceyTJ49TUlJCt2496NSpC3/++Qfx8UNZuHAB3bv34tZbE1i06Gu2b99KSkryOevO5/TpdGbPfoPmzaNZs2YVM2fOIjy8MS+//DxbtmzCzc2NrKxMPvroM3bv3snq1b8zdOhwVq/+na5du7Njx1Z69boGtbrBDqIkxGVTq5QE+XoQ5HtxNzOebfUuKjVRZDBRVGqi2GCmtMxMqdFMidFMaZmFEqMZY7mFgpJyyvKsl9xooVCAt4cGN60KrVqFRq1Eq1ai0ajw0bmhUfKvVvGKlnFPdzWebhW/3d3UUpS7oDo74/fu3Zt58+aRkJBAcnIyISEhjq4barWapk2bcvz4cZo1a8b+/fsZPnw4AQEB592nNp3Krvgm26SKmy2EcKZRMTc4WpOvZAt8fPxQVq/+nTZt2vLXX+v54IP5GI0G3n77DT799COKi4to1ap1lfseP36M/v0r7n3o1KkrmzdvBMDd3Z2HH34AlUpFQUEBRUVVjwpw8OABOnXqAkBQUDAqlYqioopLvR06dAIgODiU0tKSSvutXLmCQYOGOOL/7befiY8fyqFDKUyY8BAAY8feDsDy5UvPWXf48MEq43F396B582gA/Pz8eP31WVitVk6fTqdLl27k5+fRrl0HADp27EzHjp2xWCx88MF/sVgsbNjwB8OGXZ3dT4RwVRfT6v1vdrsds8XmaO0uN1spN1sxmW2Ox4Yyy5ni3ESRwUyRwURxqcmxzWSxYbbYLilWBeB+plVcq1HhfqZVXHumlVyjUqJWKdGoK36r1Qrczjzv7H4VP2q83NWOwl2GLHSuOiuoO3fuTFxcHAkJCSgUCmbOnMnSpUvx9vYmPj6e6dOnM3PmTMrLy2nRogUDBgxAqVSes09dSNeXoNWoCPGTYXyEAOjbtz8LFnxGfPwQIiIi8fHx4d1336JHj56MHDmatWtXsXHjn1XuW9E1S3nmccUflszMDBYt+pr587/G09OT8ePHXODVFZW6e9lsNsfxVKq/74/4d5ewVatWolQq2LjxT2y2ioK3uLgYpVLliOOsqtb9szuZxWJxPNZo/j4tvvrqy/zf/71Ns2ZRzJ37+nmPpVar6datJ9u3b+XYsaO0bVs3w30KIWqPQqFAe6Zrh6+XtsbHsdntWCw2dD4enDiV72gJLz3zYyi3YCiznPO73GxxtJabTFYut4OfVqPEy12Dp5vaUYifLc7VKiUKBZw9jdrtdsfruWtVeJ7pi372R6tRolQoUCoVlX4H5RgoM5RXvG/qiq4xmjNfAjRqxZnXaZit73V6TXLq1KmVlmNj/x5FIDIyks8//7zafWqb1WbjdK6BZmHeMjSPEGd4eemIjo7hyy8/Y9CgoQAUFBQ4+kz/+ecfWK1Vt8JERESSkpJMbGxrdu7c7tjX398fT09PDh5MITMzE7PZjEKhwGw2Vdq/des27Ny5nUGDhpCVlYlSqcTb+8J9i5OTk/D09GT+/K8c62bPfpE//lhD69Zt2LFjG61bx/HDD9/j5uZW5TovLy9HF7O9e3dX+TqlpSWEhjaiuLiYnTt3EB3dgtat2/DVV58zbtydHDqUwk8//ciUKU8zZMgw3nzzVbp163lR77kQwjUozxTmvjo3wgJrNhSv3W7HZLFhMluxWO2YrRUt3xaLDbO1Yn2ZyUqZyXLmtxXjmcK8tOxMlxZjxeOCknIsVjsWq61W7sO5VGpVRWGtUipQKRUozhbliopltVp5pgD/x49KeeZ5/F3EKxSOY6nVf7faV9r3H4/VaiVq5ZniX6lArVRW/FZVtPBr1Eq0Z37XRZebBtfJT19QhsVqIzLMx9mhCHFViY+/nlmzZjJz5ssAjBgxirfffoPQ0DBGjx7LnDmvsHXr5nP2u/XW25gx4xnWr19LdHQLAFq0aImHhycPPXQv7dp1ZMSIUbz55us89tgTfPjhPEJDwxz7Dxw4mF27dvDIIw9isZh58snp1ca6alUiw4dX7lYxfPhNfPbZx8yaNYdZs57n4YcfwNPTixdemIXNZj9nXVFREU8++RgHDuynY8fOVb7OqFG38tBD99G0aQS3334n8+f/jw8+mE9kZBQTJ04AYMqUZwCIjW1NUVER8fFDL+LdFkKIvykUFUVfbQ/la7NVFNYWqw07Fd1NQIFCgaPF+mxxfvbHUG7BZLZhs9ux2e3YbXZsdrDa7Li5a8gvMFR0i7FYMZmslJ8p/C1nvwSc/W2zY7NVHMNmszu+NBjKLZgtNkwWK/YrX+8D4OmmZtKodpVmD71cCvu/r6PWM5fax7TMZOHTXw5w66BWhHjX/BLP1c4VR8D4N1fP0dXzA9fK8eTJE7z55uu88877jnXV5dcQR/mo6eftSv9WquLq+YHr5+jq+UHt52i12TCZK4pwm73iC4CjCLfbsZ5paTdb/26tt1jOtuBbMZ/pw362Rd9ms2M982OzVexvtlYU72azzXEVAOC2QS2ICK18Dr6cc3aDa6F216qZdHO7BvEPXwhxZfzwwxJ+/HEpzz33krNDEUKIekOlVOLh5ho3Uza4gloIIWrbyJGjGTlytLPDqBOzZ89mz549KBQKpk+fTvv2f99wuXHjRubOnYtKpaJPnz5MmjTJiZEKIYTzuMbXAiGEELVu69atnDhxgkWLFjFr1ixefvnlSttnzZrFvHnzWLhwIRs2bCA1NdVJkQohhHNJQS2EEKJKmzZtYtCgijHGY2JiKCoqoqSkYjzwtLQ0fH19CQsLQ6lU0rdvXzZt2uTMcIUQwmmky4cQQogq5eTkEBcX51gODAxEr9ej0+nQ6/UEBAQ4tgUFBZGWllbtMf39PVGrazaSgavfxOnq+YHr5+jq+YHr51jT/KSgFkIIUaV/DwJVMYmPosptwEVN6JCfb6hRLK5+I7mr5weun6Or5weun+PljPIhXT6EEEJUKTQ01DH5DUB2djZBQUFVbsvKyiI4OPiKxyiEEFcDKaiFEEJUqXfv3iQmJgKQnJxMSEgIOp0OgCZNmlBSUsKpU6ewWCysXbuW3r17OzNcIYRwGunyIYQQokqdO3cmLi6OhIQEFAoFM2fOZOnSpXh7exMfH88LL7zAlClTABg2bBhRUVFOjlgIIZyj3s+UKIQQQgghhDNJlw8hhBBCCCEugxTUQgghhBBCXAYpqIUQQgghhLgMUlALIYQQQghxGaSgFkIIIYQQ4jJIQS2EEEIIIcRlkIJaCCGEEEKIy9DgJnaZPXs2e/bsQaFQMH36dNq3b+/skGrFoUOHmDhxInfffTd33HEHGRkZPPXUU1itVoKDg/m///s/tFqts8O8LHPmzGHHjh1YLBYefPBB2rVr5zI5Go1GnnnmGXJzcykvL2fixInExsa6TH5nlZWVMXz4cCZNmkSvXr1cKr+kpCQmTpxIZGQkAC1btmTChAkulaMzyDm7/pJzdv3N7yw5Z198jg2qhXrr1q2cOHGCRYsWMWvWLF5++WVnh1QrDAYDL7/8Mr169XKs++9//8u4ceP45ptvaNy4MUuWLHFihJdv8+bNHD58mEWLFvHJJ58we/Zsl8px7dq1tG3blq+++oq3336b1157zaXyO+uDDz7Az88PcL1/owaDgSFDhrBgwQIWLFjAjBkzXC7HK03O2fWXnLPrd35nyTn74nNsUAX1pk2bGDRoEAAxMTEUFRVRUlLi5Kgun1ar5eOPPyYkJMSxbsuWLQwcOBCAgQMHsmnTJmeFVyu6devGO++8A4Cvry9Go9Glchw2bBj3338/ABkZGYSGhrpUfgBHjhwhNTWVfv36Aa73b7S0tPScda6W45Um5+z6S87Z9Ts/kHP2pebYoArqnJwc/P39HcuBgYHo9XonRlQ71Go17u7uldYZjUbHZYrg4OB6n6dKpcLT0xOAxYsX06dPH5fLESAhIYGpU6cyffp0l8vv9ddf55lnnnEsu1p+BoOBHTt2MGHCBG6//XY2b97scjleaXLOrr/knF3/85Nz9qXl2KD6UNvt9nOWFQqFk6KpW//M699512erVq1iyZIlzJ8/nyFDhjjWu0qO3377LQcOHODJJ590qc/whx9+oGPHjjRt2tSxzpXyA4iNjWXSpEkMHDiQY8eOcc8992CxWBzbXSHHK03O2fWfnLPrJzlnX3qODaqgDg0NJScnx7GcnZ1NUFCQEyOqOx4eHpSVleHu7k5WVlalS4v11YYNG/jwww/55JNP8Pb2dqkck5KSCAwMJCwsjNatW2O1Wl0qv3Xr1pGWlsa6devIzMxEq9W6VH4A0dHRREdHAxAVFUVQUBAZGRkuleOVJufs+k3O2fU3PzlnX3qODarLR+/evUlMTAQgOTmZkJAQdDqdk6OqG9dcc40j15UrV3Ldddc5OaLLU1xczJw5c/joo48cN0i4Uo7bt29n/vz5QMVlboPB4FL5vf3223z//fd899133HrrrUycONGl8gNYsmQJX375JQB6vZ7c3FxGjRrlUjleaXLOrr/knF2/85Nz9qXnqLC7Qrv9JXjjjTfYvn07CoWCmTNnEhsb6+yQLltSUhKvv/466enpqNVqQkNDeeONN3jmmWcoLy8nPDycV199FY1G4+xQa2zRokXMmzePqKgox7rXXnuN5557ziVyLCsr49lnn3V8O3744Ydp27YtTz/9tEvk90/z5s2jcePGXHvttS6VX2FhIVOnTsVgMGAymXj44Ydp3bq1S+XoDHLOrp/knF2/8/snOWdfXI4NrqAWQgghhBCiNjWoLh9CCCGEEELUNimohRBCCCGEuAxSUAshhBBCCHEZpKAWQgghhBDiMkhBLYQQQgghxGVoUBO7iIbl1KlTDB06lE6dOlVa37dvXyZMmHDZx9+yZQtvv/02CxcuvOxjCSFEQyfnbFGfSUEtXFpAQAALFixwdhhCCCEugpyzRX0lBbVokNq0acPEiRPZsmULpaWlvPbaa7Rs2ZI9e/bw2muvoVarUSgUPP/888TExHD8+HFmzJiBzWbDzc2NV199FQCbzcbMmTM5cOAAWq2Wjz76CIApU6ZQVFSExWKhf//+PPTQQ85MVwgh6jU5Z4urnfShFg2S1WqlRYsWLFiwgNtuu43//ve/ADz11FNMmzaNBQsWcM899/Diiy8CMHPmTO677z6+/vprbrjhBn77/3btmKWRMAjA8LvZLURJFQVBm9ikC6KQRkHwJxgs/QkiBBSbQKpgmhTW2kaxERutBMGQpBFJQDsb+wimFmMhHNyd3sEtckl8n2r5FnaZZpiZby4uAHh4eGBzc5OTkxOiKKJer9NoNHh5eaFWq3F8fMz4+Divr6//LVZJGnbmbA06J9QaaU9PT2xsbPx0tr29DcDy8jIACwsLHB4e0uv16Ha7ZLNZAHK5HIVCAYBOp0MulwNgbW0NeN/Hm5ubY3JyEoDp6Wl6vR6rq6vs7++ztbXFysoK6+vrJBL2rpL0N+ZsDSsLao20P+3j9fv9H89BEBAEwafvgQ8nFmEY/naWSqU4Ozvj9vaWy8tL8vk8p6enjI2N/UsIkvRtmLM1rGzB9G21Wi0Abm5uyGQyJJNJpqamaLfbADSbTebn54H3icj19TUA5+fnVKvVT79br9e5urpicXGRnZ0dJiYm6Ha7XxuMJI04c7YGmRNqjbSPrg9nZ2cBuL+/5+joiOfnZyqVCgCVSoW9vT3CMCSRSFAqlQAoFosUi0VqtRpRFFEul3l8fPzwn+l0mt3dXQ4ODgjDkKWlJWZmZr4uSEkaEeZsDaug/+sdifQNZDIZ7u7uiCJ7SkkadOZsDTpXPiRJkqQYnFBLkiRJMTihliRJkmKwoJYkSZJisKCWJEmSYrCgliRJkmKwoJYkSZJieAPtGfqO9pJQXAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Remove Dense Layers\n",
    "\n",
    "Our model is overfitting so we can try to reduce the capacity of our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.ResNet50(input_shape=(IMG_SIZE, IMG_SIZE, 3), include_top=False)\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_model_no_dense(base_model):\n",
    "    inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    x = tf.keras.applications.resnet.preprocess_input(inputs)\n",
    "    x = base_model(x, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    outputs = Dense(NUM_CLASSES)(x)\n",
    "    _model = tf.keras.Model(inputs, outputs)    \n",
    "    return _model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_strided_slice_5  [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_BiasAdd_5 (Tenso [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 1, 1, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 23,616,394\n",
      "Trainable params: 24,586\n",
      "Non-trainable params: 23,591,808\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_no_dense_model = get_pretrained_model_no_dense(base_model)\n",
    "resnet_no_dense_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "  2/390 [..............................] - ETA: 36s - loss: 2.6398 - accuracy: 0.2031WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0133s vs `on_train_batch_end` time: 0.1724s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0133s vs `on_train_batch_end` time: 0.1724s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 6s 16ms/step - loss: 1.6202 - accuracy: 0.5767 - val_loss: 1.1804 - val_accuracy: 0.6278\n",
      "Epoch 2/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 1.0436 - accuracy: 0.6491 - val_loss: 1.0515 - val_accuracy: 0.6416\n",
      "Epoch 3/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9816 - accuracy: 0.6599 - val_loss: 1.0674 - val_accuracy: 0.6349\n",
      "Epoch 4/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.9757 - accuracy: 0.6607 - val_loss: 1.0504 - val_accuracy: 0.6379\n",
      "Epoch 5/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9729 - accuracy: 0.6628 - val_loss: 1.0537 - val_accuracy: 0.6371\n",
      "Epoch 6/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9726 - accuracy: 0.6613 - val_loss: 1.0206 - val_accuracy: 0.6497\n",
      "Epoch 7/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9771 - accuracy: 0.6594 - val_loss: 1.0454 - val_accuracy: 0.6422\n",
      "Epoch 8/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9742 - accuracy: 0.6622 - val_loss: 1.0812 - val_accuracy: 0.6372\n",
      "Epoch 9/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9826 - accuracy: 0.6572 - val_loss: 1.0485 - val_accuracy: 0.6434\n",
      "Epoch 10/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9897 - accuracy: 0.6564 - val_loss: 1.0268 - val_accuracy: 0.6537\n",
      "Epoch 11/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.9860 - accuracy: 0.6555 - val_loss: 1.0810 - val_accuracy: 0.6355\n",
      "Epoch 12/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.8512 - accuracy: 0.7025 - val_loss: 0.9716 - val_accuracy: 0.6674\n",
      "Epoch 13/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.8281 - accuracy: 0.7091 - val_loss: 0.9536 - val_accuracy: 0.6722\n",
      "Epoch 14/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.8187 - accuracy: 0.7112 - val_loss: 0.9562 - val_accuracy: 0.6733\n",
      "Epoch 15/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.8145 - accuracy: 0.7127 - val_loss: 0.9615 - val_accuracy: 0.6712\n",
      "Epoch 16/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.8112 - accuracy: 0.7136 - val_loss: 0.9691 - val_accuracy: 0.6722\n",
      "Epoch 17/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.8098 - accuracy: 0.7154 - val_loss: 0.9713 - val_accuracy: 0.6691\n",
      "Epoch 18/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.8054 - accuracy: 0.7156 - val_loss: 0.9826 - val_accuracy: 0.6667\n",
      "Epoch 19/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7736 - accuracy: 0.7277 - val_loss: 0.9629 - val_accuracy: 0.6702\n",
      "Epoch 20/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7715 - accuracy: 0.7283 - val_loss: 0.9653 - val_accuracy: 0.6720\n",
      "Epoch 21/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7675 - accuracy: 0.7285 - val_loss: 0.9705 - val_accuracy: 0.6728\n",
      "Epoch 22/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7695 - accuracy: 0.7295 - val_loss: 0.9765 - val_accuracy: 0.6690\n",
      "Epoch 23/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7644 - accuracy: 0.7303 - val_loss: 0.9673 - val_accuracy: 0.6710\n",
      "Epoch 24/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7612 - accuracy: 0.7320 - val_loss: 0.9808 - val_accuracy: 0.6687\n",
      "Epoch 25/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7603 - accuracy: 0.7323 - val_loss: 0.9751 - val_accuracy: 0.6677\n",
      "Epoch 26/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7610 - accuracy: 0.7333 - val_loss: 0.9768 - val_accuracy: 0.6724\n",
      "Epoch 27/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7610 - accuracy: 0.7317 - val_loss: 0.9754 - val_accuracy: 0.6725\n",
      "Epoch 28/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7536 - accuracy: 0.7331 - val_loss: 0.9735 - val_accuracy: 0.6706\n",
      "Epoch 29/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7561 - accuracy: 0.7338 - val_loss: 0.9830 - val_accuracy: 0.6675\n",
      "Epoch 30/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7567 - accuracy: 0.7338 - val_loss: 0.9791 - val_accuracy: 0.6676\n",
      "Epoch 31/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7544 - accuracy: 0.7330 - val_loss: 0.9852 - val_accuracy: 0.6707\n",
      "Epoch 32/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7539 - accuracy: 0.7342 - val_loss: 0.9850 - val_accuracy: 0.6689\n",
      "Epoch 33/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7530 - accuracy: 0.7336 - val_loss: 0.9824 - val_accuracy: 0.6693\n",
      "Epoch 34/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7521 - accuracy: 0.7342 - val_loss: 0.9871 - val_accuracy: 0.6692\n",
      "Epoch 35/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7538 - accuracy: 0.7343 - val_loss: 0.9872 - val_accuracy: 0.6681\n",
      "Epoch 36/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7547 - accuracy: 0.7344 - val_loss: 0.9940 - val_accuracy: 0.6650\n",
      "Epoch 37/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7496 - accuracy: 0.7363 - val_loss: 0.9888 - val_accuracy: 0.6666\n",
      "Epoch 38/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7499 - accuracy: 0.7346 - val_loss: 0.9865 - val_accuracy: 0.6695\n",
      "Epoch 39/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7490 - accuracy: 0.7344 - val_loss: 1.0082 - val_accuracy: 0.6575\n",
      "Epoch 40/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7513 - accuracy: 0.7339 - val_loss: 0.9919 - val_accuracy: 0.6678\n",
      "Epoch 41/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7507 - accuracy: 0.7343 - val_loss: 0.9941 - val_accuracy: 0.6686\n",
      "Epoch 42/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7462 - accuracy: 0.7347 - val_loss: 0.9931 - val_accuracy: 0.6657\n",
      "Epoch 43/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7500 - accuracy: 0.7343 - val_loss: 0.9997 - val_accuracy: 0.6668\n",
      "Epoch 44/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7503 - accuracy: 0.7341 - val_loss: 0.9926 - val_accuracy: 0.6667\n",
      "Epoch 45/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7475 - accuracy: 0.7355 - val_loss: 0.9940 - val_accuracy: 0.6691\n",
      "Epoch 46/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7470 - accuracy: 0.7343 - val_loss: 1.0075 - val_accuracy: 0.6659\n",
      "Epoch 47/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7492 - accuracy: 0.7353 - val_loss: 0.9983 - val_accuracy: 0.6653\n",
      "Epoch 48/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7456 - accuracy: 0.7364 - val_loss: 0.9963 - val_accuracy: 0.6678\n",
      "Epoch 49/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7471 - accuracy: 0.7369 - val_loss: 0.9977 - val_accuracy: 0.6671\n",
      "Epoch 50/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7449 - accuracy: 0.7380 - val_loss: 0.9960 - val_accuracy: 0.6650\n",
      "Epoch 51/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7456 - accuracy: 0.7346 - val_loss: 0.9974 - val_accuracy: 0.6678\n",
      "Epoch 52/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7442 - accuracy: 0.7365 - val_loss: 1.0014 - val_accuracy: 0.6627\n",
      "Epoch 53/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7464 - accuracy: 0.7355 - val_loss: 1.0007 - val_accuracy: 0.6652\n",
      "Epoch 54/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7469 - accuracy: 0.7347 - val_loss: 1.0084 - val_accuracy: 0.6609\n",
      "Epoch 55/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7446 - accuracy: 0.7358 - val_loss: 0.9998 - val_accuracy: 0.6680\n",
      "Epoch 56/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7449 - accuracy: 0.7363 - val_loss: 1.0055 - val_accuracy: 0.6665\n",
      "Epoch 57/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7448 - accuracy: 0.7361 - val_loss: 1.0067 - val_accuracy: 0.6633\n",
      "Epoch 58/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7472 - accuracy: 0.7354 - val_loss: 1.0053 - val_accuracy: 0.6658\n",
      "Epoch 59/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7412 - accuracy: 0.7380 - val_loss: 1.0074 - val_accuracy: 0.6647\n",
      "Epoch 60/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7473 - accuracy: 0.7357 - val_loss: 1.0088 - val_accuracy: 0.6626\n",
      "Epoch 61/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7437 - accuracy: 0.7372 - val_loss: 1.0088 - val_accuracy: 0.6642\n",
      "Epoch 62/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7446 - accuracy: 0.7350 - val_loss: 1.0095 - val_accuracy: 0.6650\n",
      "Epoch 63/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7422 - accuracy: 0.7372 - val_loss: 1.0054 - val_accuracy: 0.6654\n",
      "Epoch 64/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7464 - accuracy: 0.7361 - val_loss: 1.0035 - val_accuracy: 0.6657\n",
      "Epoch 65/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7416 - accuracy: 0.7379 - val_loss: 1.0052 - val_accuracy: 0.6641\n",
      "Epoch 66/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7442 - accuracy: 0.7380 - val_loss: 1.0056 - val_accuracy: 0.6635\n",
      "Epoch 67/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7437 - accuracy: 0.7365 - val_loss: 1.0027 - val_accuracy: 0.6659\n",
      "Epoch 68/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7432 - accuracy: 0.7373 - val_loss: 1.0022 - val_accuracy: 0.6687\n",
      "Epoch 69/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7432 - accuracy: 0.7375 - val_loss: 1.0103 - val_accuracy: 0.6609\n",
      "Epoch 70/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7427 - accuracy: 0.7363 - val_loss: 1.0077 - val_accuracy: 0.6657\n",
      "Epoch 71/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7439 - accuracy: 0.7350 - val_loss: 1.0071 - val_accuracy: 0.6670\n",
      "Epoch 72/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7418 - accuracy: 0.7357 - val_loss: 1.0114 - val_accuracy: 0.6651\n",
      "Epoch 73/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7424 - accuracy: 0.7364 - val_loss: 1.0114 - val_accuracy: 0.6635\n",
      "Epoch 74/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7383 - accuracy: 0.7384 - val_loss: 1.0012 - val_accuracy: 0.6662\n",
      "Epoch 75/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7428 - accuracy: 0.7363 - val_loss: 1.0114 - val_accuracy: 0.6607\n",
      "Epoch 76/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7418 - accuracy: 0.7383 - val_loss: 1.0027 - val_accuracy: 0.6646\n",
      "Epoch 77/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7449 - accuracy: 0.7365 - val_loss: 1.0052 - val_accuracy: 0.6646\n",
      "Epoch 78/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7406 - accuracy: 0.7365 - val_loss: 1.0053 - val_accuracy: 0.6615\n",
      "Epoch 79/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7393 - accuracy: 0.7396 - val_loss: 1.0118 - val_accuracy: 0.6623\n",
      "Epoch 80/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7428 - accuracy: 0.7379 - val_loss: 1.0089 - val_accuracy: 0.6638\n",
      "Epoch 81/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7404 - accuracy: 0.7374 - val_loss: 1.0096 - val_accuracy: 0.6632\n",
      "Epoch 82/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7432 - accuracy: 0.7360 - val_loss: 1.0152 - val_accuracy: 0.6616\n",
      "Epoch 83/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7421 - accuracy: 0.7355 - val_loss: 1.0058 - val_accuracy: 0.6656\n",
      "Epoch 84/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7374 - accuracy: 0.7386 - val_loss: 1.0051 - val_accuracy: 0.6655\n",
      "Epoch 85/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7427 - accuracy: 0.7364 - val_loss: 1.0078 - val_accuracy: 0.6643\n",
      "Epoch 86/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7417 - accuracy: 0.7374 - val_loss: 1.0110 - val_accuracy: 0.6633\n",
      "Epoch 87/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7420 - accuracy: 0.7376 - val_loss: 1.0128 - val_accuracy: 0.6638\n",
      "Epoch 88/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7419 - accuracy: 0.7369 - val_loss: 1.0130 - val_accuracy: 0.6627\n",
      "Epoch 89/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7401 - accuracy: 0.7378 - val_loss: 1.0130 - val_accuracy: 0.6583\n",
      "Epoch 90/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7433 - accuracy: 0.7373 - val_loss: 1.0177 - val_accuracy: 0.6631\n",
      "Epoch 91/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7425 - accuracy: 0.7369 - val_loss: 1.0084 - val_accuracy: 0.6667\n",
      "Epoch 92/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7409 - accuracy: 0.7359 - val_loss: 1.0100 - val_accuracy: 0.6663\n",
      "Epoch 93/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7431 - accuracy: 0.7356 - val_loss: 1.0110 - val_accuracy: 0.6628\n",
      "Epoch 94/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7407 - accuracy: 0.7386 - val_loss: 1.0087 - val_accuracy: 0.6629\n",
      "Epoch 95/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7411 - accuracy: 0.7373 - val_loss: 1.0094 - val_accuracy: 0.6655\n",
      "Epoch 96/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7436 - accuracy: 0.7358 - val_loss: 1.0181 - val_accuracy: 0.6636\n",
      "Epoch 97/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7417 - accuracy: 0.7373 - val_loss: 1.0130 - val_accuracy: 0.6648\n",
      "Epoch 98/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7419 - accuracy: 0.7363 - val_loss: 1.0166 - val_accuracy: 0.6632\n",
      "Epoch 99/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7420 - accuracy: 0.7361 - val_loss: 1.0092 - val_accuracy: 0.6669\n",
      "Epoch 100/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7384 - accuracy: 0.7384 - val_loss: 1.0283 - val_accuracy: 0.6603\n",
      "Epoch 101/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7406 - accuracy: 0.7366 - val_loss: 1.0183 - val_accuracy: 0.6626\n",
      "Epoch 102/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7402 - accuracy: 0.7387 - val_loss: 1.0092 - val_accuracy: 0.6665\n",
      "Epoch 103/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7416 - accuracy: 0.7357 - val_loss: 1.0108 - val_accuracy: 0.6656\n",
      "Epoch 104/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7374 - accuracy: 0.7377 - val_loss: 1.0124 - val_accuracy: 0.6634\n",
      "Epoch 105/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7406 - accuracy: 0.7377 - val_loss: 1.0101 - val_accuracy: 0.6646\n",
      "Epoch 106/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7425 - accuracy: 0.7342 - val_loss: 1.0106 - val_accuracy: 0.6656\n",
      "Epoch 107/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7400 - accuracy: 0.7359 - val_loss: 1.0088 - val_accuracy: 0.6628\n",
      "Epoch 108/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7409 - accuracy: 0.7384 - val_loss: 1.0184 - val_accuracy: 0.6611\n",
      "Epoch 109/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7428 - accuracy: 0.7362 - val_loss: 1.0125 - val_accuracy: 0.6629\n",
      "Epoch 110/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7389 - accuracy: 0.7385 - val_loss: 1.0071 - val_accuracy: 0.6653\n",
      "Epoch 111/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7408 - accuracy: 0.7365 - val_loss: 1.0189 - val_accuracy: 0.6639\n",
      "Epoch 112/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7410 - accuracy: 0.7373 - val_loss: 1.0163 - val_accuracy: 0.6606\n",
      "Epoch 113/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7390 - accuracy: 0.7384 - val_loss: 1.0086 - val_accuracy: 0.6624\n",
      "Epoch 114/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7427 - accuracy: 0.7367 - val_loss: 1.0070 - val_accuracy: 0.6666\n",
      "Epoch 115/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7378 - accuracy: 0.7359 - val_loss: 1.0167 - val_accuracy: 0.6671\n",
      "Epoch 116/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7392 - accuracy: 0.7369 - val_loss: 1.0140 - val_accuracy: 0.6628\n",
      "Epoch 117/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7385 - accuracy: 0.7382 - val_loss: 1.0171 - val_accuracy: 0.6643\n",
      "Epoch 118/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7409 - accuracy: 0.7362 - val_loss: 1.0118 - val_accuracy: 0.6630\n",
      "Epoch 119/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7396 - accuracy: 0.7381 - val_loss: 1.0135 - val_accuracy: 0.6621\n",
      "Epoch 120/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7366 - accuracy: 0.7397 - val_loss: 1.0108 - val_accuracy: 0.6628\n",
      "Epoch 121/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7397 - accuracy: 0.7388 - val_loss: 1.0104 - val_accuracy: 0.6631\n",
      "Epoch 122/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7372 - accuracy: 0.7382 - val_loss: 1.0091 - val_accuracy: 0.6639\n",
      "Epoch 123/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7385 - accuracy: 0.7381 - val_loss: 1.0100 - val_accuracy: 0.6646\n",
      "Epoch 124/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7417 - accuracy: 0.7356 - val_loss: 1.0116 - val_accuracy: 0.6662\n",
      "Epoch 125/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7371 - accuracy: 0.7400 - val_loss: 1.0141 - val_accuracy: 0.6629\n",
      "Epoch 126/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7376 - accuracy: 0.7377 - val_loss: 1.0128 - val_accuracy: 0.6634\n",
      "Epoch 127/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7425 - accuracy: 0.7371 - val_loss: 1.0109 - val_accuracy: 0.6663\n",
      "Epoch 128/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7390 - accuracy: 0.7361 - val_loss: 1.0175 - val_accuracy: 0.6603\n",
      "Epoch 129/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7380 - accuracy: 0.7373 - val_loss: 1.0130 - val_accuracy: 0.6662\n",
      "Epoch 130/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7402 - accuracy: 0.7368 - val_loss: 1.0177 - val_accuracy: 0.6595\n",
      "Epoch 131/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7381 - accuracy: 0.7390 - val_loss: 1.0110 - val_accuracy: 0.6680\n",
      "Epoch 132/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7381 - accuracy: 0.7376 - val_loss: 1.0165 - val_accuracy: 0.6625\n",
      "Epoch 133/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7391 - accuracy: 0.7376 - val_loss: 1.0094 - val_accuracy: 0.6651\n",
      "Epoch 134/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7409 - accuracy: 0.7380 - val_loss: 1.0135 - val_accuracy: 0.6677\n",
      "Epoch 135/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7399 - accuracy: 0.7376 - val_loss: 1.0124 - val_accuracy: 0.6674\n",
      "Epoch 136/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7366 - accuracy: 0.7381 - val_loss: 1.0090 - val_accuracy: 0.6651\n",
      "Epoch 137/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7396 - accuracy: 0.7374 - val_loss: 1.0130 - val_accuracy: 0.6656\n",
      "Epoch 138/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7401 - accuracy: 0.7370 - val_loss: 1.0180 - val_accuracy: 0.6635\n",
      "Epoch 139/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7385 - accuracy: 0.7389 - val_loss: 1.0176 - val_accuracy: 0.6628\n",
      "Epoch 140/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7366 - accuracy: 0.7383 - val_loss: 1.0147 - val_accuracy: 0.6611\n",
      "Epoch 141/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7386 - accuracy: 0.7381 - val_loss: 1.0205 - val_accuracy: 0.6627\n",
      "Epoch 142/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7390 - accuracy: 0.7380 - val_loss: 1.0219 - val_accuracy: 0.6630\n",
      "Epoch 143/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7376 - accuracy: 0.7393 - val_loss: 1.0255 - val_accuracy: 0.6578\n",
      "Epoch 144/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7372 - accuracy: 0.7382 - val_loss: 1.0192 - val_accuracy: 0.6636\n",
      "Epoch 145/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7386 - accuracy: 0.7396 - val_loss: 1.0203 - val_accuracy: 0.6606\n",
      "Epoch 146/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7411 - accuracy: 0.7377 - val_loss: 1.0122 - val_accuracy: 0.6646\n",
      "Epoch 147/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7387 - accuracy: 0.7373 - val_loss: 1.0114 - val_accuracy: 0.6661\n",
      "Epoch 148/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7358 - accuracy: 0.7367 - val_loss: 1.0188 - val_accuracy: 0.6641\n",
      "Epoch 149/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7396 - accuracy: 0.7370 - val_loss: 1.0134 - val_accuracy: 0.6627\n",
      "Epoch 150/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7366 - accuracy: 0.7390 - val_loss: 1.0130 - val_accuracy: 0.6630\n",
      "Epoch 151/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7405 - accuracy: 0.7379 - val_loss: 1.0171 - val_accuracy: 0.6635\n",
      "Epoch 152/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7416 - accuracy: 0.7367 - val_loss: 1.0137 - val_accuracy: 0.6645\n",
      "Epoch 153/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7414 - accuracy: 0.7348 - val_loss: 1.0149 - val_accuracy: 0.6632\n",
      "Epoch 154/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7387 - accuracy: 0.7374 - val_loss: 1.0147 - val_accuracy: 0.6637\n",
      "Epoch 155/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7381 - accuracy: 0.7392 - val_loss: 1.0242 - val_accuracy: 0.6596\n",
      "Epoch 156/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7387 - accuracy: 0.7370 - val_loss: 1.0128 - val_accuracy: 0.6656\n",
      "Epoch 157/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7382 - accuracy: 0.7366 - val_loss: 1.0300 - val_accuracy: 0.6597\n",
      "Epoch 158/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7382 - accuracy: 0.7385 - val_loss: 1.0202 - val_accuracy: 0.6635\n",
      "Epoch 159/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7383 - accuracy: 0.7375 - val_loss: 1.0149 - val_accuracy: 0.6673\n",
      "Epoch 160/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7384 - accuracy: 0.7375 - val_loss: 1.0176 - val_accuracy: 0.6619\n",
      "Epoch 161/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7376 - accuracy: 0.7377 - val_loss: 1.0228 - val_accuracy: 0.6610\n",
      "Epoch 162/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7339 - accuracy: 0.7410 - val_loss: 1.0216 - val_accuracy: 0.6625\n",
      "Epoch 163/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7376 - accuracy: 0.7383 - val_loss: 1.0145 - val_accuracy: 0.6640\n",
      "Epoch 164/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7365 - accuracy: 0.7389 - val_loss: 1.0166 - val_accuracy: 0.6643\n",
      "Epoch 165/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7398 - accuracy: 0.7375 - val_loss: 1.0144 - val_accuracy: 0.6646\n",
      "Epoch 166/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7360 - accuracy: 0.7379 - val_loss: 1.0218 - val_accuracy: 0.6632\n",
      "Epoch 167/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7393 - accuracy: 0.7380 - val_loss: 1.0204 - val_accuracy: 0.6622\n",
      "Epoch 168/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7364 - accuracy: 0.7382 - val_loss: 1.0148 - val_accuracy: 0.6669\n",
      "Epoch 169/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7360 - accuracy: 0.7391 - val_loss: 1.0132 - val_accuracy: 0.6650\n",
      "Epoch 170/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7370 - accuracy: 0.7385 - val_loss: 1.0124 - val_accuracy: 0.6631\n",
      "Epoch 171/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7383 - accuracy: 0.7375 - val_loss: 1.0227 - val_accuracy: 0.6639\n",
      "Epoch 172/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7356 - accuracy: 0.7384 - val_loss: 1.0279 - val_accuracy: 0.6591\n",
      "Epoch 173/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7352 - accuracy: 0.7352 - val_loss: 1.0199 - val_accuracy: 0.6676\n",
      "Epoch 174/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7391 - accuracy: 0.7376 - val_loss: 1.0240 - val_accuracy: 0.6637\n",
      "Epoch 175/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7388 - accuracy: 0.7382 - val_loss: 1.0198 - val_accuracy: 0.6633\n",
      "Epoch 176/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7369 - accuracy: 0.7389 - val_loss: 1.0202 - val_accuracy: 0.6628\n",
      "Epoch 177/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7377 - accuracy: 0.7375 - val_loss: 1.0138 - val_accuracy: 0.6659\n",
      "Epoch 178/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7321 - accuracy: 0.7401 - val_loss: 1.0185 - val_accuracy: 0.6650\n",
      "Epoch 179/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7363 - accuracy: 0.7378 - val_loss: 1.0102 - val_accuracy: 0.6643\n",
      "Epoch 180/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7378 - accuracy: 0.7379 - val_loss: 1.0265 - val_accuracy: 0.6601\n",
      "Epoch 181/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7369 - accuracy: 0.7379 - val_loss: 1.0160 - val_accuracy: 0.6625\n",
      "Epoch 182/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7379 - accuracy: 0.7363 - val_loss: 1.0171 - val_accuracy: 0.6641\n",
      "Epoch 183/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7393 - accuracy: 0.7369 - val_loss: 1.0199 - val_accuracy: 0.6621\n",
      "Epoch 184/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7376 - accuracy: 0.7394 - val_loss: 1.0292 - val_accuracy: 0.6614\n",
      "Epoch 185/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7362 - accuracy: 0.7389 - val_loss: 1.0229 - val_accuracy: 0.6641\n",
      "Epoch 186/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7370 - accuracy: 0.7391 - val_loss: 1.0223 - val_accuracy: 0.6623\n",
      "Epoch 187/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7337 - accuracy: 0.7402 - val_loss: 1.0280 - val_accuracy: 0.6601\n",
      "Epoch 188/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7362 - accuracy: 0.7389 - val_loss: 1.0126 - val_accuracy: 0.6652\n",
      "Epoch 189/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7391 - accuracy: 0.7361 - val_loss: 1.0220 - val_accuracy: 0.6633\n",
      "Epoch 190/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.7377 - accuracy: 0.7374 - val_loss: 1.0249 - val_accuracy: 0.6622\n",
      "Epoch 191/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7380 - accuracy: 0.7373 - val_loss: 1.0182 - val_accuracy: 0.6620\n",
      "Epoch 192/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7333 - accuracy: 0.7398 - val_loss: 1.0211 - val_accuracy: 0.6609\n",
      "Epoch 193/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7377 - accuracy: 0.7383 - val_loss: 1.0211 - val_accuracy: 0.6633\n",
      "Epoch 194/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7411 - accuracy: 0.7369 - val_loss: 1.0139 - val_accuracy: 0.6665\n",
      "Epoch 195/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7394 - accuracy: 0.7385 - val_loss: 1.0195 - val_accuracy: 0.6622\n",
      "Epoch 196/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7368 - accuracy: 0.7373 - val_loss: 1.0255 - val_accuracy: 0.6612\n",
      "Epoch 197/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7386 - accuracy: 0.7378 - val_loss: 1.0179 - val_accuracy: 0.6625\n",
      "Epoch 198/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7363 - accuracy: 0.7393 - val_loss: 1.0192 - val_accuracy: 0.6637\n",
      "Epoch 199/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7383 - accuracy: 0.7393 - val_loss: 1.0182 - val_accuracy: 0.6658\n",
      "Epoch 200/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7350 - accuracy: 0.7405 - val_loss: 1.0169 - val_accuracy: 0.6637\n"
     ]
    }
   ],
   "source": [
    "# a higher learning rate for BN\n",
    "lr = 1e-2\n",
    "resnet_no_dense_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.001)\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logdir, update_freq='epoch', profile_batch=2\n",
    ")\n",
    "\n",
    "# We are going to train for 50 epochs\n",
    "history = resnet_no_dense_model.fit(\n",
    "    train_ds, epochs=200, validation_data=test_ds, \n",
    "    callbacks=[reduce_lr, tb_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: Add some capacity\n",
    "\n",
    "Looks better than 1st model but we can perhaps add capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_strided_slice_6  [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_BiasAdd_6 (Tenso [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 1, 1, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 23,727,690\n",
      "Trainable params: 135,882\n",
      "Non-trainable params: 23,591,808\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.ResNet50(input_shape=(IMG_SIZE, IMG_SIZE, 3), include_top=False)\n",
    "base_model.trainable = False\n",
    "def get_pretrained_model_dense(base_model, size):\n",
    "    inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    x = tf.keras.applications.resnet.preprocess_input(inputs)\n",
    "    x = base_model(x, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(size, activation='relu')(x)\n",
    "    outputs = Dense(NUM_CLASSES)(x)\n",
    "    _model = tf.keras.Model(inputs, outputs)    \n",
    "    return _model\n",
    "resnet_dense_model = get_pretrained_model_dense(base_model, 64)\n",
    "resnet_dense_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "  2/390 [..............................] - ETA: 46s - loss: 2.7405 - accuracy: 0.2344WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0104s vs `on_train_batch_end` time: 0.2291s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0104s vs `on_train_batch_end` time: 0.2291s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 7s 17ms/step - loss: 1.2451 - accuracy: 0.5873 - val_loss: 1.0947 - val_accuracy: 0.6281\n",
      "Epoch 2/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 1.0170 - accuracy: 0.6499 - val_loss: 1.0700 - val_accuracy: 0.6366\n",
      "Epoch 3/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.9406 - accuracy: 0.6760 - val_loss: 1.0825 - val_accuracy: 0.6463\n",
      "Epoch 4/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.9012 - accuracy: 0.6897 - val_loss: 1.1155 - val_accuracy: 0.6338\n",
      "Epoch 5/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.8687 - accuracy: 0.6993 - val_loss: 1.1106 - val_accuracy: 0.6452\n",
      "Epoch 6/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.8324 - accuracy: 0.7102 - val_loss: 1.1546 - val_accuracy: 0.6399\n",
      "Epoch 7/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.8041 - accuracy: 0.7216 - val_loss: 1.1431 - val_accuracy: 0.6361\n",
      "Epoch 8/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.6122 - accuracy: 0.7838 - val_loss: 1.1025 - val_accuracy: 0.6605\n",
      "Epoch 9/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5459 - accuracy: 0.8046 - val_loss: 1.1482 - val_accuracy: 0.6583\n",
      "Epoch 10/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5099 - accuracy: 0.8177 - val_loss: 1.2022 - val_accuracy: 0.6509\n",
      "Epoch 11/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4826 - accuracy: 0.8274 - val_loss: 1.2595 - val_accuracy: 0.6510\n",
      "Epoch 12/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4614 - accuracy: 0.8330 - val_loss: 1.2906 - val_accuracy: 0.6490\n",
      "Epoch 13/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4113 - accuracy: 0.8521 - val_loss: 1.3077 - val_accuracy: 0.6501\n",
      "Epoch 14/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.3911 - accuracy: 0.8601 - val_loss: 1.3509 - val_accuracy: 0.6519\n",
      "Epoch 15/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3808 - accuracy: 0.8630 - val_loss: 1.3737 - val_accuracy: 0.6492\n",
      "Epoch 16/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3680 - accuracy: 0.8680 - val_loss: 1.4070 - val_accuracy: 0.6525\n",
      "Epoch 17/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3555 - accuracy: 0.8727 - val_loss: 1.4737 - val_accuracy: 0.6475\n",
      "Epoch 18/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3438 - accuracy: 0.8758 - val_loss: 1.4932 - val_accuracy: 0.6479\n",
      "Epoch 19/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3349 - accuracy: 0.8801 - val_loss: 1.5347 - val_accuracy: 0.6497\n",
      "Epoch 20/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3251 - accuracy: 0.8827 - val_loss: 1.5805 - val_accuracy: 0.6472\n",
      "Epoch 21/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3158 - accuracy: 0.8855 - val_loss: 1.6007 - val_accuracy: 0.6459\n",
      "Epoch 22/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3066 - accuracy: 0.8904 - val_loss: 1.6347 - val_accuracy: 0.6418\n",
      "Epoch 23/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.2994 - accuracy: 0.8917 - val_loss: 1.6646 - val_accuracy: 0.6437\n",
      "Epoch 24/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.2907 - accuracy: 0.8957 - val_loss: 1.6924 - val_accuracy: 0.6437\n",
      "Epoch 25/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.2856 - accuracy: 0.8962 - val_loss: 1.7469 - val_accuracy: 0.6450\n",
      "Epoch 26/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.2755 - accuracy: 0.9004 - val_loss: 1.7590 - val_accuracy: 0.6385\n",
      "Epoch 27/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.2708 - accuracy: 0.9025 - val_loss: 1.8001 - val_accuracy: 0.6416\n",
      "Epoch 28/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.2605 - accuracy: 0.9067 - val_loss: 1.8239 - val_accuracy: 0.6448\n",
      "Epoch 29/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.2538 - accuracy: 0.9092 - val_loss: 1.8614 - val_accuracy: 0.6420\n",
      "Epoch 30/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.2540 - accuracy: 0.9096 - val_loss: 1.8794 - val_accuracy: 0.6405\n",
      "Epoch 31/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.2441 - accuracy: 0.9120 - val_loss: 1.9392 - val_accuracy: 0.6407\n",
      "Epoch 32/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.2389 - accuracy: 0.9154 - val_loss: 1.9386 - val_accuracy: 0.6426\n",
      "Epoch 33/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.2360 - accuracy: 0.9142 - val_loss: 1.9892 - val_accuracy: 0.6389\n",
      "Epoch 34/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.2300 - accuracy: 0.9168 - val_loss: 1.9873 - val_accuracy: 0.6389\n",
      "Epoch 35/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.2224 - accuracy: 0.9214 - val_loss: 2.0134 - val_accuracy: 0.6336\n",
      "Epoch 36/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.2204 - accuracy: 0.9194 - val_loss: 2.0803 - val_accuracy: 0.6384\n",
      "Epoch 37/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.2156 - accuracy: 0.9225 - val_loss: 2.0755 - val_accuracy: 0.6339\n",
      "Epoch 38/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.2120 - accuracy: 0.9242 - val_loss: 2.1044 - val_accuracy: 0.6392\n",
      "Epoch 39/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.2074 - accuracy: 0.9252 - val_loss: 2.1122 - val_accuracy: 0.6353\n",
      "Epoch 40/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.2022 - accuracy: 0.9276 - val_loss: 2.1576 - val_accuracy: 0.6386\n",
      "Epoch 41/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.2015 - accuracy: 0.9284 - val_loss: 2.1875 - val_accuracy: 0.6348\n",
      "Epoch 42/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.2018 - accuracy: 0.9275 - val_loss: 2.1962 - val_accuracy: 0.6344\n",
      "Epoch 43/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.1947 - accuracy: 0.9305 - val_loss: 2.2258 - val_accuracy: 0.6325\n",
      "Epoch 44/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1913 - accuracy: 0.9310 - val_loss: 2.2123 - val_accuracy: 0.6361\n",
      "Epoch 45/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1893 - accuracy: 0.9320 - val_loss: 2.2807 - val_accuracy: 0.6349\n",
      "Epoch 46/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1841 - accuracy: 0.9329 - val_loss: 2.2979 - val_accuracy: 0.6347\n",
      "Epoch 47/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1810 - accuracy: 0.9347 - val_loss: 2.3085 - val_accuracy: 0.6342\n",
      "Epoch 48/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1808 - accuracy: 0.9346 - val_loss: 2.3370 - val_accuracy: 0.6342\n",
      "Epoch 49/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.1788 - accuracy: 0.9357 - val_loss: 2.4261 - val_accuracy: 0.6306\n",
      "Epoch 50/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1779 - accuracy: 0.9359 - val_loss: 2.3820 - val_accuracy: 0.6322\n",
      "Epoch 51/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1732 - accuracy: 0.9379 - val_loss: 2.3975 - val_accuracy: 0.6326\n",
      "Epoch 52/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1700 - accuracy: 0.9395 - val_loss: 2.4017 - val_accuracy: 0.6340\n",
      "Epoch 53/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1644 - accuracy: 0.9415 - val_loss: 2.4544 - val_accuracy: 0.6329\n",
      "Epoch 54/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1673 - accuracy: 0.9405 - val_loss: 2.4447 - val_accuracy: 0.6326\n",
      "Epoch 55/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1632 - accuracy: 0.9416 - val_loss: 2.4752 - val_accuracy: 0.6316\n",
      "Epoch 56/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1626 - accuracy: 0.9415 - val_loss: 2.5235 - val_accuracy: 0.6321\n",
      "Epoch 57/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1590 - accuracy: 0.9438 - val_loss: 2.5492 - val_accuracy: 0.6332\n",
      "Epoch 58/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1572 - accuracy: 0.9444 - val_loss: 2.5651 - val_accuracy: 0.6329\n",
      "Epoch 59/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1557 - accuracy: 0.9439 - val_loss: 2.5871 - val_accuracy: 0.6294\n",
      "Epoch 60/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.1557 - accuracy: 0.9442 - val_loss: 2.5837 - val_accuracy: 0.6323\n",
      "Epoch 61/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.1534 - accuracy: 0.9459 - val_loss: 2.5907 - val_accuracy: 0.6287\n",
      "Epoch 62/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1536 - accuracy: 0.9448 - val_loss: 2.6072 - val_accuracy: 0.6316\n",
      "Epoch 63/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1478 - accuracy: 0.9480 - val_loss: 2.6601 - val_accuracy: 0.6298\n",
      "Epoch 64/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1470 - accuracy: 0.9473 - val_loss: 2.6632 - val_accuracy: 0.6301\n",
      "Epoch 65/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1428 - accuracy: 0.9488 - val_loss: 2.7312 - val_accuracy: 0.6310\n",
      "Epoch 66/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1456 - accuracy: 0.9486 - val_loss: 2.7054 - val_accuracy: 0.6288\n",
      "Epoch 67/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1416 - accuracy: 0.9491 - val_loss: 2.6791 - val_accuracy: 0.6330\n",
      "Epoch 68/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1437 - accuracy: 0.9497 - val_loss: 2.7109 - val_accuracy: 0.6312\n",
      "Epoch 69/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1419 - accuracy: 0.9493 - val_loss: 2.7618 - val_accuracy: 0.6280\n",
      "Epoch 70/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1380 - accuracy: 0.9507 - val_loss: 2.7597 - val_accuracy: 0.6289\n",
      "Epoch 71/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1384 - accuracy: 0.9508 - val_loss: 2.7761 - val_accuracy: 0.6294\n",
      "Epoch 72/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.1338 - accuracy: 0.9537 - val_loss: 2.8121 - val_accuracy: 0.6294\n",
      "Epoch 73/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1382 - accuracy: 0.9516 - val_loss: 2.8499 - val_accuracy: 0.6302\n",
      "Epoch 74/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1321 - accuracy: 0.9529 - val_loss: 2.8569 - val_accuracy: 0.6269\n",
      "Epoch 75/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1382 - accuracy: 0.9515 - val_loss: 2.8278 - val_accuracy: 0.6256\n",
      "Epoch 76/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1285 - accuracy: 0.9547 - val_loss: 2.8640 - val_accuracy: 0.6248\n",
      "Epoch 77/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1354 - accuracy: 0.9527 - val_loss: 2.8544 - val_accuracy: 0.6269\n",
      "Epoch 78/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1301 - accuracy: 0.9537 - val_loss: 2.8879 - val_accuracy: 0.6320\n",
      "Epoch 79/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1294 - accuracy: 0.9534 - val_loss: 2.8844 - val_accuracy: 0.6314\n",
      "Epoch 80/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1272 - accuracy: 0.9547 - val_loss: 2.8897 - val_accuracy: 0.6322\n",
      "Epoch 81/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1252 - accuracy: 0.9558 - val_loss: 2.8627 - val_accuracy: 0.6303\n",
      "Epoch 82/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1254 - accuracy: 0.9554 - val_loss: 2.9293 - val_accuracy: 0.6297\n",
      "Epoch 83/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1242 - accuracy: 0.9561 - val_loss: 2.9637 - val_accuracy: 0.6279\n",
      "Epoch 84/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.1277 - accuracy: 0.9549 - val_loss: 2.9388 - val_accuracy: 0.6303\n",
      "Epoch 85/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1210 - accuracy: 0.9564 - val_loss: 2.9401 - val_accuracy: 0.6269\n",
      "Epoch 86/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1214 - accuracy: 0.9577 - val_loss: 2.9821 - val_accuracy: 0.6270\n",
      "Epoch 87/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1230 - accuracy: 0.9563 - val_loss: 2.9947 - val_accuracy: 0.6274\n",
      "Epoch 88/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1185 - accuracy: 0.9581 - val_loss: 2.9944 - val_accuracy: 0.6326\n",
      "Epoch 89/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1206 - accuracy: 0.9566 - val_loss: 2.9816 - val_accuracy: 0.6245\n",
      "Epoch 90/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1231 - accuracy: 0.9561 - val_loss: 2.9760 - val_accuracy: 0.6252\n",
      "Epoch 91/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1173 - accuracy: 0.9578 - val_loss: 2.9836 - val_accuracy: 0.6248\n",
      "Epoch 92/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1190 - accuracy: 0.9573 - val_loss: 3.0251 - val_accuracy: 0.6247\n",
      "Epoch 93/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1142 - accuracy: 0.9600 - val_loss: 3.0926 - val_accuracy: 0.6257\n",
      "Epoch 94/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1160 - accuracy: 0.9587 - val_loss: 3.0895 - val_accuracy: 0.6270\n",
      "Epoch 95/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.1139 - accuracy: 0.9610 - val_loss: 3.0937 - val_accuracy: 0.6258\n",
      "Epoch 96/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1158 - accuracy: 0.9590 - val_loss: 3.1015 - val_accuracy: 0.6276\n",
      "Epoch 97/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1166 - accuracy: 0.9587 - val_loss: 3.0844 - val_accuracy: 0.6243\n",
      "Epoch 98/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1117 - accuracy: 0.9604 - val_loss: 3.1137 - val_accuracy: 0.6299\n",
      "Epoch 99/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1068 - accuracy: 0.9622 - val_loss: 3.1825 - val_accuracy: 0.6305\n",
      "Epoch 100/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1135 - accuracy: 0.9602 - val_loss: 3.1378 - val_accuracy: 0.6254\n",
      "Epoch 101/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1111 - accuracy: 0.9609 - val_loss: 3.1416 - val_accuracy: 0.6303\n",
      "Epoch 102/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1125 - accuracy: 0.9611 - val_loss: 3.1848 - val_accuracy: 0.6286\n",
      "Epoch 103/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1073 - accuracy: 0.9626 - val_loss: 3.1993 - val_accuracy: 0.6264\n",
      "Epoch 104/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1099 - accuracy: 0.9616 - val_loss: 3.2233 - val_accuracy: 0.6258\n",
      "Epoch 105/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1036 - accuracy: 0.9633 - val_loss: 3.2274 - val_accuracy: 0.6248\n",
      "Epoch 106/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1085 - accuracy: 0.9632 - val_loss: 3.2548 - val_accuracy: 0.6241\n",
      "Epoch 107/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.1036 - accuracy: 0.9644 - val_loss: 3.1936 - val_accuracy: 0.6260\n",
      "Epoch 108/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1060 - accuracy: 0.9630 - val_loss: 3.2468 - val_accuracy: 0.6278\n",
      "Epoch 109/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1079 - accuracy: 0.9617 - val_loss: 3.2732 - val_accuracy: 0.6241\n",
      "Epoch 110/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1050 - accuracy: 0.9638 - val_loss: 3.2561 - val_accuracy: 0.6205\n",
      "Epoch 111/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1013 - accuracy: 0.9645 - val_loss: 3.2624 - val_accuracy: 0.6251\n",
      "Epoch 112/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1062 - accuracy: 0.9627 - val_loss: 3.2616 - val_accuracy: 0.6261\n",
      "Epoch 113/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1061 - accuracy: 0.9635 - val_loss: 3.2847 - val_accuracy: 0.6245\n",
      "Epoch 114/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1008 - accuracy: 0.9648 - val_loss: 3.3430 - val_accuracy: 0.6231\n",
      "Epoch 115/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1019 - accuracy: 0.9637 - val_loss: 3.2965 - val_accuracy: 0.6220\n",
      "Epoch 116/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1092 - accuracy: 0.9629 - val_loss: 3.3244 - val_accuracy: 0.6251\n",
      "Epoch 117/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1055 - accuracy: 0.9641 - val_loss: 3.3317 - val_accuracy: 0.6223\n",
      "Epoch 118/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1001 - accuracy: 0.9657 - val_loss: 3.3696 - val_accuracy: 0.6247\n",
      "Epoch 119/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.1012 - accuracy: 0.9654 - val_loss: 3.3572 - val_accuracy: 0.6279\n",
      "Epoch 120/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1029 - accuracy: 0.9638 - val_loss: 3.4139 - val_accuracy: 0.6254\n",
      "Epoch 121/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0986 - accuracy: 0.9667 - val_loss: 3.3930 - val_accuracy: 0.6282\n",
      "Epoch 122/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1004 - accuracy: 0.9644 - val_loss: 3.4013 - val_accuracy: 0.6239\n",
      "Epoch 123/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0987 - accuracy: 0.9666 - val_loss: 3.3661 - val_accuracy: 0.6233\n",
      "Epoch 124/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0983 - accuracy: 0.9662 - val_loss: 3.3746 - val_accuracy: 0.6214\n",
      "Epoch 125/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1005 - accuracy: 0.9660 - val_loss: 3.3772 - val_accuracy: 0.6238\n",
      "Epoch 126/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.1005 - accuracy: 0.9661 - val_loss: 3.3866 - val_accuracy: 0.6207\n",
      "Epoch 127/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0971 - accuracy: 0.9662 - val_loss: 3.3612 - val_accuracy: 0.6225\n",
      "Epoch 128/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0977 - accuracy: 0.9663 - val_loss: 3.4121 - val_accuracy: 0.6249\n",
      "Epoch 129/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0991 - accuracy: 0.9662 - val_loss: 3.4258 - val_accuracy: 0.6239\n",
      "Epoch 130/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.0931 - accuracy: 0.9673 - val_loss: 3.4528 - val_accuracy: 0.6246\n",
      "Epoch 131/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.0962 - accuracy: 0.9668 - val_loss: 3.4199 - val_accuracy: 0.6234\n",
      "Epoch 132/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0968 - accuracy: 0.9670 - val_loss: 3.4952 - val_accuracy: 0.6224\n",
      "Epoch 133/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0943 - accuracy: 0.9673 - val_loss: 3.4935 - val_accuracy: 0.6209\n",
      "Epoch 134/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0915 - accuracy: 0.9687 - val_loss: 3.4260 - val_accuracy: 0.6211\n",
      "Epoch 135/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0961 - accuracy: 0.9667 - val_loss: 3.4737 - val_accuracy: 0.6243\n",
      "Epoch 136/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0930 - accuracy: 0.9681 - val_loss: 3.4800 - val_accuracy: 0.6223\n",
      "Epoch 137/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0912 - accuracy: 0.9689 - val_loss: 3.4685 - val_accuracy: 0.6229\n",
      "Epoch 138/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0919 - accuracy: 0.9691 - val_loss: 3.4789 - val_accuracy: 0.6228\n",
      "Epoch 139/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0970 - accuracy: 0.9672 - val_loss: 3.5631 - val_accuracy: 0.6229\n",
      "Epoch 140/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0938 - accuracy: 0.9676 - val_loss: 3.5009 - val_accuracy: 0.6221\n",
      "Epoch 141/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0924 - accuracy: 0.9680 - val_loss: 3.5784 - val_accuracy: 0.6280\n",
      "Epoch 142/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.0944 - accuracy: 0.9669 - val_loss: 3.5693 - val_accuracy: 0.6239\n",
      "Epoch 143/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0940 - accuracy: 0.9670 - val_loss: 3.5570 - val_accuracy: 0.6198\n",
      "Epoch 144/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0917 - accuracy: 0.9682 - val_loss: 3.5080 - val_accuracy: 0.6237\n",
      "Epoch 145/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0907 - accuracy: 0.9692 - val_loss: 3.6394 - val_accuracy: 0.6213\n",
      "Epoch 146/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0925 - accuracy: 0.9682 - val_loss: 3.5570 - val_accuracy: 0.6195\n",
      "Epoch 147/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0911 - accuracy: 0.9688 - val_loss: 3.5339 - val_accuracy: 0.6221\n",
      "Epoch 148/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0856 - accuracy: 0.9704 - val_loss: 3.5601 - val_accuracy: 0.6199\n",
      "Epoch 149/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0929 - accuracy: 0.9683 - val_loss: 3.5457 - val_accuracy: 0.6239\n",
      "Epoch 150/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0886 - accuracy: 0.9692 - val_loss: 3.5774 - val_accuracy: 0.6266\n",
      "Epoch 151/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0881 - accuracy: 0.9695 - val_loss: 3.5878 - val_accuracy: 0.6261\n",
      "Epoch 152/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0911 - accuracy: 0.9690 - val_loss: 3.6988 - val_accuracy: 0.6288\n",
      "Epoch 153/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0915 - accuracy: 0.9688 - val_loss: 3.5958 - val_accuracy: 0.6211\n",
      "Epoch 154/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.0875 - accuracy: 0.9703 - val_loss: 3.5968 - val_accuracy: 0.6264\n",
      "Epoch 155/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0885 - accuracy: 0.9696 - val_loss: 3.6622 - val_accuracy: 0.6215\n",
      "Epoch 156/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0870 - accuracy: 0.9708 - val_loss: 3.5904 - val_accuracy: 0.6238\n",
      "Epoch 157/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0850 - accuracy: 0.9705 - val_loss: 3.6480 - val_accuracy: 0.6294\n",
      "Epoch 158/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0815 - accuracy: 0.9721 - val_loss: 3.6491 - val_accuracy: 0.6231\n",
      "Epoch 159/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0859 - accuracy: 0.9707 - val_loss: 3.6471 - val_accuracy: 0.6246\n",
      "Epoch 160/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0891 - accuracy: 0.9697 - val_loss: 3.7030 - val_accuracy: 0.6265\n",
      "Epoch 161/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0886 - accuracy: 0.9691 - val_loss: 3.6576 - val_accuracy: 0.6208\n",
      "Epoch 162/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0896 - accuracy: 0.9708 - val_loss: 3.6461 - val_accuracy: 0.6193\n",
      "Epoch 163/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0824 - accuracy: 0.9712 - val_loss: 3.7058 - val_accuracy: 0.6191\n",
      "Epoch 164/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0852 - accuracy: 0.9706 - val_loss: 3.6827 - val_accuracy: 0.6305\n",
      "Epoch 165/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.0869 - accuracy: 0.9703 - val_loss: 3.6813 - val_accuracy: 0.6266\n",
      "Epoch 166/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.0861 - accuracy: 0.9702 - val_loss: 3.6732 - val_accuracy: 0.6246\n",
      "Epoch 167/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0844 - accuracy: 0.9707 - val_loss: 3.6549 - val_accuracy: 0.6208\n",
      "Epoch 168/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0850 - accuracy: 0.9711 - val_loss: 3.6651 - val_accuracy: 0.6231\n",
      "Epoch 169/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0857 - accuracy: 0.9702 - val_loss: 3.7225 - val_accuracy: 0.6258\n",
      "Epoch 170/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0834 - accuracy: 0.9721 - val_loss: 3.6751 - val_accuracy: 0.6254\n",
      "Epoch 171/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0803 - accuracy: 0.9726 - val_loss: 3.7432 - val_accuracy: 0.6206\n",
      "Epoch 172/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0854 - accuracy: 0.9713 - val_loss: 3.7556 - val_accuracy: 0.6239\n",
      "Epoch 173/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0854 - accuracy: 0.9705 - val_loss: 3.7289 - val_accuracy: 0.6239\n",
      "Epoch 174/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0840 - accuracy: 0.9712 - val_loss: 3.7453 - val_accuracy: 0.6219\n",
      "Epoch 175/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0809 - accuracy: 0.9717 - val_loss: 3.7537 - val_accuracy: 0.6261\n",
      "Epoch 176/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0828 - accuracy: 0.9711 - val_loss: 3.7551 - val_accuracy: 0.6201\n",
      "Epoch 177/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.0880 - accuracy: 0.9705 - val_loss: 3.7614 - val_accuracy: 0.6198\n",
      "Epoch 178/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0806 - accuracy: 0.9731 - val_loss: 3.6659 - val_accuracy: 0.6211\n",
      "Epoch 179/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0813 - accuracy: 0.9731 - val_loss: 3.7982 - val_accuracy: 0.6199\n",
      "Epoch 180/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0771 - accuracy: 0.9740 - val_loss: 3.8412 - val_accuracy: 0.6253\n",
      "Epoch 181/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0849 - accuracy: 0.9715 - val_loss: 3.7399 - val_accuracy: 0.6224\n",
      "Epoch 182/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0779 - accuracy: 0.9734 - val_loss: 3.8565 - val_accuracy: 0.6252\n",
      "Epoch 183/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0807 - accuracy: 0.9730 - val_loss: 3.7995 - val_accuracy: 0.6219\n",
      "Epoch 184/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0806 - accuracy: 0.9733 - val_loss: 3.8003 - val_accuracy: 0.6213\n",
      "Epoch 185/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0804 - accuracy: 0.9735 - val_loss: 3.8134 - val_accuracy: 0.6243\n",
      "Epoch 186/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0832 - accuracy: 0.9720 - val_loss: 3.7808 - val_accuracy: 0.6221\n",
      "Epoch 187/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0772 - accuracy: 0.9727 - val_loss: 3.8638 - val_accuracy: 0.6230\n",
      "Epoch 188/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0813 - accuracy: 0.9726 - val_loss: 3.7765 - val_accuracy: 0.6220\n",
      "Epoch 189/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.0826 - accuracy: 0.9721 - val_loss: 3.8262 - val_accuracy: 0.6293\n",
      "Epoch 190/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0824 - accuracy: 0.9727 - val_loss: 3.7532 - val_accuracy: 0.6227\n",
      "Epoch 191/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0785 - accuracy: 0.9738 - val_loss: 3.7546 - val_accuracy: 0.6236\n",
      "Epoch 192/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0788 - accuracy: 0.9735 - val_loss: 3.8789 - val_accuracy: 0.6248\n",
      "Epoch 193/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0817 - accuracy: 0.9724 - val_loss: 3.8093 - val_accuracy: 0.6238\n",
      "Epoch 194/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0763 - accuracy: 0.9740 - val_loss: 3.8514 - val_accuracy: 0.6275\n",
      "Epoch 195/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0781 - accuracy: 0.9732 - val_loss: 3.8467 - val_accuracy: 0.6189\n",
      "Epoch 196/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0780 - accuracy: 0.9731 - val_loss: 3.8881 - val_accuracy: 0.6210\n",
      "Epoch 197/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0805 - accuracy: 0.9739 - val_loss: 3.8154 - val_accuracy: 0.6225\n",
      "Epoch 198/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0816 - accuracy: 0.9725 - val_loss: 3.8650 - val_accuracy: 0.6247\n",
      "Epoch 199/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0772 - accuracy: 0.9737 - val_loss: 3.9061 - val_accuracy: 0.6236\n",
      "Epoch 200/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.0796 - accuracy: 0.9736 - val_loss: 3.9000 - val_accuracy: 0.6206\n"
     ]
    }
   ],
   "source": [
    "# a higher learning rate for BN\n",
    "lr = 1e-2\n",
    "resnet_dense_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.001)\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logdir, update_freq='epoch', profile_batch=2\n",
    ")\n",
    "\n",
    "# We are going to train for 50 epochs\n",
    "history = resnet_dense_model.fit(\n",
    "    train_ds, epochs=200, validation_data=test_ds, \n",
    "    callbacks=[reduce_lr, tb_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4: Resnet50 + GAP + BN + Dense + Dropout\n",
    "\n",
    "Add dropout to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_strided_slice_7  [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_BiasAdd_7 (Tenso [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 1, 1, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_7 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 23,727,690\n",
      "Trainable params: 135,882\n",
      "Non-trainable params: 23,591,808\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.ResNet50(input_shape=(IMG_SIZE, IMG_SIZE, 3), include_top=False)\n",
    "base_model.trainable = False\n",
    "def get_pretrained_model_dense(base_model, size, drop=0.2):\n",
    "    inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    x = tf.keras.applications.resnet.preprocess_input(inputs)\n",
    "    x = base_model(x, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(drop)(x)\n",
    "    x = Dense(size, activation='relu')(x)\n",
    "    outputs = Dense(NUM_CLASSES)(x)\n",
    "    _model = tf.keras.Model(inputs, outputs)    \n",
    "    return _model\n",
    "resnet_dense_do_model = get_pretrained_model_dense(base_model, 64)\n",
    "resnet_dense_do_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "  2/390 [..............................] - ETA: 46s - loss: 2.8400 - accuracy: 0.1836WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0164s vs `on_train_batch_end` time: 0.2214s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0164s vs `on_train_batch_end` time: 0.2214s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 6s 17ms/step - loss: 1.2971 - accuracy: 0.5721 - val_loss: 1.0964 - val_accuracy: 0.6187\n",
      "Epoch 2/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 1.0757 - accuracy: 0.6271 - val_loss: 1.0455 - val_accuracy: 0.6398\n",
      "Epoch 3/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 1.0176 - accuracy: 0.6475 - val_loss: 1.0752 - val_accuracy: 0.6285\n",
      "Epoch 4/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9974 - accuracy: 0.6565 - val_loss: 1.0881 - val_accuracy: 0.6312\n",
      "Epoch 5/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9726 - accuracy: 0.6632 - val_loss: 1.0363 - val_accuracy: 0.6484\n",
      "Epoch 6/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.9590 - accuracy: 0.6695 - val_loss: 1.0935 - val_accuracy: 0.6326\n",
      "Epoch 7/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.9417 - accuracy: 0.6757 - val_loss: 1.0896 - val_accuracy: 0.6360\n",
      "Epoch 8/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9301 - accuracy: 0.6788 - val_loss: 1.0720 - val_accuracy: 0.6443\n",
      "Epoch 9/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.9182 - accuracy: 0.6831 - val_loss: 1.1026 - val_accuracy: 0.6425\n",
      "Epoch 10/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.9057 - accuracy: 0.6899 - val_loss: 1.0958 - val_accuracy: 0.6355\n",
      "Epoch 11/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7531 - accuracy: 0.7372 - val_loss: 1.0074 - val_accuracy: 0.6582\n",
      "Epoch 12/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7098 - accuracy: 0.7491 - val_loss: 1.0182 - val_accuracy: 0.6604\n",
      "Epoch 13/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.6903 - accuracy: 0.7573 - val_loss: 1.0132 - val_accuracy: 0.6625\n",
      "Epoch 14/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.6733 - accuracy: 0.7613 - val_loss: 1.0285 - val_accuracy: 0.6636\n",
      "Epoch 15/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.6660 - accuracy: 0.7631 - val_loss: 1.0188 - val_accuracy: 0.6621\n",
      "Epoch 16/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.6503 - accuracy: 0.7704 - val_loss: 1.0271 - val_accuracy: 0.6607\n",
      "Epoch 17/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.6244 - accuracy: 0.7780 - val_loss: 1.0222 - val_accuracy: 0.6647\n",
      "Epoch 18/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.6093 - accuracy: 0.7831 - val_loss: 1.0403 - val_accuracy: 0.6696\n",
      "Epoch 19/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.6066 - accuracy: 0.7853 - val_loss: 1.0385 - val_accuracy: 0.6695\n",
      "Epoch 20/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5983 - accuracy: 0.7867 - val_loss: 1.0447 - val_accuracy: 0.6645\n",
      "Epoch 21/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5914 - accuracy: 0.7908 - val_loss: 1.0512 - val_accuracy: 0.6636\n",
      "Epoch 22/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5886 - accuracy: 0.7893 - val_loss: 1.0477 - val_accuracy: 0.6654\n",
      "Epoch 23/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5835 - accuracy: 0.7909 - val_loss: 1.0520 - val_accuracy: 0.6680\n",
      "Epoch 24/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5771 - accuracy: 0.7929 - val_loss: 1.0693 - val_accuracy: 0.6641\n",
      "Epoch 25/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5753 - accuracy: 0.7926 - val_loss: 1.0685 - val_accuracy: 0.6627\n",
      "Epoch 26/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5694 - accuracy: 0.7949 - val_loss: 1.0728 - val_accuracy: 0.6627\n",
      "Epoch 27/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.5693 - accuracy: 0.7969 - val_loss: 1.0689 - val_accuracy: 0.6642\n",
      "Epoch 28/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.5598 - accuracy: 0.7982 - val_loss: 1.0761 - val_accuracy: 0.6640\n",
      "Epoch 29/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5614 - accuracy: 0.7988 - val_loss: 1.0790 - val_accuracy: 0.6628\n",
      "Epoch 30/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5525 - accuracy: 0.8010 - val_loss: 1.0850 - val_accuracy: 0.6662\n",
      "Epoch 31/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5503 - accuracy: 0.8049 - val_loss: 1.0839 - val_accuracy: 0.6640\n",
      "Epoch 32/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5499 - accuracy: 0.8052 - val_loss: 1.0877 - val_accuracy: 0.6628\n",
      "Epoch 33/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5391 - accuracy: 0.8069 - val_loss: 1.0943 - val_accuracy: 0.6631\n",
      "Epoch 34/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5399 - accuracy: 0.8086 - val_loss: 1.1025 - val_accuracy: 0.6598\n",
      "Epoch 35/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5346 - accuracy: 0.8087 - val_loss: 1.1091 - val_accuracy: 0.6629\n",
      "Epoch 36/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5291 - accuracy: 0.8107 - val_loss: 1.1091 - val_accuracy: 0.6648\n",
      "Epoch 37/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5276 - accuracy: 0.8112 - val_loss: 1.1115 - val_accuracy: 0.6624\n",
      "Epoch 38/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5255 - accuracy: 0.8118 - val_loss: 1.1105 - val_accuracy: 0.6651\n",
      "Epoch 39/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.5223 - accuracy: 0.8138 - val_loss: 1.1140 - val_accuracy: 0.6625\n",
      "Epoch 40/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.5205 - accuracy: 0.8131 - val_loss: 1.1184 - val_accuracy: 0.6667\n",
      "Epoch 41/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5169 - accuracy: 0.8143 - val_loss: 1.1272 - val_accuracy: 0.6630\n",
      "Epoch 42/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5141 - accuracy: 0.8138 - val_loss: 1.1223 - val_accuracy: 0.6603\n",
      "Epoch 43/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5189 - accuracy: 0.8136 - val_loss: 1.1297 - val_accuracy: 0.6579\n",
      "Epoch 44/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5097 - accuracy: 0.8173 - val_loss: 1.1362 - val_accuracy: 0.6618\n",
      "Epoch 45/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5044 - accuracy: 0.8179 - val_loss: 1.1372 - val_accuracy: 0.6597\n",
      "Epoch 46/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5024 - accuracy: 0.8202 - val_loss: 1.1454 - val_accuracy: 0.6575\n",
      "Epoch 47/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5036 - accuracy: 0.8187 - val_loss: 1.1408 - val_accuracy: 0.6615\n",
      "Epoch 48/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5030 - accuracy: 0.8193 - val_loss: 1.1544 - val_accuracy: 0.6619\n",
      "Epoch 49/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5009 - accuracy: 0.8188 - val_loss: 1.1437 - val_accuracy: 0.6602\n",
      "Epoch 50/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4990 - accuracy: 0.8217 - val_loss: 1.1541 - val_accuracy: 0.6595\n",
      "Epoch 51/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4954 - accuracy: 0.8221 - val_loss: 1.1564 - val_accuracy: 0.6605\n",
      "Epoch 52/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4911 - accuracy: 0.8235 - val_loss: 1.1680 - val_accuracy: 0.6609\n",
      "Epoch 53/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4925 - accuracy: 0.8238 - val_loss: 1.1695 - val_accuracy: 0.6566\n",
      "Epoch 54/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4838 - accuracy: 0.8269 - val_loss: 1.1622 - val_accuracy: 0.6590\n",
      "Epoch 55/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4872 - accuracy: 0.8248 - val_loss: 1.1656 - val_accuracy: 0.6612\n",
      "Epoch 56/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4879 - accuracy: 0.8229 - val_loss: 1.1708 - val_accuracy: 0.6573\n",
      "Epoch 57/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4801 - accuracy: 0.8274 - val_loss: 1.1808 - val_accuracy: 0.6559\n",
      "Epoch 58/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4788 - accuracy: 0.8277 - val_loss: 1.1685 - val_accuracy: 0.6595\n",
      "Epoch 59/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4805 - accuracy: 0.8271 - val_loss: 1.1873 - val_accuracy: 0.6601\n",
      "Epoch 60/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4769 - accuracy: 0.8292 - val_loss: 1.1743 - val_accuracy: 0.6587\n",
      "Epoch 61/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4800 - accuracy: 0.8265 - val_loss: 1.1682 - val_accuracy: 0.6584\n",
      "Epoch 62/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4726 - accuracy: 0.8298 - val_loss: 1.1896 - val_accuracy: 0.6550\n",
      "Epoch 63/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4781 - accuracy: 0.8300 - val_loss: 1.1898 - val_accuracy: 0.6587\n",
      "Epoch 64/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4692 - accuracy: 0.8324 - val_loss: 1.1833 - val_accuracy: 0.6576\n",
      "Epoch 65/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4706 - accuracy: 0.8292 - val_loss: 1.1946 - val_accuracy: 0.6568\n",
      "Epoch 66/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4675 - accuracy: 0.8310 - val_loss: 1.1936 - val_accuracy: 0.6538\n",
      "Epoch 67/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4648 - accuracy: 0.8332 - val_loss: 1.1932 - val_accuracy: 0.6582\n",
      "Epoch 68/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4683 - accuracy: 0.8312 - val_loss: 1.1944 - val_accuracy: 0.6574\n",
      "Epoch 69/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4639 - accuracy: 0.8324 - val_loss: 1.1857 - val_accuracy: 0.6558\n",
      "Epoch 70/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4561 - accuracy: 0.8368 - val_loss: 1.1992 - val_accuracy: 0.6557\n",
      "Epoch 71/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4622 - accuracy: 0.8334 - val_loss: 1.2085 - val_accuracy: 0.6570\n",
      "Epoch 72/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4644 - accuracy: 0.8346 - val_loss: 1.1919 - val_accuracy: 0.6557\n",
      "Epoch 73/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4571 - accuracy: 0.8355 - val_loss: 1.2059 - val_accuracy: 0.6525\n",
      "Epoch 74/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4570 - accuracy: 0.8368 - val_loss: 1.2132 - val_accuracy: 0.6531\n",
      "Epoch 75/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4487 - accuracy: 0.8385 - val_loss: 1.2092 - val_accuracy: 0.6541\n",
      "Epoch 76/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4536 - accuracy: 0.8363 - val_loss: 1.2117 - val_accuracy: 0.6568\n",
      "Epoch 77/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4539 - accuracy: 0.8362 - val_loss: 1.2246 - val_accuracy: 0.6555\n",
      "Epoch 78/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4528 - accuracy: 0.8381 - val_loss: 1.2250 - val_accuracy: 0.6572\n",
      "Epoch 79/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4533 - accuracy: 0.8384 - val_loss: 1.2070 - val_accuracy: 0.6516\n",
      "Epoch 80/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4503 - accuracy: 0.8373 - val_loss: 1.2279 - val_accuracy: 0.6506\n",
      "Epoch 81/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4509 - accuracy: 0.8383 - val_loss: 1.2226 - val_accuracy: 0.6575\n",
      "Epoch 82/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4436 - accuracy: 0.8405 - val_loss: 1.2320 - val_accuracy: 0.6542\n",
      "Epoch 83/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4414 - accuracy: 0.8391 - val_loss: 1.2253 - val_accuracy: 0.6521\n",
      "Epoch 84/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4450 - accuracy: 0.8396 - val_loss: 1.2365 - val_accuracy: 0.6520\n",
      "Epoch 85/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4423 - accuracy: 0.8393 - val_loss: 1.2417 - val_accuracy: 0.6537\n",
      "Epoch 86/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4451 - accuracy: 0.8404 - val_loss: 1.2321 - val_accuracy: 0.6523\n",
      "Epoch 87/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4359 - accuracy: 0.8433 - val_loss: 1.2318 - val_accuracy: 0.6576\n",
      "Epoch 88/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4391 - accuracy: 0.8418 - val_loss: 1.2252 - val_accuracy: 0.6570\n",
      "Epoch 89/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4337 - accuracy: 0.8454 - val_loss: 1.2547 - val_accuracy: 0.6548\n",
      "Epoch 90/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4416 - accuracy: 0.8413 - val_loss: 1.2528 - val_accuracy: 0.6528\n",
      "Epoch 91/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4415 - accuracy: 0.8425 - val_loss: 1.2392 - val_accuracy: 0.6566\n",
      "Epoch 92/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4342 - accuracy: 0.8429 - val_loss: 1.2519 - val_accuracy: 0.6557\n",
      "Epoch 93/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4359 - accuracy: 0.8440 - val_loss: 1.2476 - val_accuracy: 0.6576\n",
      "Epoch 94/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4357 - accuracy: 0.8442 - val_loss: 1.2380 - val_accuracy: 0.6573\n",
      "Epoch 95/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4363 - accuracy: 0.8426 - val_loss: 1.2580 - val_accuracy: 0.6551\n",
      "Epoch 96/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4333 - accuracy: 0.8452 - val_loss: 1.2428 - val_accuracy: 0.6532\n",
      "Epoch 97/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4341 - accuracy: 0.8443 - val_loss: 1.2336 - val_accuracy: 0.6549\n",
      "Epoch 98/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4310 - accuracy: 0.8448 - val_loss: 1.2453 - val_accuracy: 0.6538\n",
      "Epoch 99/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4344 - accuracy: 0.8439 - val_loss: 1.2618 - val_accuracy: 0.6523\n",
      "Epoch 100/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4289 - accuracy: 0.8457 - val_loss: 1.2480 - val_accuracy: 0.6528\n",
      "Epoch 101/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4290 - accuracy: 0.8457 - val_loss: 1.2619 - val_accuracy: 0.6513\n",
      "Epoch 102/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4219 - accuracy: 0.8482 - val_loss: 1.2644 - val_accuracy: 0.6516\n",
      "Epoch 103/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4309 - accuracy: 0.8469 - val_loss: 1.2580 - val_accuracy: 0.6518\n",
      "Epoch 104/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4198 - accuracy: 0.8501 - val_loss: 1.2543 - val_accuracy: 0.6545\n",
      "Epoch 105/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4268 - accuracy: 0.8464 - val_loss: 1.2597 - val_accuracy: 0.6524\n",
      "Epoch 106/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4212 - accuracy: 0.8475 - val_loss: 1.2674 - val_accuracy: 0.6499\n",
      "Epoch 107/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4211 - accuracy: 0.8491 - val_loss: 1.2546 - val_accuracy: 0.6547\n",
      "Epoch 108/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4229 - accuracy: 0.8498 - val_loss: 1.2641 - val_accuracy: 0.6512\n",
      "Epoch 109/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4211 - accuracy: 0.8476 - val_loss: 1.2609 - val_accuracy: 0.6539\n",
      "Epoch 110/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4189 - accuracy: 0.8485 - val_loss: 1.2571 - val_accuracy: 0.6516\n",
      "Epoch 111/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4209 - accuracy: 0.8495 - val_loss: 1.2610 - val_accuracy: 0.6489\n",
      "Epoch 112/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4159 - accuracy: 0.8509 - val_loss: 1.2807 - val_accuracy: 0.6501\n",
      "Epoch 113/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4177 - accuracy: 0.8499 - val_loss: 1.2769 - val_accuracy: 0.6479\n",
      "Epoch 114/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4217 - accuracy: 0.8486 - val_loss: 1.2783 - val_accuracy: 0.6497\n",
      "Epoch 115/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4181 - accuracy: 0.8495 - val_loss: 1.2632 - val_accuracy: 0.6506\n",
      "Epoch 116/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4139 - accuracy: 0.8513 - val_loss: 1.2909 - val_accuracy: 0.6488\n",
      "Epoch 117/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4112 - accuracy: 0.8520 - val_loss: 1.2741 - val_accuracy: 0.6472\n",
      "Epoch 118/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4143 - accuracy: 0.8526 - val_loss: 1.2650 - val_accuracy: 0.6489\n",
      "Epoch 119/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4127 - accuracy: 0.8517 - val_loss: 1.2796 - val_accuracy: 0.6464\n",
      "Epoch 120/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4095 - accuracy: 0.8541 - val_loss: 1.2810 - val_accuracy: 0.6502\n",
      "Epoch 121/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4125 - accuracy: 0.8530 - val_loss: 1.2938 - val_accuracy: 0.6487\n",
      "Epoch 122/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4151 - accuracy: 0.8518 - val_loss: 1.2903 - val_accuracy: 0.6508\n",
      "Epoch 123/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4116 - accuracy: 0.8520 - val_loss: 1.2911 - val_accuracy: 0.6473\n",
      "Epoch 124/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4161 - accuracy: 0.8508 - val_loss: 1.2850 - val_accuracy: 0.6482\n",
      "Epoch 125/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4123 - accuracy: 0.8518 - val_loss: 1.2806 - val_accuracy: 0.6499\n",
      "Epoch 126/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4087 - accuracy: 0.8540 - val_loss: 1.2888 - val_accuracy: 0.6483\n",
      "Epoch 127/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4107 - accuracy: 0.8508 - val_loss: 1.2898 - val_accuracy: 0.6498\n",
      "Epoch 128/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4134 - accuracy: 0.8503 - val_loss: 1.2838 - val_accuracy: 0.6501\n",
      "Epoch 129/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4102 - accuracy: 0.8516 - val_loss: 1.2875 - val_accuracy: 0.6507\n",
      "Epoch 130/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4048 - accuracy: 0.8554 - val_loss: 1.2965 - val_accuracy: 0.6513\n",
      "Epoch 131/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4077 - accuracy: 0.8528 - val_loss: 1.2894 - val_accuracy: 0.6504\n",
      "Epoch 132/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4052 - accuracy: 0.8558 - val_loss: 1.2951 - val_accuracy: 0.6517\n",
      "Epoch 133/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4060 - accuracy: 0.8558 - val_loss: 1.2874 - val_accuracy: 0.6509\n",
      "Epoch 134/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4029 - accuracy: 0.8558 - val_loss: 1.2978 - val_accuracy: 0.6485\n",
      "Epoch 135/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4061 - accuracy: 0.8549 - val_loss: 1.3050 - val_accuracy: 0.6513\n",
      "Epoch 136/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4064 - accuracy: 0.8539 - val_loss: 1.2985 - val_accuracy: 0.6493\n",
      "Epoch 137/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4082 - accuracy: 0.8531 - val_loss: 1.2972 - val_accuracy: 0.6518\n",
      "Epoch 138/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4008 - accuracy: 0.8558 - val_loss: 1.2995 - val_accuracy: 0.6475\n",
      "Epoch 139/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4005 - accuracy: 0.8577 - val_loss: 1.3073 - val_accuracy: 0.6536\n",
      "Epoch 140/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4000 - accuracy: 0.8572 - val_loss: 1.2943 - val_accuracy: 0.6507\n",
      "Epoch 141/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3995 - accuracy: 0.8573 - val_loss: 1.3068 - val_accuracy: 0.6505\n",
      "Epoch 142/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3974 - accuracy: 0.8590 - val_loss: 1.2977 - val_accuracy: 0.6450\n",
      "Epoch 143/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3956 - accuracy: 0.8577 - val_loss: 1.2986 - val_accuracy: 0.6466\n",
      "Epoch 144/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3970 - accuracy: 0.8591 - val_loss: 1.3186 - val_accuracy: 0.6477\n",
      "Epoch 145/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4031 - accuracy: 0.8533 - val_loss: 1.3032 - val_accuracy: 0.6468\n",
      "Epoch 146/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4012 - accuracy: 0.8568 - val_loss: 1.3153 - val_accuracy: 0.6491\n",
      "Epoch 147/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3970 - accuracy: 0.8582 - val_loss: 1.3187 - val_accuracy: 0.6466\n",
      "Epoch 148/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3959 - accuracy: 0.8571 - val_loss: 1.3276 - val_accuracy: 0.6484\n",
      "Epoch 149/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3969 - accuracy: 0.8575 - val_loss: 1.3271 - val_accuracy: 0.6477\n",
      "Epoch 150/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3993 - accuracy: 0.8583 - val_loss: 1.3223 - val_accuracy: 0.6459\n",
      "Epoch 151/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3947 - accuracy: 0.8597 - val_loss: 1.3341 - val_accuracy: 0.6480\n",
      "Epoch 152/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3984 - accuracy: 0.8574 - val_loss: 1.3170 - val_accuracy: 0.6425\n",
      "Epoch 153/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3964 - accuracy: 0.8574 - val_loss: 1.3210 - val_accuracy: 0.6457\n",
      "Epoch 154/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3949 - accuracy: 0.8597 - val_loss: 1.3174 - val_accuracy: 0.6516\n",
      "Epoch 155/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3954 - accuracy: 0.8588 - val_loss: 1.3181 - val_accuracy: 0.6460\n",
      "Epoch 156/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.3944 - accuracy: 0.8583 - val_loss: 1.3074 - val_accuracy: 0.6492\n",
      "Epoch 157/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.3888 - accuracy: 0.8608 - val_loss: 1.3219 - val_accuracy: 0.6503\n",
      "Epoch 158/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3948 - accuracy: 0.8601 - val_loss: 1.3210 - val_accuracy: 0.6499\n",
      "Epoch 159/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3907 - accuracy: 0.8598 - val_loss: 1.3290 - val_accuracy: 0.6470\n",
      "Epoch 160/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3930 - accuracy: 0.8597 - val_loss: 1.3392 - val_accuracy: 0.6446\n",
      "Epoch 161/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3945 - accuracy: 0.8600 - val_loss: 1.3207 - val_accuracy: 0.6438\n",
      "Epoch 162/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3946 - accuracy: 0.8573 - val_loss: 1.3178 - val_accuracy: 0.6448\n",
      "Epoch 163/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3910 - accuracy: 0.8607 - val_loss: 1.3271 - val_accuracy: 0.6456\n",
      "Epoch 164/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3903 - accuracy: 0.8603 - val_loss: 1.3397 - val_accuracy: 0.6452\n",
      "Epoch 165/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3944 - accuracy: 0.8593 - val_loss: 1.3309 - val_accuracy: 0.6497\n",
      "Epoch 166/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3916 - accuracy: 0.8597 - val_loss: 1.3128 - val_accuracy: 0.6456\n",
      "Epoch 167/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3908 - accuracy: 0.8593 - val_loss: 1.3339 - val_accuracy: 0.6493\n",
      "Epoch 168/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.3934 - accuracy: 0.8584 - val_loss: 1.3218 - val_accuracy: 0.6478\n",
      "Epoch 169/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3886 - accuracy: 0.8602 - val_loss: 1.3337 - val_accuracy: 0.6468\n",
      "Epoch 170/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3917 - accuracy: 0.8600 - val_loss: 1.3302 - val_accuracy: 0.6475\n",
      "Epoch 171/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3842 - accuracy: 0.8616 - val_loss: 1.3160 - val_accuracy: 0.6485\n",
      "Epoch 172/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3844 - accuracy: 0.8629 - val_loss: 1.3299 - val_accuracy: 0.6498\n",
      "Epoch 173/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3911 - accuracy: 0.8595 - val_loss: 1.3545 - val_accuracy: 0.6485\n",
      "Epoch 174/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3905 - accuracy: 0.8606 - val_loss: 1.3252 - val_accuracy: 0.6473\n",
      "Epoch 175/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3863 - accuracy: 0.8612 - val_loss: 1.3316 - val_accuracy: 0.6455\n",
      "Epoch 176/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3885 - accuracy: 0.8610 - val_loss: 1.3204 - val_accuracy: 0.6448\n",
      "Epoch 177/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3847 - accuracy: 0.8618 - val_loss: 1.3327 - val_accuracy: 0.6492\n",
      "Epoch 178/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3854 - accuracy: 0.8621 - val_loss: 1.3337 - val_accuracy: 0.6471\n",
      "Epoch 179/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3877 - accuracy: 0.8625 - val_loss: 1.3412 - val_accuracy: 0.6453\n",
      "Epoch 180/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.3824 - accuracy: 0.8632 - val_loss: 1.3439 - val_accuracy: 0.6448\n",
      "Epoch 181/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3805 - accuracy: 0.8637 - val_loss: 1.3392 - val_accuracy: 0.6478\n",
      "Epoch 182/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3919 - accuracy: 0.8599 - val_loss: 1.3288 - val_accuracy: 0.6492\n",
      "Epoch 183/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3816 - accuracy: 0.8640 - val_loss: 1.3383 - val_accuracy: 0.6511\n",
      "Epoch 184/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3861 - accuracy: 0.8604 - val_loss: 1.3368 - val_accuracy: 0.6493\n",
      "Epoch 185/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3842 - accuracy: 0.8615 - val_loss: 1.3400 - val_accuracy: 0.6485\n",
      "Epoch 186/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3807 - accuracy: 0.8633 - val_loss: 1.3274 - val_accuracy: 0.6455\n",
      "Epoch 187/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3823 - accuracy: 0.8623 - val_loss: 1.3426 - val_accuracy: 0.6458\n",
      "Epoch 188/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3860 - accuracy: 0.8626 - val_loss: 1.3472 - val_accuracy: 0.6466\n",
      "Epoch 189/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3887 - accuracy: 0.8613 - val_loss: 1.3401 - val_accuracy: 0.6480\n",
      "Epoch 190/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3804 - accuracy: 0.8650 - val_loss: 1.3400 - val_accuracy: 0.6440\n",
      "Epoch 191/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.3780 - accuracy: 0.8657 - val_loss: 1.3372 - val_accuracy: 0.6472\n",
      "Epoch 192/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3754 - accuracy: 0.8639 - val_loss: 1.3356 - val_accuracy: 0.6461\n",
      "Epoch 193/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3816 - accuracy: 0.8628 - val_loss: 1.3402 - val_accuracy: 0.6448\n",
      "Epoch 194/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3786 - accuracy: 0.8627 - val_loss: 1.3547 - val_accuracy: 0.6469\n",
      "Epoch 195/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3800 - accuracy: 0.8639 - val_loss: 1.3408 - val_accuracy: 0.6436\n",
      "Epoch 196/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3754 - accuracy: 0.8645 - val_loss: 1.3619 - val_accuracy: 0.6447\n",
      "Epoch 197/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3856 - accuracy: 0.8625 - val_loss: 1.3432 - val_accuracy: 0.6497\n",
      "Epoch 198/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3756 - accuracy: 0.8640 - val_loss: 1.3496 - val_accuracy: 0.6469\n",
      "Epoch 199/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3793 - accuracy: 0.8632 - val_loss: 1.3470 - val_accuracy: 0.6456\n",
      "Epoch 200/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3800 - accuracy: 0.8635 - val_loss: 1.3393 - val_accuracy: 0.6447\n"
     ]
    }
   ],
   "source": [
    "# a higher learning rate for BN\n",
    "lr = 1e-2\n",
    "resnet_dense_do_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.001)\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%dDropoutM%S\")\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logdir, update_freq='epoch', profile_batch=2\n",
    ")\n",
    "\n",
    "# We are going to train for 50 epochs\n",
    "history = resnet_dense_do_model.fit(\n",
    "    train_ds, epochs=200, validation_data=test_ds, \n",
    "    callbacks=[reduce_lr, tb_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5: Model2 + Dropout\n",
    "\n",
    "Add dropout to model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_strided_slice_9  [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_BiasAdd_9 (Tenso [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 1, 1, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_9 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 23,616,394\n",
      "Trainable params: 24,586\n",
      "Non-trainable params: 23,591,808\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.ResNet50(input_shape=(IMG_SIZE, IMG_SIZE, 3), include_top=False)\n",
    "base_model.trainable = False\n",
    "def get_model_5(base_model, drop=0.2):\n",
    "    inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    x = tf.keras.applications.resnet.preprocess_input(inputs)\n",
    "    x = base_model(x, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(drop)(x)\n",
    "    outputs = Dense(NUM_CLASSES)(x)\n",
    "    _model = tf.keras.Model(inputs, outputs)    \n",
    "    return _model\n",
    "model5 = get_model_5(base_model, 0.2)\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "  2/390 [..............................] - ETA: 46s - loss: 2.8400 - accuracy: 0.1836WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0164s vs `on_train_batch_end` time: 0.2214s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0164s vs `on_train_batch_end` time: 0.2214s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 6s 17ms/step - loss: 1.2971 - accuracy: 0.5721 - val_loss: 1.0964 - val_accuracy: 0.6187\n",
      "Epoch 2/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 1.0757 - accuracy: 0.6271 - val_loss: 1.0455 - val_accuracy: 0.6398\n",
      "Epoch 3/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 1.0176 - accuracy: 0.6475 - val_loss: 1.0752 - val_accuracy: 0.6285\n",
      "Epoch 4/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9974 - accuracy: 0.6565 - val_loss: 1.0881 - val_accuracy: 0.6312\n",
      "Epoch 5/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9726 - accuracy: 0.6632 - val_loss: 1.0363 - val_accuracy: 0.6484\n",
      "Epoch 6/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.9590 - accuracy: 0.6695 - val_loss: 1.0935 - val_accuracy: 0.6326\n",
      "Epoch 7/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.9417 - accuracy: 0.6757 - val_loss: 1.0896 - val_accuracy: 0.6360\n",
      "Epoch 8/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9301 - accuracy: 0.6788 - val_loss: 1.0720 - val_accuracy: 0.6443\n",
      "Epoch 9/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.9182 - accuracy: 0.6831 - val_loss: 1.1026 - val_accuracy: 0.6425\n",
      "Epoch 10/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.9057 - accuracy: 0.6899 - val_loss: 1.0958 - val_accuracy: 0.6355\n",
      "Epoch 11/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7531 - accuracy: 0.7372 - val_loss: 1.0074 - val_accuracy: 0.6582\n",
      "Epoch 12/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7098 - accuracy: 0.7491 - val_loss: 1.0182 - val_accuracy: 0.6604\n",
      "Epoch 13/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.6903 - accuracy: 0.7573 - val_loss: 1.0132 - val_accuracy: 0.6625\n",
      "Epoch 14/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.6733 - accuracy: 0.7613 - val_loss: 1.0285 - val_accuracy: 0.6636\n",
      "Epoch 15/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.6660 - accuracy: 0.7631 - val_loss: 1.0188 - val_accuracy: 0.6621\n",
      "Epoch 16/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.6503 - accuracy: 0.7704 - val_loss: 1.0271 - val_accuracy: 0.6607\n",
      "Epoch 17/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.6244 - accuracy: 0.7780 - val_loss: 1.0222 - val_accuracy: 0.6647\n",
      "Epoch 18/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.6093 - accuracy: 0.7831 - val_loss: 1.0403 - val_accuracy: 0.6696\n",
      "Epoch 19/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.6066 - accuracy: 0.7853 - val_loss: 1.0385 - val_accuracy: 0.6695\n",
      "Epoch 20/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5983 - accuracy: 0.7867 - val_loss: 1.0447 - val_accuracy: 0.6645\n",
      "Epoch 21/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5914 - accuracy: 0.7908 - val_loss: 1.0512 - val_accuracy: 0.6636\n",
      "Epoch 22/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5886 - accuracy: 0.7893 - val_loss: 1.0477 - val_accuracy: 0.6654\n",
      "Epoch 23/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5835 - accuracy: 0.7909 - val_loss: 1.0520 - val_accuracy: 0.6680\n",
      "Epoch 24/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5771 - accuracy: 0.7929 - val_loss: 1.0693 - val_accuracy: 0.6641\n",
      "Epoch 25/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5753 - accuracy: 0.7926 - val_loss: 1.0685 - val_accuracy: 0.6627\n",
      "Epoch 26/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5694 - accuracy: 0.7949 - val_loss: 1.0728 - val_accuracy: 0.6627\n",
      "Epoch 27/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.5693 - accuracy: 0.7969 - val_loss: 1.0689 - val_accuracy: 0.6642\n",
      "Epoch 28/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.5598 - accuracy: 0.7982 - val_loss: 1.0761 - val_accuracy: 0.6640\n",
      "Epoch 29/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5614 - accuracy: 0.7988 - val_loss: 1.0790 - val_accuracy: 0.6628\n",
      "Epoch 30/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5525 - accuracy: 0.8010 - val_loss: 1.0850 - val_accuracy: 0.6662\n",
      "Epoch 31/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5503 - accuracy: 0.8049 - val_loss: 1.0839 - val_accuracy: 0.6640\n",
      "Epoch 32/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5499 - accuracy: 0.8052 - val_loss: 1.0877 - val_accuracy: 0.6628\n",
      "Epoch 33/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5391 - accuracy: 0.8069 - val_loss: 1.0943 - val_accuracy: 0.6631\n",
      "Epoch 34/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5399 - accuracy: 0.8086 - val_loss: 1.1025 - val_accuracy: 0.6598\n",
      "Epoch 35/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5346 - accuracy: 0.8087 - val_loss: 1.1091 - val_accuracy: 0.6629\n",
      "Epoch 36/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5291 - accuracy: 0.8107 - val_loss: 1.1091 - val_accuracy: 0.6648\n",
      "Epoch 37/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5276 - accuracy: 0.8112 - val_loss: 1.1115 - val_accuracy: 0.6624\n",
      "Epoch 38/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5255 - accuracy: 0.8118 - val_loss: 1.1105 - val_accuracy: 0.6651\n",
      "Epoch 39/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.5223 - accuracy: 0.8138 - val_loss: 1.1140 - val_accuracy: 0.6625\n",
      "Epoch 40/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.5205 - accuracy: 0.8131 - val_loss: 1.1184 - val_accuracy: 0.6667\n",
      "Epoch 41/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5169 - accuracy: 0.8143 - val_loss: 1.1272 - val_accuracy: 0.6630\n",
      "Epoch 42/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5141 - accuracy: 0.8138 - val_loss: 1.1223 - val_accuracy: 0.6603\n",
      "Epoch 43/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5189 - accuracy: 0.8136 - val_loss: 1.1297 - val_accuracy: 0.6579\n",
      "Epoch 44/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5097 - accuracy: 0.8173 - val_loss: 1.1362 - val_accuracy: 0.6618\n",
      "Epoch 45/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5044 - accuracy: 0.8179 - val_loss: 1.1372 - val_accuracy: 0.6597\n",
      "Epoch 46/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5024 - accuracy: 0.8202 - val_loss: 1.1454 - val_accuracy: 0.6575\n",
      "Epoch 47/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5036 - accuracy: 0.8187 - val_loss: 1.1408 - val_accuracy: 0.6615\n",
      "Epoch 48/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5030 - accuracy: 0.8193 - val_loss: 1.1544 - val_accuracy: 0.6619\n",
      "Epoch 49/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5009 - accuracy: 0.8188 - val_loss: 1.1437 - val_accuracy: 0.6602\n",
      "Epoch 50/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4990 - accuracy: 0.8217 - val_loss: 1.1541 - val_accuracy: 0.6595\n",
      "Epoch 51/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4954 - accuracy: 0.8221 - val_loss: 1.1564 - val_accuracy: 0.6605\n",
      "Epoch 52/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4911 - accuracy: 0.8235 - val_loss: 1.1680 - val_accuracy: 0.6609\n",
      "Epoch 53/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4925 - accuracy: 0.8238 - val_loss: 1.1695 - val_accuracy: 0.6566\n",
      "Epoch 54/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4838 - accuracy: 0.8269 - val_loss: 1.1622 - val_accuracy: 0.6590\n",
      "Epoch 55/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4872 - accuracy: 0.8248 - val_loss: 1.1656 - val_accuracy: 0.6612\n",
      "Epoch 56/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4879 - accuracy: 0.8229 - val_loss: 1.1708 - val_accuracy: 0.6573\n",
      "Epoch 57/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4801 - accuracy: 0.8274 - val_loss: 1.1808 - val_accuracy: 0.6559\n",
      "Epoch 58/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4788 - accuracy: 0.8277 - val_loss: 1.1685 - val_accuracy: 0.6595\n",
      "Epoch 59/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4805 - accuracy: 0.8271 - val_loss: 1.1873 - val_accuracy: 0.6601\n",
      "Epoch 60/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4769 - accuracy: 0.8292 - val_loss: 1.1743 - val_accuracy: 0.6587\n",
      "Epoch 61/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4800 - accuracy: 0.8265 - val_loss: 1.1682 - val_accuracy: 0.6584\n",
      "Epoch 62/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4726 - accuracy: 0.8298 - val_loss: 1.1896 - val_accuracy: 0.6550\n",
      "Epoch 63/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4781 - accuracy: 0.8300 - val_loss: 1.1898 - val_accuracy: 0.6587\n",
      "Epoch 64/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4692 - accuracy: 0.8324 - val_loss: 1.1833 - val_accuracy: 0.6576\n",
      "Epoch 65/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4706 - accuracy: 0.8292 - val_loss: 1.1946 - val_accuracy: 0.6568\n",
      "Epoch 66/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4675 - accuracy: 0.8310 - val_loss: 1.1936 - val_accuracy: 0.6538\n",
      "Epoch 67/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4648 - accuracy: 0.8332 - val_loss: 1.1932 - val_accuracy: 0.6582\n",
      "Epoch 68/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4683 - accuracy: 0.8312 - val_loss: 1.1944 - val_accuracy: 0.6574\n",
      "Epoch 69/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4639 - accuracy: 0.8324 - val_loss: 1.1857 - val_accuracy: 0.6558\n",
      "Epoch 70/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4561 - accuracy: 0.8368 - val_loss: 1.1992 - val_accuracy: 0.6557\n",
      "Epoch 71/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4622 - accuracy: 0.8334 - val_loss: 1.2085 - val_accuracy: 0.6570\n",
      "Epoch 72/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4644 - accuracy: 0.8346 - val_loss: 1.1919 - val_accuracy: 0.6557\n",
      "Epoch 73/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4571 - accuracy: 0.8355 - val_loss: 1.2059 - val_accuracy: 0.6525\n",
      "Epoch 74/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4570 - accuracy: 0.8368 - val_loss: 1.2132 - val_accuracy: 0.6531\n",
      "Epoch 75/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4487 - accuracy: 0.8385 - val_loss: 1.2092 - val_accuracy: 0.6541\n",
      "Epoch 76/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4536 - accuracy: 0.8363 - val_loss: 1.2117 - val_accuracy: 0.6568\n",
      "Epoch 77/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4539 - accuracy: 0.8362 - val_loss: 1.2246 - val_accuracy: 0.6555\n",
      "Epoch 78/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4528 - accuracy: 0.8381 - val_loss: 1.2250 - val_accuracy: 0.6572\n",
      "Epoch 79/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4533 - accuracy: 0.8384 - val_loss: 1.2070 - val_accuracy: 0.6516\n",
      "Epoch 80/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4503 - accuracy: 0.8373 - val_loss: 1.2279 - val_accuracy: 0.6506\n",
      "Epoch 81/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4509 - accuracy: 0.8383 - val_loss: 1.2226 - val_accuracy: 0.6575\n",
      "Epoch 82/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4436 - accuracy: 0.8405 - val_loss: 1.2320 - val_accuracy: 0.6542\n",
      "Epoch 83/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4414 - accuracy: 0.8391 - val_loss: 1.2253 - val_accuracy: 0.6521\n",
      "Epoch 84/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4450 - accuracy: 0.8396 - val_loss: 1.2365 - val_accuracy: 0.6520\n",
      "Epoch 85/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4423 - accuracy: 0.8393 - val_loss: 1.2417 - val_accuracy: 0.6537\n",
      "Epoch 86/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4451 - accuracy: 0.8404 - val_loss: 1.2321 - val_accuracy: 0.6523\n",
      "Epoch 87/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4359 - accuracy: 0.8433 - val_loss: 1.2318 - val_accuracy: 0.6576\n",
      "Epoch 88/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4391 - accuracy: 0.8418 - val_loss: 1.2252 - val_accuracy: 0.6570\n",
      "Epoch 89/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4337 - accuracy: 0.8454 - val_loss: 1.2547 - val_accuracy: 0.6548\n",
      "Epoch 90/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4416 - accuracy: 0.8413 - val_loss: 1.2528 - val_accuracy: 0.6528\n",
      "Epoch 91/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4415 - accuracy: 0.8425 - val_loss: 1.2392 - val_accuracy: 0.6566\n",
      "Epoch 92/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4342 - accuracy: 0.8429 - val_loss: 1.2519 - val_accuracy: 0.6557\n",
      "Epoch 93/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4359 - accuracy: 0.8440 - val_loss: 1.2476 - val_accuracy: 0.6576\n",
      "Epoch 94/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4357 - accuracy: 0.8442 - val_loss: 1.2380 - val_accuracy: 0.6573\n",
      "Epoch 95/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4363 - accuracy: 0.8426 - val_loss: 1.2580 - val_accuracy: 0.6551\n",
      "Epoch 96/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4333 - accuracy: 0.8452 - val_loss: 1.2428 - val_accuracy: 0.6532\n",
      "Epoch 97/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4341 - accuracy: 0.8443 - val_loss: 1.2336 - val_accuracy: 0.6549\n",
      "Epoch 98/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4310 - accuracy: 0.8448 - val_loss: 1.2453 - val_accuracy: 0.6538\n",
      "Epoch 99/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4344 - accuracy: 0.8439 - val_loss: 1.2618 - val_accuracy: 0.6523\n",
      "Epoch 100/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4289 - accuracy: 0.8457 - val_loss: 1.2480 - val_accuracy: 0.6528\n",
      "Epoch 101/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4290 - accuracy: 0.8457 - val_loss: 1.2619 - val_accuracy: 0.6513\n",
      "Epoch 102/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4219 - accuracy: 0.8482 - val_loss: 1.2644 - val_accuracy: 0.6516\n",
      "Epoch 103/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4309 - accuracy: 0.8469 - val_loss: 1.2580 - val_accuracy: 0.6518\n",
      "Epoch 104/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4198 - accuracy: 0.8501 - val_loss: 1.2543 - val_accuracy: 0.6545\n",
      "Epoch 105/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4268 - accuracy: 0.8464 - val_loss: 1.2597 - val_accuracy: 0.6524\n",
      "Epoch 106/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4212 - accuracy: 0.8475 - val_loss: 1.2674 - val_accuracy: 0.6499\n",
      "Epoch 107/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4211 - accuracy: 0.8491 - val_loss: 1.2546 - val_accuracy: 0.6547\n",
      "Epoch 108/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4229 - accuracy: 0.8498 - val_loss: 1.2641 - val_accuracy: 0.6512\n",
      "Epoch 109/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4211 - accuracy: 0.8476 - val_loss: 1.2609 - val_accuracy: 0.6539\n",
      "Epoch 110/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4189 - accuracy: 0.8485 - val_loss: 1.2571 - val_accuracy: 0.6516\n",
      "Epoch 111/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4209 - accuracy: 0.8495 - val_loss: 1.2610 - val_accuracy: 0.6489\n",
      "Epoch 112/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4159 - accuracy: 0.8509 - val_loss: 1.2807 - val_accuracy: 0.6501\n",
      "Epoch 113/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4177 - accuracy: 0.8499 - val_loss: 1.2769 - val_accuracy: 0.6479\n",
      "Epoch 114/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4217 - accuracy: 0.8486 - val_loss: 1.2783 - val_accuracy: 0.6497\n",
      "Epoch 115/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4181 - accuracy: 0.8495 - val_loss: 1.2632 - val_accuracy: 0.6506\n",
      "Epoch 116/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4139 - accuracy: 0.8513 - val_loss: 1.2909 - val_accuracy: 0.6488\n",
      "Epoch 117/200\n",
      "  6/390 [..............................] - ETA: 3s - loss: 0.4286 - accuracy: 0.8398"
     ]
    }
   ],
   "source": [
    "# a higher learning rate for BN\n",
    "lr = 1e-2\n",
    "model5.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.001)\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%dDropoutM%S\")\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logdir, update_freq='epoch', profile_batch=2\n",
    ")\n",
    "\n",
    "# We are going to train for 50 epochs\n",
    "history = model5.fit(\n",
    "    train_ds, epochs=200, validation_data=test_ds, \n",
    "    callbacks=[reduce_lr, tb_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 6: moar dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_strided_slice_10 [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_BiasAdd_10 (Tens [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 1, 1, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_10  (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 23,616,394\n",
      "Trainable params: 24,586\n",
      "Non-trainable params: 23,591,808\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.ResNet50(input_shape=(IMG_SIZE, IMG_SIZE, 3), include_top=False)\n",
    "base_model.trainable = False\n",
    "model6 = get_model_5(base_model, 0.4)\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "  2/390 [..............................] - ETA: 51s - loss: 2.9598 - accuracy: 0.1992WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0157s vs `on_train_batch_end` time: 0.2499s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0157s vs `on_train_batch_end` time: 0.2499s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 6s 17ms/step - loss: 2.0632 - accuracy: 0.5269 - val_loss: 1.2440 - val_accuracy: 0.6077\n",
      "Epoch 2/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 1.2407 - accuracy: 0.5912 - val_loss: 1.0402 - val_accuracy: 0.6391\n",
      "Epoch 3/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 1.1272 - accuracy: 0.6077 - val_loss: 1.0194 - val_accuracy: 0.6413\n",
      "Epoch 4/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 1.1273 - accuracy: 0.6056 - val_loss: 1.0940 - val_accuracy: 0.6177\n",
      "Epoch 5/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 1.1359 - accuracy: 0.6022 - val_loss: 1.0969 - val_accuracy: 0.6182\n",
      "Epoch 6/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 1.1533 - accuracy: 0.6027 - val_loss: 1.0603 - val_accuracy: 0.6255\n",
      "Epoch 7/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 1.1514 - accuracy: 0.6024 - val_loss: 1.0560 - val_accuracy: 0.6326\n",
      "Epoch 8/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 1.1592 - accuracy: 0.5958 - val_loss: 1.0549 - val_accuracy: 0.6296\n",
      "Epoch 9/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 1.0473 - accuracy: 0.6352 - val_loss: 0.9749 - val_accuracy: 0.6571\n",
      "Epoch 10/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 1.0196 - accuracy: 0.6434 - val_loss: 0.9678 - val_accuracy: 0.6634\n",
      "Epoch 11/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 1.0108 - accuracy: 0.6449 - val_loss: 0.9741 - val_accuracy: 0.6659\n",
      "Epoch 12/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 1.0061 - accuracy: 0.6454 - val_loss: 0.9672 - val_accuracy: 0.6619\n",
      "Epoch 13/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 1.0008 - accuracy: 0.6490 - val_loss: 0.9653 - val_accuracy: 0.6665\n",
      "Epoch 14/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 1.0048 - accuracy: 0.6476 - val_loss: 0.9575 - val_accuracy: 0.6674\n",
      "Epoch 15/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9980 - accuracy: 0.6477 - val_loss: 0.9640 - val_accuracy: 0.6648\n",
      "Epoch 16/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9980 - accuracy: 0.6484 - val_loss: 0.9630 - val_accuracy: 0.6646\n",
      "Epoch 17/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9959 - accuracy: 0.6538 - val_loss: 0.9573 - val_accuracy: 0.6697\n",
      "Epoch 18/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9938 - accuracy: 0.6488 - val_loss: 0.9597 - val_accuracy: 0.6662\n",
      "Epoch 19/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9960 - accuracy: 0.6502 - val_loss: 0.9624 - val_accuracy: 0.6618\n",
      "Epoch 20/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9981 - accuracy: 0.6474 - val_loss: 0.9682 - val_accuracy: 0.6640\n",
      "Epoch 21/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9932 - accuracy: 0.6524 - val_loss: 0.9727 - val_accuracy: 0.6587\n",
      "Epoch 22/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9945 - accuracy: 0.6506 - val_loss: 0.9623 - val_accuracy: 0.6657\n",
      "Epoch 23/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9673 - accuracy: 0.6601 - val_loss: 0.9518 - val_accuracy: 0.6726\n",
      "Epoch 37/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9663 - accuracy: 0.6607 - val_loss: 0.9465 - val_accuracy: 0.6714\n",
      "Epoch 38/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9642 - accuracy: 0.6618 - val_loss: 0.9516 - val_accuracy: 0.6703\n",
      "Epoch 39/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9627 - accuracy: 0.6605 - val_loss: 0.9431 - val_accuracy: 0.6720\n",
      "Epoch 40/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9662 - accuracy: 0.6587 - val_loss: 0.9458 - val_accuracy: 0.6748\n",
      "Epoch 41/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9639 - accuracy: 0.6603 - val_loss: 0.9429 - val_accuracy: 0.6721\n",
      "Epoch 42/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9609 - accuracy: 0.6635 - val_loss: 0.9433 - val_accuracy: 0.6719\n",
      "Epoch 43/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9618 - accuracy: 0.6631 - val_loss: 0.9427 - val_accuracy: 0.6730\n",
      "Epoch 44/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9669 - accuracy: 0.6606 - val_loss: 0.9468 - val_accuracy: 0.6735\n",
      "Epoch 45/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9585 - accuracy: 0.6618 - val_loss: 0.9470 - val_accuracy: 0.6711\n",
      "Epoch 46/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9612 - accuracy: 0.6610 - val_loss: 0.9473 - val_accuracy: 0.6697\n",
      "Epoch 47/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9634 - accuracy: 0.6624 - val_loss: 0.9440 - val_accuracy: 0.6718\n",
      "Epoch 48/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9640 - accuracy: 0.6615 - val_loss: 0.9466 - val_accuracy: 0.6727\n",
      "Epoch 49/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9624 - accuracy: 0.6591 - val_loss: 0.9509 - val_accuracy: 0.6692\n",
      "Epoch 50/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9612 - accuracy: 0.6630 - val_loss: 0.9493 - val_accuracy: 0.6714\n",
      "Epoch 51/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9634 - accuracy: 0.6605 - val_loss: 0.9448 - val_accuracy: 0.6735\n",
      "Epoch 52/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9607 - accuracy: 0.6617 - val_loss: 0.9502 - val_accuracy: 0.6709\n",
      "Epoch 53/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9623 - accuracy: 0.6605 - val_loss: 0.9453 - val_accuracy: 0.6726\n",
      "Epoch 54/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9607 - accuracy: 0.6632 - val_loss: 0.9446 - val_accuracy: 0.6755\n",
      "Epoch 55/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9591 - accuracy: 0.6615 - val_loss: 0.9480 - val_accuracy: 0.6703\n",
      "Epoch 56/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9638 - accuracy: 0.6597 - val_loss: 0.9483 - val_accuracy: 0.6718\n",
      "Epoch 57/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9621 - accuracy: 0.6613 - val_loss: 0.9413 - val_accuracy: 0.6748\n",
      "Epoch 58/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9647 - accuracy: 0.6602 - val_loss: 0.9467 - val_accuracy: 0.6686\n",
      "Epoch 59/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9639 - accuracy: 0.6604 - val_loss: 0.9467 - val_accuracy: 0.6712\n",
      "Epoch 60/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9588 - accuracy: 0.6642 - val_loss: 0.9464 - val_accuracy: 0.6691\n",
      "Epoch 61/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9654 - accuracy: 0.6589 - val_loss: 0.9474 - val_accuracy: 0.6707\n",
      "Epoch 62/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9601 - accuracy: 0.6615 - val_loss: 0.9480 - val_accuracy: 0.6728\n",
      "Epoch 63/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9630 - accuracy: 0.6613 - val_loss: 0.9476 - val_accuracy: 0.6705\n",
      "Epoch 64/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9664 - accuracy: 0.6602 - val_loss: 0.9419 - val_accuracy: 0.6730\n",
      "Epoch 65/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9636 - accuracy: 0.6596 - val_loss: 0.9443 - val_accuracy: 0.6732\n",
      "Epoch 66/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9628 - accuracy: 0.6625 - val_loss: 0.9453 - val_accuracy: 0.6706\n",
      "Epoch 67/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9631 - accuracy: 0.6631 - val_loss: 0.9440 - val_accuracy: 0.6719\n",
      "Epoch 68/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9612 - accuracy: 0.6607 - val_loss: 0.9470 - val_accuracy: 0.6737\n",
      "Epoch 69/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9608 - accuracy: 0.6627 - val_loss: 0.9458 - val_accuracy: 0.6709\n",
      "Epoch 70/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9560 - accuracy: 0.6632 - val_loss: 0.9430 - val_accuracy: 0.6747\n",
      "Epoch 71/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9598 - accuracy: 0.6628 - val_loss: 0.9494 - val_accuracy: 0.6706\n",
      "Epoch 72/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9642 - accuracy: 0.6615 - val_loss: 0.9451 - val_accuracy: 0.6725\n",
      "Epoch 73/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9639 - accuracy: 0.6608 - val_loss: 0.9431 - val_accuracy: 0.6751\n",
      "Epoch 74/200\n",
      "340/390 [=========================>....] - ETA: 0s - loss: 0.9662 - accuracy: 0.6597"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9647 - accuracy: 0.6618 - val_loss: 0.9521 - val_accuracy: 0.6705\n",
      "Epoch 187/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9584 - accuracy: 0.6631 - val_loss: 0.9548 - val_accuracy: 0.6684\n",
      "Epoch 188/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9579 - accuracy: 0.6641 - val_loss: 0.9437 - val_accuracy: 0.6717\n",
      "Epoch 189/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9603 - accuracy: 0.6632 - val_loss: 0.9442 - val_accuracy: 0.6706\n",
      "Epoch 190/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9665 - accuracy: 0.6598 - val_loss: 0.9504 - val_accuracy: 0.6734\n",
      "Epoch 191/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9575 - accuracy: 0.6623 - val_loss: 0.9458 - val_accuracy: 0.6726\n",
      "Epoch 192/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9631 - accuracy: 0.6632 - val_loss: 0.9466 - val_accuracy: 0.6732\n",
      "Epoch 193/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9612 - accuracy: 0.6629 - val_loss: 0.9456 - val_accuracy: 0.6706\n",
      "Epoch 194/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9614 - accuracy: 0.6613 - val_loss: 0.9449 - val_accuracy: 0.6721\n",
      "Epoch 195/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.9649 - accuracy: 0.6593 - val_loss: 0.9465 - val_accuracy: 0.6691\n",
      "Epoch 196/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9601 - accuracy: 0.6624 - val_loss: 0.9532 - val_accuracy: 0.6682\n",
      "Epoch 197/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9574 - accuracy: 0.6628 - val_loss: 0.9508 - val_accuracy: 0.6688\n",
      "Epoch 198/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.9615 - accuracy: 0.6616 - val_loss: 0.9443 - val_accuracy: 0.6729\n",
      "Epoch 199/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9609 - accuracy: 0.6624 - val_loss: 0.9476 - val_accuracy: 0.6721\n",
      "Epoch 200/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.9611 - accuracy: 0.6629 - val_loss: 0.9530 - val_accuracy: 0.6670\n"
     ]
    }
   ],
   "source": [
    "# a higher learning rate for BN\n",
    "lr = 1e-2\n",
    "model6.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.001)\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%M%S-model6\")\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logdir, update_freq='epoch', profile_batch=2\n",
    ")\n",
    "\n",
    "# We are going to train for 50 epochs\n",
    "history = model6.fit(\n",
    "    train_ds, epochs=200, validation_data=test_ds, \n",
    "    callbacks=[reduce_lr, tb_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 1s 12ms/step - loss: 0.9530 - accuracy: 0.6670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9530342221260071, 0.6669671535491943]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 7:  model 1 + dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_strided_slice_11 [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_BiasAdd_11 (Tens [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 1, 1, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_11  (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 23,859,466\n",
      "Trainable params: 267,658\n",
      "Non-trainable params: 23,591,808\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.ResNet50(input_shape=(IMG_SIZE, IMG_SIZE, 3), include_top=False)\n",
    "base_model.trainable = False\n",
    "def get_model_7(base_model, drop=0.2):\n",
    "    inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    x = tf.keras.applications.resnet.preprocess_input(inputs)\n",
    "    x = base_model(x, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(drop)(x)\n",
    "    outputs = Dense(NUM_CLASSES)(x)\n",
    "    _model = tf.keras.Model(inputs, outputs)    \n",
    "    return _model\n",
    "model7 = get_model_7(base_model, 0.4)\n",
    "model7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "  2/390 [..............................] - ETA: 48s - loss: 2.8815 - accuracy: 0.2773WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0101s vs `on_train_batch_end` time: 0.2380s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0101s vs `on_train_batch_end` time: 0.2380s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390/390 [==============================] - 6s 17ms/step - loss: 1.5033 - accuracy: 0.5285 - val_loss: 1.1652 - val_accuracy: 0.5930\n",
      "Epoch 2/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 1.2523 - accuracy: 0.5761 - val_loss: 1.1345 - val_accuracy: 0.6172\n",
      "Epoch 3/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 1.1743 - accuracy: 0.6004 - val_loss: 1.0862 - val_accuracy: 0.6282\n",
      "Epoch 4/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 1.1362 - accuracy: 0.6149 - val_loss: 1.0845 - val_accuracy: 0.6424\n",
      "Epoch 5/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 1.1123 - accuracy: 0.6216 - val_loss: 1.1013 - val_accuracy: 0.6305\n",
      "Epoch 6/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 1.0993 - accuracy: 0.6268 - val_loss: 1.0875 - val_accuracy: 0.6355\n",
      "Epoch 7/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 1.0855 - accuracy: 0.6307 - val_loss: 1.0698 - val_accuracy: 0.6470\n",
      "Epoch 8/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 1.0784 - accuracy: 0.6331 - val_loss: 1.0911 - val_accuracy: 0.6320\n",
      "Epoch 9/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 1.0623 - accuracy: 0.6369 - val_loss: 1.1023 - val_accuracy: 0.6286\n",
      "Epoch 10/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 1.0620 - accuracy: 0.6381 - val_loss: 1.1193 - val_accuracy: 0.6192\n",
      "Epoch 11/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 1.0595 - accuracy: 0.6427 - val_loss: 1.1324 - val_accuracy: 0.6350\n",
      "Epoch 12/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 1.0525 - accuracy: 0.6436 - val_loss: 1.1611 - val_accuracy: 0.6360\n",
      "Epoch 13/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.8731 - accuracy: 0.6964 - val_loss: 1.0238 - val_accuracy: 0.6680\n",
      "Epoch 14/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.8002 - accuracy: 0.7193 - val_loss: 1.0437 - val_accuracy: 0.6672\n",
      "Epoch 15/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7657 - accuracy: 0.7286 - val_loss: 1.0392 - val_accuracy: 0.6696\n",
      "Epoch 16/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7392 - accuracy: 0.7332 - val_loss: 1.0465 - val_accuracy: 0.6688\n",
      "Epoch 17/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7219 - accuracy: 0.7418 - val_loss: 1.0527 - val_accuracy: 0.6708\n",
      "Epoch 18/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.7038 - accuracy: 0.7467 - val_loss: 1.0564 - val_accuracy: 0.6735\n",
      "Epoch 19/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.6684 - accuracy: 0.7582 - val_loss: 1.0536 - val_accuracy: 0.6721\n",
      "Epoch 20/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.6510 - accuracy: 0.7620 - val_loss: 1.0614 - val_accuracy: 0.6698\n",
      "Epoch 21/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.6363 - accuracy: 0.7656 - val_loss: 1.0794 - val_accuracy: 0.6712\n",
      "Epoch 22/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.6289 - accuracy: 0.7697 - val_loss: 1.0906 - val_accuracy: 0.6756\n",
      "Epoch 23/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.6205 - accuracy: 0.7750 - val_loss: 1.1156 - val_accuracy: 0.6750\n",
      "Epoch 24/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.6133 - accuracy: 0.7747 - val_loss: 1.1106 - val_accuracy: 0.6711\n",
      "Epoch 25/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.6039 - accuracy: 0.7765 - val_loss: 1.1290 - val_accuracy: 0.6699\n",
      "Epoch 26/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5974 - accuracy: 0.7796 - val_loss: 1.1298 - val_accuracy: 0.6700\n",
      "Epoch 27/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5898 - accuracy: 0.7816 - val_loss: 1.1273 - val_accuracy: 0.6685\n",
      "Epoch 28/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5790 - accuracy: 0.7863 - val_loss: 1.1523 - val_accuracy: 0.6701\n",
      "Epoch 29/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5632 - accuracy: 0.7880 - val_loss: 1.1698 - val_accuracy: 0.6707\n",
      "Epoch 30/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5712 - accuracy: 0.7872 - val_loss: 1.1734 - val_accuracy: 0.6683\n",
      "Epoch 31/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5606 - accuracy: 0.7929 - val_loss: 1.1853 - val_accuracy: 0.6684\n",
      "Epoch 32/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5572 - accuracy: 0.7925 - val_loss: 1.2011 - val_accuracy: 0.6645\n",
      "Epoch 33/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.5418 - accuracy: 0.7983 - val_loss: 1.1956 - val_accuracy: 0.6669\n",
      "Epoch 34/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.5383 - accuracy: 0.7993 - val_loss: 1.2154 - val_accuracy: 0.6664\n",
      "Epoch 35/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5345 - accuracy: 0.7996 - val_loss: 1.2227 - val_accuracy: 0.6690\n",
      "Epoch 36/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5298 - accuracy: 0.8018 - val_loss: 1.2272 - val_accuracy: 0.6677\n",
      "Epoch 37/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5281 - accuracy: 0.8022 - val_loss: 1.2395 - val_accuracy: 0.6643\n",
      "Epoch 38/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5268 - accuracy: 0.8020 - val_loss: 1.2476 - val_accuracy: 0.6669\n",
      "Epoch 39/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5150 - accuracy: 0.8077 - val_loss: 1.2783 - val_accuracy: 0.6647\n",
      "Epoch 40/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5113 - accuracy: 0.8085 - val_loss: 1.2697 - val_accuracy: 0.6682\n",
      "Epoch 41/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5072 - accuracy: 0.8121 - val_loss: 1.3088 - val_accuracy: 0.6666\n",
      "Epoch 42/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4974 - accuracy: 0.8124 - val_loss: 1.3069 - val_accuracy: 0.6688\n",
      "Epoch 43/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.5021 - accuracy: 0.8092 - val_loss: 1.2894 - val_accuracy: 0.6678\n",
      "Epoch 44/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4933 - accuracy: 0.8141 - val_loss: 1.3174 - val_accuracy: 0.6660\n",
      "Epoch 45/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4884 - accuracy: 0.8178 - val_loss: 1.3287 - val_accuracy: 0.6692\n",
      "Epoch 46/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4897 - accuracy: 0.8143 - val_loss: 1.3160 - val_accuracy: 0.6644\n",
      "Epoch 47/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4761 - accuracy: 0.8214 - val_loss: 1.3586 - val_accuracy: 0.6688\n",
      "Epoch 48/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4842 - accuracy: 0.8169 - val_loss: 1.3446 - val_accuracy: 0.6657\n",
      "Epoch 49/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4775 - accuracy: 0.8207 - val_loss: 1.3365 - val_accuracy: 0.6672\n",
      "Epoch 50/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4758 - accuracy: 0.8209 - val_loss: 1.3461 - val_accuracy: 0.6631\n",
      "Epoch 51/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4732 - accuracy: 0.8219 - val_loss: 1.3942 - val_accuracy: 0.6648\n",
      "Epoch 52/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4620 - accuracy: 0.8250 - val_loss: 1.3405 - val_accuracy: 0.6585\n",
      "Epoch 53/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4617 - accuracy: 0.8251 - val_loss: 1.3717 - val_accuracy: 0.6609\n",
      "Epoch 54/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4584 - accuracy: 0.8274 - val_loss: 1.3982 - val_accuracy: 0.6634\n",
      "Epoch 55/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4519 - accuracy: 0.8285 - val_loss: 1.4237 - val_accuracy: 0.6651\n",
      "Epoch 56/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4505 - accuracy: 0.8296 - val_loss: 1.4347 - val_accuracy: 0.6621\n",
      "Epoch 57/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4480 - accuracy: 0.8305 - val_loss: 1.4314 - val_accuracy: 0.6627\n",
      "Epoch 58/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4508 - accuracy: 0.8281 - val_loss: 1.4173 - val_accuracy: 0.6651\n",
      "Epoch 59/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4467 - accuracy: 0.8309 - val_loss: 1.4011 - val_accuracy: 0.6657\n",
      "Epoch 60/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4445 - accuracy: 0.8314 - val_loss: 1.4184 - val_accuracy: 0.6665\n",
      "Epoch 61/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4406 - accuracy: 0.8317 - val_loss: 1.4394 - val_accuracy: 0.6663\n",
      "Epoch 62/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4379 - accuracy: 0.8327 - val_loss: 1.4306 - val_accuracy: 0.6602\n",
      "Epoch 63/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4414 - accuracy: 0.8330 - val_loss: 1.4563 - val_accuracy: 0.6645\n",
      "Epoch 64/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4339 - accuracy: 0.8365 - val_loss: 1.4599 - val_accuracy: 0.6650\n",
      "Epoch 65/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4308 - accuracy: 0.8363 - val_loss: 1.4854 - val_accuracy: 0.6641\n",
      "Epoch 66/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4241 - accuracy: 0.8376 - val_loss: 1.4583 - val_accuracy: 0.6636\n",
      "Epoch 67/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4280 - accuracy: 0.8378 - val_loss: 1.4487 - val_accuracy: 0.6594\n",
      "Epoch 68/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4209 - accuracy: 0.8391 - val_loss: 1.4830 - val_accuracy: 0.6613\n",
      "Epoch 69/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4235 - accuracy: 0.8390 - val_loss: 1.5148 - val_accuracy: 0.6634\n",
      "Epoch 70/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4209 - accuracy: 0.8394 - val_loss: 1.4896 - val_accuracy: 0.6611\n",
      "Epoch 71/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4180 - accuracy: 0.8391 - val_loss: 1.5207 - val_accuracy: 0.6604\n",
      "Epoch 72/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4167 - accuracy: 0.8398 - val_loss: 1.5148 - val_accuracy: 0.6588\n",
      "Epoch 73/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4125 - accuracy: 0.8425 - val_loss: 1.5196 - val_accuracy: 0.6578\n",
      "Epoch 74/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4081 - accuracy: 0.8435 - val_loss: 1.4993 - val_accuracy: 0.6588\n",
      "Epoch 75/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4085 - accuracy: 0.8449 - val_loss: 1.5140 - val_accuracy: 0.6597\n",
      "Epoch 76/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4055 - accuracy: 0.8449 - val_loss: 1.5524 - val_accuracy: 0.6636\n",
      "Epoch 77/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4005 - accuracy: 0.8458 - val_loss: 1.5610 - val_accuracy: 0.6628\n",
      "Epoch 78/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4082 - accuracy: 0.8445 - val_loss: 1.5554 - val_accuracy: 0.6586\n",
      "Epoch 79/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4013 - accuracy: 0.8473 - val_loss: 1.6040 - val_accuracy: 0.6598\n",
      "Epoch 80/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.4077 - accuracy: 0.8464 - val_loss: 1.5487 - val_accuracy: 0.6615\n",
      "Epoch 81/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.4015 - accuracy: 0.8470 - val_loss: 1.5715 - val_accuracy: 0.6593\n",
      "Epoch 82/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3950 - accuracy: 0.8467 - val_loss: 1.6130 - val_accuracy: 0.6616\n",
      "Epoch 83/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3918 - accuracy: 0.8521 - val_loss: 1.6127 - val_accuracy: 0.6599\n",
      "Epoch 84/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3937 - accuracy: 0.8517 - val_loss: 1.5784 - val_accuracy: 0.6570\n",
      "Epoch 85/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3863 - accuracy: 0.8527 - val_loss: 1.5637 - val_accuracy: 0.6593\n",
      "Epoch 86/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3917 - accuracy: 0.8505 - val_loss: 1.6202 - val_accuracy: 0.6628\n",
      "Epoch 87/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3900 - accuracy: 0.8512 - val_loss: 1.6174 - val_accuracy: 0.6598\n",
      "Epoch 88/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3829 - accuracy: 0.8521 - val_loss: 1.6095 - val_accuracy: 0.6627\n",
      "Epoch 89/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3823 - accuracy: 0.8550 - val_loss: 1.6051 - val_accuracy: 0.6619\n",
      "Epoch 90/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3846 - accuracy: 0.8545 - val_loss: 1.5969 - val_accuracy: 0.6610\n",
      "Epoch 91/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3862 - accuracy: 0.8532 - val_loss: 1.6225 - val_accuracy: 0.6621\n",
      "Epoch 92/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.3809 - accuracy: 0.8528 - val_loss: 1.6329 - val_accuracy: 0.6576\n",
      "Epoch 93/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3797 - accuracy: 0.8558 - val_loss: 1.6183 - val_accuracy: 0.6595\n",
      "Epoch 94/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3774 - accuracy: 0.8549 - val_loss: 1.6126 - val_accuracy: 0.6597\n",
      "Epoch 95/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3820 - accuracy: 0.8545 - val_loss: 1.6452 - val_accuracy: 0.6596\n",
      "Epoch 96/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3753 - accuracy: 0.8568 - val_loss: 1.6610 - val_accuracy: 0.6600\n",
      "Epoch 97/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3752 - accuracy: 0.8568 - val_loss: 1.6431 - val_accuracy: 0.6568\n",
      "Epoch 98/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3751 - accuracy: 0.8566 - val_loss: 1.6446 - val_accuracy: 0.6593\n",
      "Epoch 99/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3739 - accuracy: 0.8565 - val_loss: 1.6642 - val_accuracy: 0.6619\n",
      "Epoch 100/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3734 - accuracy: 0.8567 - val_loss: 1.6610 - val_accuracy: 0.6579\n",
      "Epoch 101/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3693 - accuracy: 0.8595 - val_loss: 1.6708 - val_accuracy: 0.6570\n",
      "Epoch 102/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3725 - accuracy: 0.8582 - val_loss: 1.7058 - val_accuracy: 0.6587\n",
      "Epoch 103/200\n",
      "390/390 [==============================] - 6s 15ms/step - loss: 0.3726 - accuracy: 0.8574 - val_loss: 1.6532 - val_accuracy: 0.6595\n",
      "Epoch 104/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3684 - accuracy: 0.8593 - val_loss: 1.7289 - val_accuracy: 0.6561\n",
      "Epoch 105/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3628 - accuracy: 0.8601 - val_loss: 1.6905 - val_accuracy: 0.6576\n",
      "Epoch 106/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3641 - accuracy: 0.8600 - val_loss: 1.6689 - val_accuracy: 0.6554\n",
      "Epoch 107/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3600 - accuracy: 0.8617 - val_loss: 1.7185 - val_accuracy: 0.6589\n",
      "Epoch 108/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3640 - accuracy: 0.8588 - val_loss: 1.7264 - val_accuracy: 0.6602\n",
      "Epoch 109/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3616 - accuracy: 0.8621 - val_loss: 1.7152 - val_accuracy: 0.6581\n",
      "Epoch 110/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3589 - accuracy: 0.8624 - val_loss: 1.7344 - val_accuracy: 0.6575\n",
      "Epoch 111/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3584 - accuracy: 0.8640 - val_loss: 1.7201 - val_accuracy: 0.6606\n",
      "Epoch 112/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3644 - accuracy: 0.8618 - val_loss: 1.7385 - val_accuracy: 0.6583\n",
      "Epoch 113/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3634 - accuracy: 0.8623 - val_loss: 1.6965 - val_accuracy: 0.6577\n",
      "Epoch 114/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3588 - accuracy: 0.8616 - val_loss: 1.7327 - val_accuracy: 0.6584\n",
      "Epoch 115/200\n",
      "390/390 [==============================] - 5s 14ms/step - loss: 0.3555 - accuracy: 0.8647 - val_loss: 1.7164 - val_accuracy: 0.6597\n",
      "Epoch 116/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3536 - accuracy: 0.8635 - val_loss: 1.7190 - val_accuracy: 0.6574\n",
      "Epoch 117/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3500 - accuracy: 0.8658 - val_loss: 1.7116 - val_accuracy: 0.6577\n",
      "Epoch 118/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3543 - accuracy: 0.8653 - val_loss: 1.7235 - val_accuracy: 0.6583\n",
      "Epoch 119/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3583 - accuracy: 0.8631 - val_loss: 1.7193 - val_accuracy: 0.6573\n",
      "Epoch 120/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3528 - accuracy: 0.8666 - val_loss: 1.7681 - val_accuracy: 0.6581\n",
      "Epoch 121/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3419 - accuracy: 0.8688 - val_loss: 1.7836 - val_accuracy: 0.6574\n",
      "Epoch 134/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3475 - accuracy: 0.8668 - val_loss: 1.7453 - val_accuracy: 0.6589\n",
      "Epoch 135/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3416 - accuracy: 0.8701 - val_loss: 1.7540 - val_accuracy: 0.6572\n",
      "Epoch 136/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3393 - accuracy: 0.8724 - val_loss: 1.7937 - val_accuracy: 0.6584\n",
      "Epoch 137/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3373 - accuracy: 0.8703 - val_loss: 1.7885 - val_accuracy: 0.6578\n",
      "Epoch 138/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3358 - accuracy: 0.8719 - val_loss: 1.8178 - val_accuracy: 0.6595\n",
      "Epoch 139/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3365 - accuracy: 0.8723 - val_loss: 1.7676 - val_accuracy: 0.6573\n",
      "Epoch 140/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3417 - accuracy: 0.8686 - val_loss: 1.8315 - val_accuracy: 0.6576\n",
      "Epoch 141/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3350 - accuracy: 0.8732 - val_loss: 1.8219 - val_accuracy: 0.6577\n",
      "Epoch 142/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3361 - accuracy: 0.8716 - val_loss: 1.7678 - val_accuracy: 0.6584\n",
      "Epoch 143/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3266 - accuracy: 0.8745 - val_loss: 1.7664 - val_accuracy: 0.6572\n",
      "Epoch 144/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3337 - accuracy: 0.8728 - val_loss: 1.8132 - val_accuracy: 0.6619\n",
      "Epoch 145/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3326 - accuracy: 0.8709 - val_loss: 1.8396 - val_accuracy: 0.6542\n",
      "Epoch 146/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3380 - accuracy: 0.8717 - val_loss: 1.8408 - val_accuracy: 0.6576\n",
      "Epoch 147/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3303 - accuracy: 0.8739 - val_loss: 1.8140 - val_accuracy: 0.6599\n",
      "Epoch 148/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3329 - accuracy: 0.8735 - val_loss: 1.8137 - val_accuracy: 0.6576\n",
      "Epoch 149/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3277 - accuracy: 0.8755 - val_loss: 1.7944 - val_accuracy: 0.6576\n",
      "Epoch 150/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3259 - accuracy: 0.8758 - val_loss: 1.8296 - val_accuracy: 0.6603\n",
      "Epoch 151/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3294 - accuracy: 0.8754 - val_loss: 1.8645 - val_accuracy: 0.6595\n",
      "Epoch 152/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3320 - accuracy: 0.8736 - val_loss: 1.8127 - val_accuracy: 0.6558\n",
      "Epoch 153/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3255 - accuracy: 0.8773 - val_loss: 1.8475 - val_accuracy: 0.6583\n",
      "Epoch 154/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3259 - accuracy: 0.8752 - val_loss: 1.8280 - val_accuracy: 0.6610\n",
      "Epoch 155/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3233 - accuracy: 0.8793 - val_loss: 1.8451 - val_accuracy: 0.6576\n",
      "Epoch 156/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3266 - accuracy: 0.8739 - val_loss: 1.8555 - val_accuracy: 0.6621\n",
      "Epoch 157/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3245 - accuracy: 0.8763 - val_loss: 1.8415 - val_accuracy: 0.6583\n",
      "Epoch 158/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3259 - accuracy: 0.8771 - val_loss: 1.8286 - val_accuracy: 0.6575\n",
      "Epoch 159/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3250 - accuracy: 0.8765 - val_loss: 1.8643 - val_accuracy: 0.6560\n",
      "Epoch 160/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3298 - accuracy: 0.8738 - val_loss: 1.8265 - val_accuracy: 0.6536\n",
      "Epoch 161/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3224 - accuracy: 0.8774 - val_loss: 1.8438 - val_accuracy: 0.6579\n",
      "Epoch 162/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3237 - accuracy: 0.8777 - val_loss: 1.8385 - val_accuracy: 0.6593\n",
      "Epoch 163/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3195 - accuracy: 0.8776 - val_loss: 1.8157 - val_accuracy: 0.6576\n",
      "Epoch 164/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3205 - accuracy: 0.8768 - val_loss: 1.8367 - val_accuracy: 0.6620\n",
      "Epoch 165/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3220 - accuracy: 0.8774 - val_loss: 1.8380 - val_accuracy: 0.6605\n",
      "Epoch 166/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3197 - accuracy: 0.8781 - val_loss: 1.8734 - val_accuracy: 0.6587\n",
      "Epoch 167/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3152 - accuracy: 0.8795 - val_loss: 1.8714 - val_accuracy: 0.6550\n",
      "Epoch 168/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3223 - accuracy: 0.8770 - val_loss: 1.8692 - val_accuracy: 0.6599\n",
      "Epoch 169/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3230 - accuracy: 0.8763 - val_loss: 1.8395 - val_accuracy: 0.6567\n",
      "Epoch 170/200\n",
      "390/390 [==============================] - 6s 14ms/step - loss: 0.3186 - accuracy: 0.8781 - val_loss: 1.8696 - val_accuracy: 0.6586\n",
      "Epoch 171/200\n",
      "185/390 [=============>................] - ETA: 2s - loss: 0.3158 - accuracy: 0.8792"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a higher learning rate for BN\n",
    "lr = 1e-2\n",
    "model7.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.001)\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%M%S-model7\")\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logdir, update_freq='epoch', profile_batch=2\n",
    ")\n",
    "\n",
    "# We are going to train for 50 epochs\n",
    "history = model7.fit(\n",
    "    train_ds, epochs=200, validation_data=test_ds, \n",
    "    callbacks=[reduce_lr, tb_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 1s 12ms/step - loss: 1.9338 - accuracy: 0.6594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.933787226676941, 0.6593549847602844]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2_3]",
   "language": "python",
   "name": "conda-env-tf2_3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
